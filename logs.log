2023-02-28 00:48:09,604:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-28 00:48:09,604:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-28 00:48:09,604:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-28 00:48:09,604:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-28 00:48:10,215:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-28 00:48:54,615:INFO:PyCaret RegressionExperiment
2023-02-28 00:48:54,615:INFO:Logging name: reg-default-name
2023-02-28 00:48:54,615:INFO:ML Usecase: MLUsecase.REGRESSION
2023-02-28 00:48:54,615:INFO:version 3.0.0.rc9
2023-02-28 00:48:54,615:INFO:Initializing setup()
2023-02-28 00:48:54,615:INFO:self.USI: 4c4b
2023-02-28 00:48:54,615:INFO:self._variable_keys: {'exp_name_log', 'data', 'idx', 'exp_id', 'html_param', '_available_plots', 'logging_param', 'memory', 'y_test', 'X_test', 'X_train', 'fold_groups_param', 'USI', 'seed', 'fold_generator', 'gpu_param', 'transform_target_param', 'fold_shuffle_param', '_ml_usecase', 'gpu_n_jobs_param', 'pipeline', 'log_plots_param', 'n_jobs_param', 'target_param', 'y_train', 'X', 'y'}
2023-02-28 00:48:54,615:INFO:Checking environment
2023-02-28 00:48:54,615:INFO:python_version: 3.8.16
2023-02-28 00:48:54,615:INFO:python_build: ('default', 'Jan 17 2023 22:25:28')
2023-02-28 00:48:54,617:INFO:machine: AMD64
2023-02-28 00:48:54,617:INFO:platform: Windows-10-10.0.22621-SP0
2023-02-28 00:48:54,641:INFO:Memory: svmem(total=14702026752, available=4716072960, percent=67.9, used=9985953792, free=4716072960)
2023-02-28 00:48:54,641:INFO:Physical Core: 8
2023-02-28 00:48:54,641:INFO:Logical Core: 16
2023-02-28 00:48:54,641:INFO:Checking libraries
2023-02-28 00:48:54,641:INFO:System:
2023-02-28 00:48:54,641:INFO:    python: 3.8.16 (default, Jan 17 2023, 22:25:28) [MSC v.1916 64 bit (AMD64)]
2023-02-28 00:48:54,641:INFO:executable: c:\Users\takis\anaconda3\envs\caretenv\python.exe
2023-02-28 00:48:54,641:INFO:   machine: Windows-10-10.0.22621-SP0
2023-02-28 00:48:54,641:INFO:PyCaret required dependencies:
2023-02-28 00:48:54,641:INFO:                 pip: 22.3.1
2023-02-28 00:48:54,641:INFO:          setuptools: 65.6.3
2023-02-28 00:48:54,641:INFO:             pycaret: 3.0.0rc9
2023-02-28 00:48:54,641:INFO:             IPython: 8.10.0
2023-02-28 00:48:54,641:INFO:          ipywidgets: 8.0.4
2023-02-28 00:48:54,643:INFO:                tqdm: 4.64.1
2023-02-28 00:48:54,643:INFO:               numpy: 1.23.5
2023-02-28 00:48:54,643:INFO:              pandas: 1.5.3
2023-02-28 00:48:54,643:INFO:              jinja2: 3.1.2
2023-02-28 00:48:54,643:INFO:               scipy: 1.10.1
2023-02-28 00:48:54,643:INFO:              joblib: 1.2.0
2023-02-28 00:48:54,643:INFO:             sklearn: 1.2.1
2023-02-28 00:48:54,643:INFO:                pyod: 1.0.7
2023-02-28 00:48:54,643:INFO:            imblearn: 0.10.1
2023-02-28 00:48:54,643:INFO:   category_encoders: 2.6.0
2023-02-28 00:48:54,643:INFO:            lightgbm: 3.3.5
2023-02-28 00:48:54,643:INFO:               numba: 0.56.4
2023-02-28 00:48:54,643:INFO:            requests: 2.28.2
2023-02-28 00:48:54,643:INFO:          matplotlib: 3.7.0
2023-02-28 00:48:54,643:INFO:          scikitplot: 0.3.7
2023-02-28 00:48:54,643:INFO:         yellowbrick: 1.5
2023-02-28 00:48:54,643:INFO:              plotly: 5.13.1
2023-02-28 00:48:54,643:INFO:             kaleido: 0.2.1
2023-02-28 00:48:54,643:INFO:         statsmodels: 0.13.5
2023-02-28 00:48:54,643:INFO:              sktime: 0.16.1
2023-02-28 00:48:54,643:INFO:               tbats: 1.1.2
2023-02-28 00:48:54,643:INFO:            pmdarima: 2.0.2
2023-02-28 00:48:54,643:INFO:              psutil: 5.9.4
2023-02-28 00:48:54,643:INFO:PyCaret optional dependencies:
2023-02-28 00:48:54,664:INFO:                shap: Not installed
2023-02-28 00:48:54,664:INFO:           interpret: Not installed
2023-02-28 00:48:54,664:INFO:                umap: Not installed
2023-02-28 00:48:54,664:INFO:    pandas_profiling: Not installed
2023-02-28 00:48:54,664:INFO:  explainerdashboard: Not installed
2023-02-28 00:48:54,664:INFO:             autoviz: Not installed
2023-02-28 00:48:54,664:INFO:           fairlearn: Not installed
2023-02-28 00:48:54,664:INFO:             xgboost: Not installed
2023-02-28 00:48:54,664:INFO:            catboost: Not installed
2023-02-28 00:48:54,664:INFO:              kmodes: Not installed
2023-02-28 00:48:54,664:INFO:             mlxtend: Not installed
2023-02-28 00:48:54,664:INFO:       statsforecast: Not installed
2023-02-28 00:48:54,664:INFO:        tune_sklearn: Not installed
2023-02-28 00:48:54,664:INFO:                 ray: Not installed
2023-02-28 00:48:54,664:INFO:            hyperopt: Not installed
2023-02-28 00:48:54,664:INFO:              optuna: Not installed
2023-02-28 00:48:54,664:INFO:               skopt: Not installed
2023-02-28 00:48:54,664:INFO:              mlflow: Not installed
2023-02-28 00:48:54,664:INFO:              gradio: Not installed
2023-02-28 00:48:54,664:INFO:             fastapi: Not installed
2023-02-28 00:48:54,664:INFO:             uvicorn: Not installed
2023-02-28 00:48:54,672:INFO:              m2cgen: Not installed
2023-02-28 00:48:54,672:INFO:           evidently: Not installed
2023-02-28 00:48:54,672:INFO:               fugue: Not installed
2023-02-28 00:48:54,672:INFO:           streamlit: Not installed
2023-02-28 00:48:54,672:INFO:             prophet: Not installed
2023-02-28 00:48:54,672:INFO:None
2023-02-28 00:48:54,672:INFO:Set up data.
2023-02-28 00:48:54,680:INFO:Set up train/test split.
2023-02-28 00:48:54,688:INFO:Set up index.
2023-02-28 00:48:54,688:INFO:Set up folding strategy.
2023-02-28 00:48:54,688:INFO:Assigning column types.
2023-02-28 00:48:54,694:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-28 00:48:54,694:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-28 00:48:54,699:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-28 00:48:54,705:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 00:48:54,797:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 00:48:54,867:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 00:48:54,867:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:48:54,896:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:48:54,896:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-28 00:48:54,909:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-28 00:48:54,915:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 00:48:54,995:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 00:48:55,050:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 00:48:55,050:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:48:55,050:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:48:55,050:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-02-28 00:48:55,059:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-28 00:48:55,067:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 00:48:55,148:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 00:48:55,301:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 00:48:55,301:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:48:55,301:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:48:55,315:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-28 00:48:55,326:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 00:48:55,415:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 00:48:55,480:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 00:48:55,480:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:48:55,480:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:48:55,480:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-02-28 00:48:55,498:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 00:48:55,579:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 00:48:55,625:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 00:48:55,625:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:48:55,633:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:48:55,641:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 00:48:55,714:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 00:48:55,777:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 00:48:55,780:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:48:55,780:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:48:55,780:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-02-28 00:48:55,852:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 00:48:55,902:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 00:48:55,902:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:48:55,902:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:48:55,968:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 00:48:56,010:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 00:48:56,010:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:48:56,011:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:48:56,011:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-28 00:48:56,067:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 00:48:56,110:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:48:56,110:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:48:56,172:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 00:48:56,213:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:48:56,213:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:48:56,213:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-02-28 00:48:56,319:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:48:56,319:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:48:56,433:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:48:56,433:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:48:56,433:INFO:Preparing preprocessing pipeline...
2023-02-28 00:48:56,433:INFO:Set up simple imputation.
2023-02-28 00:48:56,442:INFO:Set up encoding of ordinal features.
2023-02-28 00:48:56,445:INFO:Set up encoding of categorical features.
2023-02-28 00:48:56,514:INFO:Finished creating preprocessing pipeline.
2023-02-28 00:48:56,544:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\takis\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                     'smoker'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64},
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-02-28 00:48:56,544:INFO:Creating final display dataframe.
2023-02-28 00:48:56,872:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           charges
2                   Target type        Regression
3           Original data shape         (1338, 7)
4        Transformed data shape        (1338, 10)
5   Transformed train set shape         (936, 10)
6    Transformed test set shape         (402, 10)
7              Ordinal features                 2
8              Numeric features                 3
9          Categorical features                 3
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              4c4b
2023-02-28 00:48:56,991:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:48:56,991:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:48:57,094:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:48:57,094:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:48:57,094:INFO:setup() successfully completed in 2.48s...............
2023-02-28 00:50:05,380:ERROR:
'autoviz' is a soft dependency and not included in the pycaret installation. Please run: `pip install autoviz` to install.
Alternately, you can install this by running `pip install pycaret[mlops]`
NoneType: None
2023-02-28 00:52:05,193:ERROR:
'autoviz' is a soft dependency and not included in the pycaret installation. Please run: `pip install autoviz` to install.
Alternately, you can install this by running `pip install pycaret[mlops]`
NoneType: None
2023-02-28 00:54:40,184:ERROR:
'autoviz' is a soft dependency and not included in the pycaret installation. Please run: `pip install autoviz` to install.
Alternately, you can install this by running `pip install pycaret[mlops]`
NoneType: None
2023-02-28 00:54:47,357:INFO:PyCaret RegressionExperiment
2023-02-28 00:54:47,357:INFO:Logging name: reg-default-name
2023-02-28 00:54:47,357:INFO:ML Usecase: MLUsecase.REGRESSION
2023-02-28 00:54:47,357:INFO:version 3.0.0.rc9
2023-02-28 00:54:47,357:INFO:Initializing setup()
2023-02-28 00:54:47,357:INFO:self.USI: a15f
2023-02-28 00:54:47,357:INFO:self._variable_keys: {'exp_name_log', 'data', 'idx', 'exp_id', 'html_param', '_available_plots', 'logging_param', 'memory', 'y_test', 'X_test', 'X_train', 'fold_groups_param', 'USI', 'seed', 'fold_generator', 'gpu_param', 'transform_target_param', 'fold_shuffle_param', '_ml_usecase', 'gpu_n_jobs_param', 'pipeline', 'log_plots_param', 'n_jobs_param', 'target_param', 'y_train', 'X', 'y'}
2023-02-28 00:54:47,357:INFO:Checking environment
2023-02-28 00:54:47,357:INFO:python_version: 3.8.16
2023-02-28 00:54:47,357:INFO:python_build: ('default', 'Jan 17 2023 22:25:28')
2023-02-28 00:54:47,357:INFO:machine: AMD64
2023-02-28 00:54:47,357:INFO:platform: Windows-10-10.0.22621-SP0
2023-02-28 00:54:47,402:INFO:Memory: svmem(total=14702026752, available=4239941632, percent=71.2, used=10462085120, free=4239941632)
2023-02-28 00:54:47,402:INFO:Physical Core: 8
2023-02-28 00:54:47,402:INFO:Logical Core: 16
2023-02-28 00:54:47,402:INFO:Checking libraries
2023-02-28 00:54:47,402:INFO:System:
2023-02-28 00:54:47,402:INFO:    python: 3.8.16 (default, Jan 17 2023, 22:25:28) [MSC v.1916 64 bit (AMD64)]
2023-02-28 00:54:47,402:INFO:executable: c:\Users\takis\anaconda3\envs\caretenv\python.exe
2023-02-28 00:54:47,402:INFO:   machine: Windows-10-10.0.22621-SP0
2023-02-28 00:54:47,402:INFO:PyCaret required dependencies:
2023-02-28 00:54:47,402:INFO:                 pip: 22.3.1
2023-02-28 00:54:47,402:INFO:          setuptools: 65.6.3
2023-02-28 00:54:47,402:INFO:             pycaret: 3.0.0rc9
2023-02-28 00:54:47,402:INFO:             IPython: 8.10.0
2023-02-28 00:54:47,402:INFO:          ipywidgets: 8.0.4
2023-02-28 00:54:47,402:INFO:                tqdm: 4.64.1
2023-02-28 00:54:47,402:INFO:               numpy: 1.23.5
2023-02-28 00:54:47,402:INFO:              pandas: 1.5.3
2023-02-28 00:54:47,402:INFO:              jinja2: 3.1.2
2023-02-28 00:54:47,402:INFO:               scipy: 1.10.1
2023-02-28 00:54:47,402:INFO:              joblib: 1.2.0
2023-02-28 00:54:47,402:INFO:             sklearn: 1.2.1
2023-02-28 00:54:47,402:INFO:                pyod: 1.0.7
2023-02-28 00:54:47,402:INFO:            imblearn: 0.10.1
2023-02-28 00:54:47,402:INFO:   category_encoders: 2.6.0
2023-02-28 00:54:47,402:INFO:            lightgbm: 3.3.5
2023-02-28 00:54:47,402:INFO:               numba: 0.56.4
2023-02-28 00:54:47,402:INFO:            requests: 2.28.2
2023-02-28 00:54:47,402:INFO:          matplotlib: 3.7.0
2023-02-28 00:54:47,402:INFO:          scikitplot: 0.3.7
2023-02-28 00:54:47,402:INFO:         yellowbrick: 1.5
2023-02-28 00:54:47,402:INFO:              plotly: 5.13.1
2023-02-28 00:54:47,402:INFO:             kaleido: 0.2.1
2023-02-28 00:54:47,402:INFO:         statsmodels: 0.13.5
2023-02-28 00:54:47,402:INFO:              sktime: 0.16.1
2023-02-28 00:54:47,402:INFO:               tbats: 1.1.2
2023-02-28 00:54:47,402:INFO:            pmdarima: 2.0.2
2023-02-28 00:54:47,402:INFO:              psutil: 5.9.4
2023-02-28 00:54:47,402:INFO:PyCaret optional dependencies:
2023-02-28 00:54:47,402:INFO:                shap: Not installed
2023-02-28 00:54:47,402:INFO:           interpret: Not installed
2023-02-28 00:54:47,402:INFO:                umap: Not installed
2023-02-28 00:54:47,402:INFO:    pandas_profiling: Not installed
2023-02-28 00:54:47,402:INFO:  explainerdashboard: Not installed
2023-02-28 00:54:47,402:INFO:             autoviz: Not installed
2023-02-28 00:54:47,402:INFO:           fairlearn: Not installed
2023-02-28 00:54:47,402:INFO:             xgboost: Not installed
2023-02-28 00:54:47,402:INFO:            catboost: Not installed
2023-02-28 00:54:47,402:INFO:              kmodes: Not installed
2023-02-28 00:54:47,402:INFO:             mlxtend: Not installed
2023-02-28 00:54:47,402:INFO:       statsforecast: Not installed
2023-02-28 00:54:47,402:INFO:        tune_sklearn: Not installed
2023-02-28 00:54:47,402:INFO:                 ray: Not installed
2023-02-28 00:54:47,402:INFO:            hyperopt: Not installed
2023-02-28 00:54:47,402:INFO:              optuna: Not installed
2023-02-28 00:54:47,402:INFO:               skopt: Not installed
2023-02-28 00:54:47,407:INFO:              mlflow: Not installed
2023-02-28 00:54:47,407:INFO:              gradio: Not installed
2023-02-28 00:54:47,407:INFO:             fastapi: Not installed
2023-02-28 00:54:47,407:INFO:             uvicorn: Not installed
2023-02-28 00:54:47,407:INFO:              m2cgen: Not installed
2023-02-28 00:54:47,407:INFO:           evidently: Not installed
2023-02-28 00:54:47,407:INFO:               fugue: Not installed
2023-02-28 00:54:47,407:INFO:           streamlit: Not installed
2023-02-28 00:54:47,407:INFO:             prophet: Not installed
2023-02-28 00:54:47,407:INFO:None
2023-02-28 00:54:47,407:INFO:Set up data.
2023-02-28 00:54:47,413:INFO:Set up train/test split.
2023-02-28 00:54:47,421:INFO:Set up index.
2023-02-28 00:54:47,422:INFO:Set up folding strategy.
2023-02-28 00:54:47,422:INFO:Assigning column types.
2023-02-28 00:54:47,422:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-28 00:54:47,426:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-28 00:54:47,426:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-28 00:54:47,439:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 00:54:47,513:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 00:54:47,573:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 00:54:47,573:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:54:47,573:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:54:47,573:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-28 00:54:47,581:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-28 00:54:47,593:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 00:54:47,670:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 00:54:47,735:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 00:54:47,735:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:54:47,735:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:54:47,738:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-02-28 00:54:47,743:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-28 00:54:47,743:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 00:54:47,835:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 00:54:47,915:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 00:54:47,915:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:54:47,915:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:54:47,923:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-28 00:54:47,926:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 00:54:48,005:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 00:54:48,070:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 00:54:48,070:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:54:48,070:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:54:48,070:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-02-28 00:54:48,087:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 00:54:48,161:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 00:54:48,223:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 00:54:48,223:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:54:48,226:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:54:48,237:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 00:54:48,308:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 00:54:48,375:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 00:54:48,375:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:54:48,375:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:54:48,375:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-02-28 00:54:48,488:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 00:54:48,545:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 00:54:48,545:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:54:48,545:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:54:48,639:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 00:54:48,693:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 00:54:48,693:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:54:48,701:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:54:48,701:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-28 00:54:48,773:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 00:54:48,835:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:54:48,835:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:54:48,922:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 00:54:48,972:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:54:48,979:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:54:48,979:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-02-28 00:54:49,093:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:54:49,093:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:54:49,220:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:54:49,220:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:54:49,220:INFO:Preparing preprocessing pipeline...
2023-02-28 00:54:49,220:INFO:Set up simple imputation.
2023-02-28 00:54:49,225:INFO:Set up encoding of ordinal features.
2023-02-28 00:54:49,225:INFO:Set up encoding of categorical features.
2023-02-28 00:54:49,298:INFO:Finished creating preprocessing pipeline.
2023-02-28 00:54:49,322:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\takis\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                     'smoker'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64},
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-02-28 00:54:49,322:INFO:Creating final display dataframe.
2023-02-28 00:54:49,648:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           charges
2                   Target type        Regression
3           Original data shape         (1338, 7)
4        Transformed data shape        (1338, 10)
5   Transformed train set shape         (936, 10)
6    Transformed test set shape         (402, 10)
7              Ordinal features                 2
8              Numeric features                 3
9          Categorical features                 3
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              a15f
2023-02-28 00:54:49,789:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:54:49,789:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:54:49,904:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:54:49,904:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:54:49,904:INFO:setup() successfully completed in 2.55s...............
2023-02-28 00:54:58,009:ERROR:
'autoviz' is a soft dependency and not included in the pycaret installation. Please run: `pip install autoviz` to install.
Alternately, you can install this by running `pip install pycaret[mlops]`
NoneType: None
2023-02-28 00:56:15,788:INFO:PyCaret RegressionExperiment
2023-02-28 00:56:15,788:INFO:Logging name: reg-default-name
2023-02-28 00:56:15,788:INFO:ML Usecase: MLUsecase.REGRESSION
2023-02-28 00:56:15,788:INFO:version 3.0.0.rc9
2023-02-28 00:56:15,789:INFO:Initializing setup()
2023-02-28 00:56:15,789:INFO:self.USI: 1a1d
2023-02-28 00:56:15,789:INFO:self._variable_keys: {'exp_name_log', 'data', 'idx', 'exp_id', 'html_param', '_available_plots', 'logging_param', 'memory', 'y_test', 'X_test', 'X_train', 'fold_groups_param', 'USI', 'seed', 'fold_generator', 'gpu_param', 'transform_target_param', 'fold_shuffle_param', '_ml_usecase', 'gpu_n_jobs_param', 'pipeline', 'log_plots_param', 'n_jobs_param', 'target_param', 'y_train', 'X', 'y'}
2023-02-28 00:56:15,789:INFO:Checking environment
2023-02-28 00:56:15,789:INFO:python_version: 3.8.16
2023-02-28 00:56:15,789:INFO:python_build: ('default', 'Jan 17 2023 22:25:28')
2023-02-28 00:56:15,789:INFO:machine: AMD64
2023-02-28 00:56:15,789:INFO:platform: Windows-10-10.0.22621-SP0
2023-02-28 00:56:15,796:INFO:Memory: svmem(total=14702026752, available=4264992768, percent=71.0, used=10437033984, free=4264992768)
2023-02-28 00:56:15,796:INFO:Physical Core: 8
2023-02-28 00:56:15,796:INFO:Logical Core: 16
2023-02-28 00:56:15,796:INFO:Checking libraries
2023-02-28 00:56:15,796:INFO:System:
2023-02-28 00:56:15,796:INFO:    python: 3.8.16 (default, Jan 17 2023, 22:25:28) [MSC v.1916 64 bit (AMD64)]
2023-02-28 00:56:15,805:INFO:executable: c:\Users\takis\anaconda3\envs\caretenv\python.exe
2023-02-28 00:56:15,805:INFO:   machine: Windows-10-10.0.22621-SP0
2023-02-28 00:56:15,805:INFO:PyCaret required dependencies:
2023-02-28 00:56:15,805:INFO:                 pip: 22.3.1
2023-02-28 00:56:15,805:INFO:          setuptools: 65.6.3
2023-02-28 00:56:15,805:INFO:             pycaret: 3.0.0rc9
2023-02-28 00:56:15,805:INFO:             IPython: 8.10.0
2023-02-28 00:56:15,805:INFO:          ipywidgets: 8.0.4
2023-02-28 00:56:15,805:INFO:                tqdm: 4.64.1
2023-02-28 00:56:15,805:INFO:               numpy: 1.23.5
2023-02-28 00:56:15,805:INFO:              pandas: 1.5.3
2023-02-28 00:56:15,805:INFO:              jinja2: 3.1.2
2023-02-28 00:56:15,805:INFO:               scipy: 1.10.1
2023-02-28 00:56:15,805:INFO:              joblib: 1.2.0
2023-02-28 00:56:15,805:INFO:             sklearn: 1.2.1
2023-02-28 00:56:15,805:INFO:                pyod: 1.0.7
2023-02-28 00:56:15,805:INFO:            imblearn: 0.10.1
2023-02-28 00:56:15,805:INFO:   category_encoders: 2.6.0
2023-02-28 00:56:15,805:INFO:            lightgbm: 3.3.5
2023-02-28 00:56:15,805:INFO:               numba: 0.56.4
2023-02-28 00:56:15,805:INFO:            requests: 2.28.2
2023-02-28 00:56:15,805:INFO:          matplotlib: 3.7.0
2023-02-28 00:56:15,805:INFO:          scikitplot: 0.3.7
2023-02-28 00:56:15,805:INFO:         yellowbrick: 1.5
2023-02-28 00:56:15,805:INFO:              plotly: 5.13.1
2023-02-28 00:56:15,805:INFO:             kaleido: 0.2.1
2023-02-28 00:56:15,805:INFO:         statsmodels: 0.13.5
2023-02-28 00:56:15,805:INFO:              sktime: 0.16.1
2023-02-28 00:56:15,805:INFO:               tbats: 1.1.2
2023-02-28 00:56:15,805:INFO:            pmdarima: 2.0.2
2023-02-28 00:56:15,805:INFO:              psutil: 5.9.4
2023-02-28 00:56:15,805:INFO:PyCaret optional dependencies:
2023-02-28 00:56:15,805:INFO:                shap: Not installed
2023-02-28 00:56:15,805:INFO:           interpret: Not installed
2023-02-28 00:56:15,805:INFO:                umap: Not installed
2023-02-28 00:56:15,805:INFO:    pandas_profiling: Not installed
2023-02-28 00:56:15,805:INFO:  explainerdashboard: Not installed
2023-02-28 00:56:15,805:INFO:             autoviz: Not installed
2023-02-28 00:56:15,805:INFO:           fairlearn: Not installed
2023-02-28 00:56:15,805:INFO:             xgboost: Not installed
2023-02-28 00:56:15,805:INFO:            catboost: Not installed
2023-02-28 00:56:15,805:INFO:              kmodes: Not installed
2023-02-28 00:56:15,805:INFO:             mlxtend: Not installed
2023-02-28 00:56:15,805:INFO:       statsforecast: Not installed
2023-02-28 00:56:15,805:INFO:        tune_sklearn: Not installed
2023-02-28 00:56:15,805:INFO:                 ray: Not installed
2023-02-28 00:56:15,805:INFO:            hyperopt: Not installed
2023-02-28 00:56:15,805:INFO:              optuna: Not installed
2023-02-28 00:56:15,805:INFO:               skopt: Not installed
2023-02-28 00:56:15,805:INFO:              mlflow: Not installed
2023-02-28 00:56:15,805:INFO:              gradio: Not installed
2023-02-28 00:56:15,805:INFO:             fastapi: Not installed
2023-02-28 00:56:15,805:INFO:             uvicorn: Not installed
2023-02-28 00:56:15,805:INFO:              m2cgen: Not installed
2023-02-28 00:56:15,805:INFO:           evidently: Not installed
2023-02-28 00:56:15,805:INFO:               fugue: Not installed
2023-02-28 00:56:15,805:INFO:           streamlit: Not installed
2023-02-28 00:56:15,829:INFO:             prophet: Not installed
2023-02-28 00:56:15,829:INFO:None
2023-02-28 00:56:15,829:INFO:Set up data.
2023-02-28 00:56:15,837:INFO:Set up train/test split.
2023-02-28 00:56:15,846:INFO:Set up index.
2023-02-28 00:56:15,846:INFO:Set up folding strategy.
2023-02-28 00:56:15,846:INFO:Assigning column types.
2023-02-28 00:56:15,853:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-28 00:56:15,853:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-28 00:56:15,868:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-28 00:56:15,870:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 00:56:15,968:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 00:56:16,025:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 00:56:16,025:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:56:16,025:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:56:16,025:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-28 00:56:16,033:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-28 00:56:16,041:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 00:56:16,113:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 00:56:16,177:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 00:56:16,177:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:56:16,177:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:56:16,177:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-02-28 00:56:16,185:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-28 00:56:16,193:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 00:56:16,270:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 00:56:16,331:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 00:56:16,334:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:56:16,334:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:56:16,339:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-28 00:56:16,339:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 00:56:16,422:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 00:56:16,479:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 00:56:16,479:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:56:16,479:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:56:16,479:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-02-28 00:56:16,496:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 00:56:16,568:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 00:56:16,633:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 00:56:16,633:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:56:16,633:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:56:16,641:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 00:56:16,725:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 00:56:16,780:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 00:56:16,780:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:56:16,780:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:56:16,780:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-02-28 00:56:16,870:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 00:56:16,919:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 00:56:16,919:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:56:16,919:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:56:16,992:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 00:56:17,042:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 00:56:17,042:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:56:17,042:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:56:17,042:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-28 00:56:17,113:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 00:56:17,161:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:56:17,169:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:56:17,237:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 00:56:17,276:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:56:17,276:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:56:17,276:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-02-28 00:56:17,382:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:56:17,382:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:56:17,485:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:56:17,485:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:56:17,485:INFO:Preparing preprocessing pipeline...
2023-02-28 00:56:17,485:INFO:Set up simple imputation.
2023-02-28 00:56:17,488:INFO:Set up encoding of ordinal features.
2023-02-28 00:56:17,488:INFO:Set up encoding of categorical features.
2023-02-28 00:56:17,553:INFO:Finished creating preprocessing pipeline.
2023-02-28 00:56:17,586:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\takis\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                     'smoker'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64},
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-02-28 00:56:17,586:INFO:Creating final display dataframe.
2023-02-28 00:56:17,928:INFO:Setup _display_container:                     Description             Value
0                    Session id              4671
1                        Target           charges
2                   Target type        Regression
3           Original data shape         (1338, 7)
4        Transformed data shape        (1338, 10)
5   Transformed train set shape         (936, 10)
6    Transformed test set shape         (402, 10)
7              Ordinal features                 2
8              Numeric features                 3
9          Categorical features                 3
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              1a1d
2023-02-28 00:56:18,046:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:56:18,049:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:56:18,150:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:56:18,150:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:56:18,150:INFO:setup() successfully completed in 2.37s...............
2023-02-28 00:56:19,683:ERROR:
'autoviz' is a soft dependency and not included in the pycaret installation. Please run: `pip install autoviz` to install.
Alternately, you can install this by running `pip install pycaret[mlops]`
NoneType: None
2023-02-28 00:56:41,699:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-28 00:56:41,700:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-28 00:56:41,700:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-28 00:56:41,700:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-28 00:56:42,258:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-28 00:56:44,900:INFO:PyCaret RegressionExperiment
2023-02-28 00:56:44,900:INFO:Logging name: reg-default-name
2023-02-28 00:56:44,900:INFO:ML Usecase: MLUsecase.REGRESSION
2023-02-28 00:56:44,903:INFO:version 3.0.0.rc9
2023-02-28 00:56:44,903:INFO:Initializing setup()
2023-02-28 00:56:44,903:INFO:self.USI: 8b11
2023-02-28 00:56:44,903:INFO:self._variable_keys: {'transform_target_param', 'log_plots_param', 'X_test', 'gpu_n_jobs_param', '_ml_usecase', 'memory', 'data', 'seed', 'y', 'y_test', 'X', 'fold_generator', 'fold_shuffle_param', 'target_param', 'n_jobs_param', 'y_train', 'exp_id', 'logging_param', 'idx', '_available_plots', 'USI', 'X_train', 'fold_groups_param', 'pipeline', 'html_param', 'gpu_param', 'exp_name_log'}
2023-02-28 00:56:44,903:INFO:Checking environment
2023-02-28 00:56:44,903:INFO:python_version: 3.8.16
2023-02-28 00:56:44,903:INFO:python_build: ('default', 'Jan 17 2023 22:25:28')
2023-02-28 00:56:44,903:INFO:machine: AMD64
2023-02-28 00:56:44,903:INFO:platform: Windows-10-10.0.22621-SP0
2023-02-28 00:56:44,930:INFO:Memory: svmem(total=14702026752, available=4298760192, percent=70.8, used=10403266560, free=4298760192)
2023-02-28 00:56:44,930:INFO:Physical Core: 8
2023-02-28 00:56:44,930:INFO:Logical Core: 16
2023-02-28 00:56:44,936:INFO:Checking libraries
2023-02-28 00:56:44,936:INFO:System:
2023-02-28 00:56:44,936:INFO:    python: 3.8.16 (default, Jan 17 2023, 22:25:28) [MSC v.1916 64 bit (AMD64)]
2023-02-28 00:56:44,936:INFO:executable: c:\Users\takis\anaconda3\envs\caretenv\python.exe
2023-02-28 00:56:44,936:INFO:   machine: Windows-10-10.0.22621-SP0
2023-02-28 00:56:44,936:INFO:PyCaret required dependencies:
2023-02-28 00:56:44,936:INFO:                 pip: 22.3.1
2023-02-28 00:56:44,936:INFO:          setuptools: 60.10.0
2023-02-28 00:56:44,936:INFO:             pycaret: 3.0.0rc9
2023-02-28 00:56:44,936:INFO:             IPython: 8.10.0
2023-02-28 00:56:44,936:INFO:          ipywidgets: 8.0.4
2023-02-28 00:56:44,936:INFO:                tqdm: 4.64.1
2023-02-28 00:56:44,936:INFO:               numpy: 1.23.5
2023-02-28 00:56:44,936:INFO:              pandas: 1.5.3
2023-02-28 00:56:44,936:INFO:              jinja2: 3.1.2
2023-02-28 00:56:44,936:INFO:               scipy: 1.10.1
2023-02-28 00:56:44,936:INFO:              joblib: 1.2.0
2023-02-28 00:56:44,936:INFO:             sklearn: 1.2.1
2023-02-28 00:56:44,936:INFO:                pyod: 1.0.7
2023-02-28 00:56:44,936:INFO:            imblearn: 0.10.1
2023-02-28 00:56:44,936:INFO:   category_encoders: 2.6.0
2023-02-28 00:56:44,936:INFO:            lightgbm: 3.3.5
2023-02-28 00:56:44,936:INFO:               numba: 0.56.4
2023-02-28 00:56:44,936:INFO:            requests: 2.28.2
2023-02-28 00:56:44,936:INFO:          matplotlib: 3.7.0
2023-02-28 00:56:44,936:INFO:          scikitplot: 0.3.7
2023-02-28 00:56:44,936:INFO:         yellowbrick: 1.5
2023-02-28 00:56:44,936:INFO:              plotly: 5.13.1
2023-02-28 00:56:44,936:INFO:             kaleido: 0.2.1
2023-02-28 00:56:44,936:INFO:         statsmodels: 0.13.5
2023-02-28 00:56:44,936:INFO:              sktime: 0.16.1
2023-02-28 00:56:44,938:INFO:               tbats: 1.1.2
2023-02-28 00:56:44,938:INFO:            pmdarima: 2.0.2
2023-02-28 00:56:44,938:INFO:              psutil: 5.9.4
2023-02-28 00:56:44,938:INFO:PyCaret optional dependencies:
2023-02-28 00:56:46,887:INFO:                shap: Not installed
2023-02-28 00:56:46,887:INFO:           interpret: Not installed
2023-02-28 00:56:46,887:INFO:                umap: Not installed
2023-02-28 00:56:46,887:INFO:    pandas_profiling: Not installed
2023-02-28 00:56:46,887:INFO:  explainerdashboard: Not installed
2023-02-28 00:56:46,887:INFO:             autoviz: 0.1.58
2023-02-28 00:56:46,887:INFO:           fairlearn: Not installed
2023-02-28 00:56:46,887:INFO:             xgboost: 1.7.4
2023-02-28 00:56:46,887:INFO:            catboost: Not installed
2023-02-28 00:56:46,887:INFO:              kmodes: Not installed
2023-02-28 00:56:46,887:INFO:             mlxtend: Not installed
2023-02-28 00:56:46,887:INFO:       statsforecast: Not installed
2023-02-28 00:56:46,887:INFO:        tune_sklearn: Not installed
2023-02-28 00:56:46,887:INFO:                 ray: Not installed
2023-02-28 00:56:46,887:INFO:            hyperopt: Not installed
2023-02-28 00:56:46,887:INFO:              optuna: Not installed
2023-02-28 00:56:46,887:INFO:               skopt: Not installed
2023-02-28 00:56:46,887:INFO:              mlflow: 1.30.0
2023-02-28 00:56:46,887:INFO:              gradio: 3.19.1
2023-02-28 00:56:46,887:INFO:             fastapi: 0.92.0
2023-02-28 00:56:46,887:INFO:             uvicorn: 0.20.0
2023-02-28 00:56:46,887:INFO:              m2cgen: 0.10.0
2023-02-28 00:56:46,887:INFO:           evidently: 0.2.5
2023-02-28 00:56:46,887:INFO:               fugue: Not installed
2023-02-28 00:56:46,887:INFO:           streamlit: Not installed
2023-02-28 00:56:46,887:INFO:             prophet: Not installed
2023-02-28 00:56:46,887:INFO:None
2023-02-28 00:56:46,887:INFO:Set up data.
2023-02-28 00:56:46,902:INFO:Set up train/test split.
2023-02-28 00:56:46,902:INFO:Set up index.
2023-02-28 00:56:46,902:INFO:Set up folding strategy.
2023-02-28 00:56:46,902:INFO:Assigning column types.
2023-02-28 00:56:46,902:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-28 00:56:46,910:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-28 00:56:46,910:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-28 00:56:46,918:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 00:56:46,985:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 00:56:47,041:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 00:56:47,041:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 00:56:47,107:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:56:47,107:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-28 00:56:47,107:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-28 00:56:47,115:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 00:56:47,172:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 00:56:47,221:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 00:56:47,221:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 00:56:47,221:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:56:47,221:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-02-28 00:56:47,232:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-28 00:56:47,237:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 00:56:47,294:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 00:56:47,335:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 00:56:47,343:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 00:56:47,344:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:56:47,350:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-28 00:56:47,350:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 00:56:47,407:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 00:56:47,451:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 00:56:47,451:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 00:56:47,451:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:56:47,451:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-02-28 00:56:47,455:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 00:56:47,507:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 00:56:47,554:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 00:56:47,554:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 00:56:47,554:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:56:47,565:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 00:56:47,619:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 00:56:47,661:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 00:56:47,661:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 00:56:47,667:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:56:47,667:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-02-28 00:56:47,731:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 00:56:47,771:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 00:56:47,771:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 00:56:47,771:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:56:47,835:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 00:56:47,877:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 00:56:47,877:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 00:56:47,882:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:56:47,882:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-28 00:56:47,934:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 00:56:47,982:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 00:56:47,983:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:56:48,040:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 00:56:48,084:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 00:56:48,084:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:56:48,084:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-02-28 00:56:48,187:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 00:56:48,187:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:56:48,292:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 00:56:48,292:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:56:48,302:INFO:Preparing preprocessing pipeline...
2023-02-28 00:56:48,302:INFO:Set up simple imputation.
2023-02-28 00:56:48,302:INFO:Set up encoding of ordinal features.
2023-02-28 00:56:48,302:INFO:Set up encoding of categorical features.
2023-02-28 00:56:48,402:INFO:Finished creating preprocessing pipeline.
2023-02-28 00:56:48,430:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\takis\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                     'smoker'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64},
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-02-28 00:56:48,430:INFO:Creating final display dataframe.
2023-02-28 00:56:48,788:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           charges
2                   Target type        Regression
3           Original data shape         (1338, 7)
4        Transformed data shape        (1338, 10)
5   Transformed train set shape         (936, 10)
6    Transformed test set shape         (402, 10)
7              Ordinal features                 2
8              Numeric features                 3
9          Categorical features                 3
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              8b11
2023-02-28 00:56:48,905:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 00:56:48,905:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:56:49,010:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 00:56:49,010:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 00:56:49,010:INFO:setup() successfully completed in 4.11s...............
2023-02-28 00:56:52,399:INFO:Soft dependency imported: autoviz: 0.1.58
2023-02-28 00:56:57,968:INFO:Soft dependency imported: autoviz: 0.1.58
2023-02-28 01:01:06,969:INFO:Initializing get_config()
2023-02-28 01:01:06,969:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, variable=None)
2023-02-28 01:02:33,208:INFO:Initializing get_config()
2023-02-28 01:02:33,208:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, variable=X_train)
2023-02-28 01:02:33,208:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2023-02-28 01:02:33,224:INFO:Variable:  returned as      age     sex        bmi  children smoker     region
0     36    male  27.549999         3     no  northeast
1     60  female  35.099998         0     no  southwest
2     30    male  31.570000         3     no  southeast
3     49    male  25.600000         2    yes  southwest
4     26    male  32.900002         2    yes  southwest
..   ...     ...        ...       ...    ...        ...
931   37    male  22.705000         3     no  northeast
932   20  female  31.920000         0     no  northwest
933   19  female  28.400000         1     no  southwest
934   18    male  23.084999         0     no  northeast
935   53  female  36.860001         3    yes  northwest

[936 rows x 6 columns]
2023-02-28 01:02:33,224:INFO:get_config() successfully completed......................................
2023-02-28 01:02:48,220:INFO:Initializing get_config()
2023-02-28 01:02:48,220:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, variable=X_train)
2023-02-28 01:02:48,220:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2023-02-28 01:02:48,231:INFO:Variable:  returned as      age     sex        bmi  children smoker     region
0     36    male  27.549999         3     no  northeast
1     60  female  35.099998         0     no  southwest
2     30    male  31.570000         3     no  southeast
3     49    male  25.600000         2    yes  southwest
4     26    male  32.900002         2    yes  southwest
..   ...     ...        ...       ...    ...        ...
931   37    male  22.705000         3     no  northeast
932   20  female  31.920000         0     no  northwest
933   19  female  28.400000         1     no  southwest
934   18    male  23.084999         0     no  northeast
935   53  female  36.860001         3    yes  northwest

[936 rows x 6 columns]
2023-02-28 01:02:48,232:INFO:get_config() successfully completed......................................
2023-02-28 01:04:14,234:INFO:Initializing get_config()
2023-02-28 01:04:14,234:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, variable=None)
2023-02-28 01:05:09,578:INFO:Initializing get_config()
2023-02-28 01:05:09,578:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, variable=USI)
2023-02-28 01:05:09,578:INFO:Variable:  returned as 8b11
2023-02-28 01:05:09,578:INFO:get_config() successfully completed......................................
2023-02-28 01:06:54,983:INFO:Initializing get_config()
2023-02-28 01:06:54,984:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, variable=None)
2023-02-28 01:09:53,116:INFO:Initializing get_config()
2023-02-28 01:09:53,117:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, variable=prep_pipe)
2023-02-28 01:10:19,440:INFO:Initializing get_config()
2023-02-28 01:10:19,440:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, variable=variable_and_property_keys)
2023-02-28 01:10:19,440:INFO:Variable: variable_and_p returned as {'train', 'transform_target_param', 'y_train_transformed', 'gpu_n_jobs_param', '_ml_usecase', 'data', 'seed', 'y', 'y_test', 'X', 'y_transformed', 'target_param', 'y_test_transformed', 'exp_id', 'logging_param', 'idx', 'exp_name_log', 'test_transformed', 'USI', 'X_train', 'variables', 'pipeline', 'test', 'html_param', 'gpu_param', 'X_train_transformed', 'variable_and_property_keys', 'log_plots_param', 'X_test', 'memory', 'X_test_transformed', 'X_transformed', 'fold_generator', 'fold_shuffle_param', 'n_jobs_param', 'y_train', 'dataset', 'train_transformed', 'fold_groups_param', 'dataset_transformed', 'is_multiclass', '_available_plots'}
2023-02-28 01:10:19,440:INFO:get_config() successfully completed......................................
2023-02-28 01:10:34,787:INFO:Initializing get_config()
2023-02-28 01:10:34,787:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, variable=pipeline)
2023-02-28 01:10:34,847:INFO:Variable:  returned as Pipeline(memory=FastMemory(location=C:\Users\takis\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                     'smoker'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64},
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-02-28 01:10:34,849:INFO:get_config() successfully completed......................................
2023-02-28 01:11:22,011:INFO:Initializing get_config()
2023-02-28 01:11:22,011:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, variable=html_param)
2023-02-28 01:11:22,011:INFO:Variable:  returned as True
2023-02-28 01:11:22,011:INFO:get_config() successfully completed......................................
2023-02-28 01:11:32,030:INFO:Initializing get_config()
2023-02-28 01:11:32,030:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, variable=idx)
2023-02-28 01:11:32,033:INFO:Variable:  returned as [RangeIndex(start=0, stop=936, step=1), RangeIndex(start=936, stop=1338, step=1)]
2023-02-28 01:11:32,033:INFO:get_config() successfully completed......................................
2023-02-28 01:11:47,258:INFO:Initializing get_config()
2023-02-28 01:11:47,258:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, variable=logging_param)
2023-02-28 01:11:47,261:INFO:Variable: l returned as False
2023-02-28 01:11:47,261:INFO:get_config() successfully completed......................................
2023-02-28 01:12:07,380:INFO:Initializing get_config()
2023-02-28 01:12:07,380:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, variable=target_param)
2023-02-28 01:12:07,385:INFO:Variable:  returned as charges
2023-02-28 01:12:07,385:INFO:get_config() successfully completed......................................
2023-02-28 01:12:28,747:INFO:Initializing get_config()
2023-02-28 01:12:28,747:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, variable=exp_name_log)
2023-02-28 01:12:28,747:INFO:Variable:  returned as reg-default-name
2023-02-28 01:12:28,747:INFO:get_config() successfully completed......................................
2023-02-28 01:14:10,919:INFO:Initializing set_config()
2023-02-28 01:14:10,919:INFO:set_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, variable=exp_name_log, value=insurance_data, kwargs={})
2023-02-28 01:14:10,919:INFO:Global variable: exp_name_log updated to insurance_data
2023-02-28 01:14:10,919:INFO:set_config() successfully completed......................................
2023-02-28 01:14:14,198:INFO:Initializing get_config()
2023-02-28 01:14:14,198:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, variable=exp_name_log)
2023-02-28 01:14:14,198:INFO:Variable:  returned as insurance_data
2023-02-28 01:14:14,198:INFO:get_config() successfully completed......................................
2023-02-28 01:14:37,685:INFO:Initializing set_config()
2023-02-28 01:14:37,685:INFO:set_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, variable=logging_param, value=True, kwargs={})
2023-02-28 01:14:37,689:INFO:Global variable: logging_param updated to True
2023-02-28 01:14:37,689:INFO:set_config() successfully completed......................................
2023-02-28 01:14:40,901:INFO:Initializing get_config()
2023-02-28 01:14:40,901:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, variable=logging_param)
2023-02-28 01:14:40,902:INFO:Variable: l returned as True
2023-02-28 01:14:40,902:INFO:get_config() successfully completed......................................
2023-02-28 01:15:27,958:INFO:Initializing get_config()
2023-02-28 01:15:27,959:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, variable=_ml_usecase)
2023-02-28 01:15:27,959:INFO:Variable:  returned as MLUsecase.REGRESSION
2023-02-28 01:15:27,959:INFO:get_config() successfully completed......................................
2023-02-28 01:17:29,151:INFO:Initializing compare_models()
2023-02-28 01:17:29,151:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-02-28 01:17:29,151:INFO:Checking exceptions
2023-02-28 01:17:29,157:INFO:Preparing display monitor
2023-02-28 01:17:29,212:INFO:Initializing Linear Regression
2023-02-28 01:17:29,212:INFO:Total runtime is 0.0 minutes
2023-02-28 01:17:29,217:INFO:SubProcess create_model() called ==================================
2023-02-28 01:17:29,219:INFO:Initializing create_model()
2023-02-28 01:17:29,219:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03C674C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:17:29,219:INFO:Checking exceptions
2023-02-28 01:17:29,219:INFO:Importing libraries
2023-02-28 01:17:29,219:INFO:Copying training dataset
2023-02-28 01:17:29,225:INFO:Defining folds
2023-02-28 01:17:29,225:INFO:Declaring metric variables
2023-02-28 01:17:29,233:INFO:Importing untrained model
2023-02-28 01:17:29,242:INFO:Linear Regression Imported successfully
2023-02-28 01:17:29,256:INFO:Starting cross validation
2023-02-28 01:17:29,266:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:17:36,170:INFO:Calculating mean and std
2023-02-28 01:17:36,170:INFO:Creating metrics dataframe
2023-02-28 01:17:36,188:INFO:Uploading results into container
2023-02-28 01:17:36,190:INFO:Uploading model into container now
2023-02-28 01:17:36,190:INFO:_master_model_container: 1
2023-02-28 01:17:36,190:INFO:_display_container: 2
2023-02-28 01:17:36,192:INFO:LinearRegression(n_jobs=-1)
2023-02-28 01:17:36,192:INFO:create_model() successfully completed......................................
2023-02-28 01:17:36,457:INFO:SubProcess create_model() end ==================================
2023-02-28 01:17:36,457:INFO:Creating metrics dataframe
2023-02-28 01:17:36,465:INFO:Initializing Lasso Regression
2023-02-28 01:17:36,465:INFO:Total runtime is 0.12089373668034871 minutes
2023-02-28 01:17:36,473:INFO:SubProcess create_model() called ==================================
2023-02-28 01:17:36,473:INFO:Initializing create_model()
2023-02-28 01:17:36,473:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03C674C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:17:36,475:INFO:Checking exceptions
2023-02-28 01:17:36,475:INFO:Importing libraries
2023-02-28 01:17:36,475:INFO:Copying training dataset
2023-02-28 01:17:36,477:INFO:Defining folds
2023-02-28 01:17:36,477:INFO:Declaring metric variables
2023-02-28 01:17:36,481:INFO:Importing untrained model
2023-02-28 01:17:36,489:INFO:Lasso Regression Imported successfully
2023-02-28 01:17:36,494:INFO:Starting cross validation
2023-02-28 01:17:36,498:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:17:39,757:INFO:Calculating mean and std
2023-02-28 01:17:39,765:INFO:Creating metrics dataframe
2023-02-28 01:17:39,768:INFO:Uploading results into container
2023-02-28 01:17:39,772:INFO:Uploading model into container now
2023-02-28 01:17:39,772:INFO:_master_model_container: 2
2023-02-28 01:17:39,772:INFO:_display_container: 2
2023-02-28 01:17:39,772:INFO:Lasso(random_state=123)
2023-02-28 01:17:39,772:INFO:create_model() successfully completed......................................
2023-02-28 01:17:40,019:INFO:SubProcess create_model() end ==================================
2023-02-28 01:17:40,019:INFO:Creating metrics dataframe
2023-02-28 01:17:40,027:INFO:Initializing Ridge Regression
2023-02-28 01:17:40,027:INFO:Total runtime is 0.1802619179089864 minutes
2023-02-28 01:17:40,027:INFO:SubProcess create_model() called ==================================
2023-02-28 01:17:40,027:INFO:Initializing create_model()
2023-02-28 01:17:40,027:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03C674C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:17:40,027:INFO:Checking exceptions
2023-02-28 01:17:40,027:INFO:Importing libraries
2023-02-28 01:17:40,027:INFO:Copying training dataset
2023-02-28 01:17:40,040:INFO:Defining folds
2023-02-28 01:17:40,040:INFO:Declaring metric variables
2023-02-28 01:17:40,044:INFO:Importing untrained model
2023-02-28 01:17:40,046:INFO:Ridge Regression Imported successfully
2023-02-28 01:17:40,057:INFO:Starting cross validation
2023-02-28 01:17:40,058:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:17:40,376:INFO:Calculating mean and std
2023-02-28 01:17:40,376:INFO:Creating metrics dataframe
2023-02-28 01:17:40,380:INFO:Uploading results into container
2023-02-28 01:17:40,380:INFO:Uploading model into container now
2023-02-28 01:17:40,382:INFO:_master_model_container: 3
2023-02-28 01:17:40,382:INFO:_display_container: 2
2023-02-28 01:17:40,382:INFO:Ridge(random_state=123)
2023-02-28 01:17:40,382:INFO:create_model() successfully completed......................................
2023-02-28 01:17:40,623:INFO:SubProcess create_model() end ==================================
2023-02-28 01:17:40,623:INFO:Creating metrics dataframe
2023-02-28 01:17:40,636:INFO:Initializing Elastic Net
2023-02-28 01:17:40,636:INFO:Total runtime is 0.19040100574493407 minutes
2023-02-28 01:17:40,640:INFO:SubProcess create_model() called ==================================
2023-02-28 01:17:40,640:INFO:Initializing create_model()
2023-02-28 01:17:40,640:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03C674C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:17:40,640:INFO:Checking exceptions
2023-02-28 01:17:40,640:INFO:Importing libraries
2023-02-28 01:17:40,640:INFO:Copying training dataset
2023-02-28 01:17:40,642:INFO:Defining folds
2023-02-28 01:17:40,642:INFO:Declaring metric variables
2023-02-28 01:17:40,649:INFO:Importing untrained model
2023-02-28 01:17:40,652:INFO:Elastic Net Imported successfully
2023-02-28 01:17:40,658:INFO:Starting cross validation
2023-02-28 01:17:40,662:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:17:41,028:INFO:Calculating mean and std
2023-02-28 01:17:41,028:INFO:Creating metrics dataframe
2023-02-28 01:17:41,028:INFO:Uploading results into container
2023-02-28 01:17:41,028:INFO:Uploading model into container now
2023-02-28 01:17:41,028:INFO:_master_model_container: 4
2023-02-28 01:17:41,028:INFO:_display_container: 2
2023-02-28 01:17:41,028:INFO:ElasticNet(random_state=123)
2023-02-28 01:17:41,028:INFO:create_model() successfully completed......................................
2023-02-28 01:17:41,270:INFO:SubProcess create_model() end ==================================
2023-02-28 01:17:41,270:INFO:Creating metrics dataframe
2023-02-28 01:17:41,279:INFO:Initializing Least Angle Regression
2023-02-28 01:17:41,279:INFO:Total runtime is 0.20113004048665364 minutes
2023-02-28 01:17:41,279:INFO:SubProcess create_model() called ==================================
2023-02-28 01:17:41,279:INFO:Initializing create_model()
2023-02-28 01:17:41,279:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03C674C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:17:41,279:INFO:Checking exceptions
2023-02-28 01:17:41,279:INFO:Importing libraries
2023-02-28 01:17:41,279:INFO:Copying training dataset
2023-02-28 01:17:41,289:INFO:Defining folds
2023-02-28 01:17:41,289:INFO:Declaring metric variables
2023-02-28 01:17:41,298:INFO:Importing untrained model
2023-02-28 01:17:41,303:INFO:Least Angle Regression Imported successfully
2023-02-28 01:17:41,312:INFO:Starting cross validation
2023-02-28 01:17:41,320:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:17:41,675:INFO:Calculating mean and std
2023-02-28 01:17:41,684:INFO:Creating metrics dataframe
2023-02-28 01:17:41,687:INFO:Uploading results into container
2023-02-28 01:17:41,687:INFO:Uploading model into container now
2023-02-28 01:17:41,687:INFO:_master_model_container: 5
2023-02-28 01:17:41,687:INFO:_display_container: 2
2023-02-28 01:17:41,687:INFO:Lars(random_state=123)
2023-02-28 01:17:41,687:INFO:create_model() successfully completed......................................
2023-02-28 01:17:41,937:INFO:SubProcess create_model() end ==================================
2023-02-28 01:17:41,937:INFO:Creating metrics dataframe
2023-02-28 01:17:41,943:INFO:Initializing Lasso Least Angle Regression
2023-02-28 01:17:41,943:INFO:Total runtime is 0.21218156814575195 minutes
2023-02-28 01:17:41,952:INFO:SubProcess create_model() called ==================================
2023-02-28 01:17:41,952:INFO:Initializing create_model()
2023-02-28 01:17:41,952:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03C674C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:17:41,952:INFO:Checking exceptions
2023-02-28 01:17:41,952:INFO:Importing libraries
2023-02-28 01:17:41,952:INFO:Copying training dataset
2023-02-28 01:17:41,962:INFO:Defining folds
2023-02-28 01:17:41,962:INFO:Declaring metric variables
2023-02-28 01:17:41,970:INFO:Importing untrained model
2023-02-28 01:17:41,975:INFO:Lasso Least Angle Regression Imported successfully
2023-02-28 01:17:41,989:INFO:Starting cross validation
2023-02-28 01:17:41,992:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:17:42,387:INFO:Calculating mean and std
2023-02-28 01:17:42,388:INFO:Creating metrics dataframe
2023-02-28 01:17:42,388:INFO:Uploading results into container
2023-02-28 01:17:42,388:INFO:Uploading model into container now
2023-02-28 01:17:42,388:INFO:_master_model_container: 6
2023-02-28 01:17:42,388:INFO:_display_container: 2
2023-02-28 01:17:42,388:INFO:LassoLars(random_state=123)
2023-02-28 01:17:42,388:INFO:create_model() successfully completed......................................
2023-02-28 01:17:42,640:INFO:SubProcess create_model() end ==================================
2023-02-28 01:17:42,640:INFO:Creating metrics dataframe
2023-02-28 01:17:42,657:INFO:Initializing Orthogonal Matching Pursuit
2023-02-28 01:17:42,657:INFO:Total runtime is 0.22408252954483032 minutes
2023-02-28 01:17:42,665:INFO:SubProcess create_model() called ==================================
2023-02-28 01:17:42,665:INFO:Initializing create_model()
2023-02-28 01:17:42,665:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03C674C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:17:42,665:INFO:Checking exceptions
2023-02-28 01:17:42,665:INFO:Importing libraries
2023-02-28 01:17:42,665:INFO:Copying training dataset
2023-02-28 01:17:42,673:INFO:Defining folds
2023-02-28 01:17:42,673:INFO:Declaring metric variables
2023-02-28 01:17:42,681:INFO:Importing untrained model
2023-02-28 01:17:42,689:INFO:Orthogonal Matching Pursuit Imported successfully
2023-02-28 01:17:42,697:INFO:Starting cross validation
2023-02-28 01:17:42,700:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:17:43,004:INFO:Calculating mean and std
2023-02-28 01:17:43,004:INFO:Creating metrics dataframe
2023-02-28 01:17:43,013:INFO:Uploading results into container
2023-02-28 01:17:43,013:INFO:Uploading model into container now
2023-02-28 01:17:43,013:INFO:_master_model_container: 7
2023-02-28 01:17:43,013:INFO:_display_container: 2
2023-02-28 01:17:43,013:INFO:OrthogonalMatchingPursuit()
2023-02-28 01:17:43,013:INFO:create_model() successfully completed......................................
2023-02-28 01:17:43,246:INFO:SubProcess create_model() end ==================================
2023-02-28 01:17:43,246:INFO:Creating metrics dataframe
2023-02-28 01:17:43,254:INFO:Initializing Bayesian Ridge
2023-02-28 01:17:43,254:INFO:Total runtime is 0.23404055436452229 minutes
2023-02-28 01:17:43,262:INFO:SubProcess create_model() called ==================================
2023-02-28 01:17:43,262:INFO:Initializing create_model()
2023-02-28 01:17:43,262:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03C674C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:17:43,263:INFO:Checking exceptions
2023-02-28 01:17:43,263:INFO:Importing libraries
2023-02-28 01:17:43,263:INFO:Copying training dataset
2023-02-28 01:17:43,269:INFO:Defining folds
2023-02-28 01:17:43,269:INFO:Declaring metric variables
2023-02-28 01:17:43,275:INFO:Importing untrained model
2023-02-28 01:17:43,278:INFO:Bayesian Ridge Imported successfully
2023-02-28 01:17:43,289:INFO:Starting cross validation
2023-02-28 01:17:43,289:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:17:43,608:INFO:Calculating mean and std
2023-02-28 01:17:43,616:INFO:Creating metrics dataframe
2023-02-28 01:17:43,619:INFO:Uploading results into container
2023-02-28 01:17:43,622:INFO:Uploading model into container now
2023-02-28 01:17:43,622:INFO:_master_model_container: 8
2023-02-28 01:17:43,622:INFO:_display_container: 2
2023-02-28 01:17:43,624:INFO:BayesianRidge()
2023-02-28 01:17:43,624:INFO:create_model() successfully completed......................................
2023-02-28 01:17:43,855:INFO:SubProcess create_model() end ==================================
2023-02-28 01:17:43,855:INFO:Creating metrics dataframe
2023-02-28 01:17:43,870:INFO:Initializing Passive Aggressive Regressor
2023-02-28 01:17:43,870:INFO:Total runtime is 0.24431261618932087 minutes
2023-02-28 01:17:43,875:INFO:SubProcess create_model() called ==================================
2023-02-28 01:17:43,876:INFO:Initializing create_model()
2023-02-28 01:17:43,876:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03C674C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:17:43,876:INFO:Checking exceptions
2023-02-28 01:17:43,876:INFO:Importing libraries
2023-02-28 01:17:43,876:INFO:Copying training dataset
2023-02-28 01:17:43,879:INFO:Defining folds
2023-02-28 01:17:43,879:INFO:Declaring metric variables
2023-02-28 01:17:43,884:INFO:Importing untrained model
2023-02-28 01:17:43,888:INFO:Passive Aggressive Regressor Imported successfully
2023-02-28 01:17:43,892:INFO:Starting cross validation
2023-02-28 01:17:43,895:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:17:44,177:INFO:Calculating mean and std
2023-02-28 01:17:44,177:INFO:Creating metrics dataframe
2023-02-28 01:17:44,186:INFO:Uploading results into container
2023-02-28 01:17:44,186:INFO:Uploading model into container now
2023-02-28 01:17:44,186:INFO:_master_model_container: 9
2023-02-28 01:17:44,186:INFO:_display_container: 2
2023-02-28 01:17:44,186:INFO:PassiveAggressiveRegressor(random_state=123)
2023-02-28 01:17:44,186:INFO:create_model() successfully completed......................................
2023-02-28 01:17:44,404:INFO:SubProcess create_model() end ==================================
2023-02-28 01:17:44,404:INFO:Creating metrics dataframe
2023-02-28 01:17:44,412:INFO:Initializing Huber Regressor
2023-02-28 01:17:44,412:INFO:Total runtime is 0.2533372163772583 minutes
2023-02-28 01:17:44,420:INFO:SubProcess create_model() called ==================================
2023-02-28 01:17:44,420:INFO:Initializing create_model()
2023-02-28 01:17:44,420:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03C674C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:17:44,420:INFO:Checking exceptions
2023-02-28 01:17:44,420:INFO:Importing libraries
2023-02-28 01:17:44,420:INFO:Copying training dataset
2023-02-28 01:17:44,422:INFO:Defining folds
2023-02-28 01:17:44,422:INFO:Declaring metric variables
2023-02-28 01:17:44,429:INFO:Importing untrained model
2023-02-28 01:17:44,430:INFO:Huber Regressor Imported successfully
2023-02-28 01:17:44,440:INFO:Starting cross validation
2023-02-28 01:17:44,441:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:17:44,654:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:17:44,662:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:17:44,670:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:17:44,694:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:17:44,714:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:17:44,714:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:17:44,728:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:17:44,737:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:17:44,737:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:17:44,792:INFO:Calculating mean and std
2023-02-28 01:17:44,799:INFO:Creating metrics dataframe
2023-02-28 01:17:44,799:INFO:Uploading results into container
2023-02-28 01:17:44,804:INFO:Uploading model into container now
2023-02-28 01:17:44,804:INFO:_master_model_container: 10
2023-02-28 01:17:44,804:INFO:_display_container: 2
2023-02-28 01:17:44,804:INFO:HuberRegressor()
2023-02-28 01:17:44,804:INFO:create_model() successfully completed......................................
2023-02-28 01:17:45,019:INFO:SubProcess create_model() end ==================================
2023-02-28 01:17:45,027:INFO:Creating metrics dataframe
2023-02-28 01:17:45,038:INFO:Initializing K Neighbors Regressor
2023-02-28 01:17:45,038:INFO:Total runtime is 0.26376721064249675 minutes
2023-02-28 01:17:45,043:INFO:SubProcess create_model() called ==================================
2023-02-28 01:17:45,045:INFO:Initializing create_model()
2023-02-28 01:17:45,045:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03C674C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:17:45,045:INFO:Checking exceptions
2023-02-28 01:17:45,045:INFO:Importing libraries
2023-02-28 01:17:45,045:INFO:Copying training dataset
2023-02-28 01:17:45,046:INFO:Defining folds
2023-02-28 01:17:45,046:INFO:Declaring metric variables
2023-02-28 01:17:45,052:INFO:Importing untrained model
2023-02-28 01:17:45,056:INFO:K Neighbors Regressor Imported successfully
2023-02-28 01:17:45,062:INFO:Starting cross validation
2023-02-28 01:17:45,068:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:17:45,387:INFO:Calculating mean and std
2023-02-28 01:17:45,387:INFO:Creating metrics dataframe
2023-02-28 01:17:45,392:INFO:Uploading results into container
2023-02-28 01:17:45,392:INFO:Uploading model into container now
2023-02-28 01:17:45,392:INFO:_master_model_container: 11
2023-02-28 01:17:45,392:INFO:_display_container: 2
2023-02-28 01:17:45,392:INFO:KNeighborsRegressor(n_jobs=-1)
2023-02-28 01:17:45,392:INFO:create_model() successfully completed......................................
2023-02-28 01:17:45,614:INFO:SubProcess create_model() end ==================================
2023-02-28 01:17:45,614:INFO:Creating metrics dataframe
2023-02-28 01:17:45,622:INFO:Initializing Decision Tree Regressor
2023-02-28 01:17:45,622:INFO:Total runtime is 0.2735086957613627 minutes
2023-02-28 01:17:45,631:INFO:SubProcess create_model() called ==================================
2023-02-28 01:17:45,631:INFO:Initializing create_model()
2023-02-28 01:17:45,631:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03C674C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:17:45,631:INFO:Checking exceptions
2023-02-28 01:17:45,631:INFO:Importing libraries
2023-02-28 01:17:45,631:INFO:Copying training dataset
2023-02-28 01:17:45,639:INFO:Defining folds
2023-02-28 01:17:45,644:INFO:Declaring metric variables
2023-02-28 01:17:45,647:INFO:Importing untrained model
2023-02-28 01:17:45,652:INFO:Decision Tree Regressor Imported successfully
2023-02-28 01:17:45,661:INFO:Starting cross validation
2023-02-28 01:17:45,663:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:17:45,980:INFO:Calculating mean and std
2023-02-28 01:17:45,989:INFO:Creating metrics dataframe
2023-02-28 01:17:45,992:INFO:Uploading results into container
2023-02-28 01:17:45,992:INFO:Uploading model into container now
2023-02-28 01:17:45,992:INFO:_master_model_container: 12
2023-02-28 01:17:45,992:INFO:_display_container: 2
2023-02-28 01:17:45,992:INFO:DecisionTreeRegressor(random_state=123)
2023-02-28 01:17:45,992:INFO:create_model() successfully completed......................................
2023-02-28 01:17:46,207:INFO:SubProcess create_model() end ==================================
2023-02-28 01:17:46,215:INFO:Creating metrics dataframe
2023-02-28 01:17:46,223:INFO:Initializing Random Forest Regressor
2023-02-28 01:17:46,223:INFO:Total runtime is 0.2835225383440654 minutes
2023-02-28 01:17:46,226:INFO:SubProcess create_model() called ==================================
2023-02-28 01:17:46,226:INFO:Initializing create_model()
2023-02-28 01:17:46,226:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03C674C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:17:46,226:INFO:Checking exceptions
2023-02-28 01:17:46,230:INFO:Importing libraries
2023-02-28 01:17:46,230:INFO:Copying training dataset
2023-02-28 01:17:46,233:INFO:Defining folds
2023-02-28 01:17:46,233:INFO:Declaring metric variables
2023-02-28 01:17:46,233:INFO:Importing untrained model
2023-02-28 01:17:46,241:INFO:Random Forest Regressor Imported successfully
2023-02-28 01:17:46,249:INFO:Starting cross validation
2023-02-28 01:17:46,249:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:17:47,189:INFO:Calculating mean and std
2023-02-28 01:17:47,192:INFO:Creating metrics dataframe
2023-02-28 01:17:47,192:INFO:Uploading results into container
2023-02-28 01:17:47,192:INFO:Uploading model into container now
2023-02-28 01:17:47,192:INFO:_master_model_container: 13
2023-02-28 01:17:47,192:INFO:_display_container: 2
2023-02-28 01:17:47,192:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-02-28 01:17:47,192:INFO:create_model() successfully completed......................................
2023-02-28 01:17:47,411:INFO:SubProcess create_model() end ==================================
2023-02-28 01:17:47,411:INFO:Creating metrics dataframe
2023-02-28 01:17:47,428:INFO:Initializing Extra Trees Regressor
2023-02-28 01:17:47,428:INFO:Total runtime is 0.3036017855008443 minutes
2023-02-28 01:17:47,433:INFO:SubProcess create_model() called ==================================
2023-02-28 01:17:47,433:INFO:Initializing create_model()
2023-02-28 01:17:47,433:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03C674C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:17:47,434:INFO:Checking exceptions
2023-02-28 01:17:47,434:INFO:Importing libraries
2023-02-28 01:17:47,434:INFO:Copying training dataset
2023-02-28 01:17:47,437:INFO:Defining folds
2023-02-28 01:17:47,437:INFO:Declaring metric variables
2023-02-28 01:17:47,443:INFO:Importing untrained model
2023-02-28 01:17:47,457:INFO:Extra Trees Regressor Imported successfully
2023-02-28 01:17:47,464:INFO:Starting cross validation
2023-02-28 01:17:47,466:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:17:48,291:INFO:Calculating mean and std
2023-02-28 01:17:48,291:INFO:Creating metrics dataframe
2023-02-28 01:17:48,299:INFO:Uploading results into container
2023-02-28 01:17:48,299:INFO:Uploading model into container now
2023-02-28 01:17:48,299:INFO:_master_model_container: 14
2023-02-28 01:17:48,299:INFO:_display_container: 2
2023-02-28 01:17:48,299:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-02-28 01:17:48,299:INFO:create_model() successfully completed......................................
2023-02-28 01:17:48,511:INFO:SubProcess create_model() end ==================================
2023-02-28 01:17:48,519:INFO:Creating metrics dataframe
2023-02-28 01:17:48,528:INFO:Initializing AdaBoost Regressor
2023-02-28 01:17:48,528:INFO:Total runtime is 0.3219382723172506 minutes
2023-02-28 01:17:48,536:INFO:SubProcess create_model() called ==================================
2023-02-28 01:17:48,536:INFO:Initializing create_model()
2023-02-28 01:17:48,536:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03C674C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:17:48,536:INFO:Checking exceptions
2023-02-28 01:17:48,536:INFO:Importing libraries
2023-02-28 01:17:48,536:INFO:Copying training dataset
2023-02-28 01:17:48,536:INFO:Defining folds
2023-02-28 01:17:48,536:INFO:Declaring metric variables
2023-02-28 01:17:48,544:INFO:Importing untrained model
2023-02-28 01:17:48,544:INFO:AdaBoost Regressor Imported successfully
2023-02-28 01:17:48,552:INFO:Starting cross validation
2023-02-28 01:17:48,561:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:17:49,037:INFO:Calculating mean and std
2023-02-28 01:17:49,037:INFO:Creating metrics dataframe
2023-02-28 01:17:49,037:INFO:Uploading results into container
2023-02-28 01:17:49,037:INFO:Uploading model into container now
2023-02-28 01:17:49,045:INFO:_master_model_container: 15
2023-02-28 01:17:49,045:INFO:_display_container: 2
2023-02-28 01:17:49,045:INFO:AdaBoostRegressor(random_state=123)
2023-02-28 01:17:49,045:INFO:create_model() successfully completed......................................
2023-02-28 01:17:49,279:INFO:SubProcess create_model() end ==================================
2023-02-28 01:17:49,279:INFO:Creating metrics dataframe
2023-02-28 01:17:49,295:INFO:Initializing Gradient Boosting Regressor
2023-02-28 01:17:49,295:INFO:Total runtime is 0.3347280303637187 minutes
2023-02-28 01:17:49,305:INFO:SubProcess create_model() called ==================================
2023-02-28 01:17:49,305:INFO:Initializing create_model()
2023-02-28 01:17:49,305:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03C674C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:17:49,305:INFO:Checking exceptions
2023-02-28 01:17:49,305:INFO:Importing libraries
2023-02-28 01:17:49,305:INFO:Copying training dataset
2023-02-28 01:17:49,312:INFO:Defining folds
2023-02-28 01:17:49,312:INFO:Declaring metric variables
2023-02-28 01:17:49,317:INFO:Importing untrained model
2023-02-28 01:17:49,320:INFO:Gradient Boosting Regressor Imported successfully
2023-02-28 01:17:49,328:INFO:Starting cross validation
2023-02-28 01:17:49,328:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:17:49,939:INFO:Calculating mean and std
2023-02-28 01:17:49,943:INFO:Creating metrics dataframe
2023-02-28 01:17:49,945:INFO:Uploading results into container
2023-02-28 01:17:49,945:INFO:Uploading model into container now
2023-02-28 01:17:49,945:INFO:_master_model_container: 16
2023-02-28 01:17:49,945:INFO:_display_container: 2
2023-02-28 01:17:49,950:INFO:GradientBoostingRegressor(random_state=123)
2023-02-28 01:17:49,950:INFO:create_model() successfully completed......................................
2023-02-28 01:17:50,196:INFO:SubProcess create_model() end ==================================
2023-02-28 01:17:50,198:INFO:Creating metrics dataframe
2023-02-28 01:17:50,209:INFO:Initializing Extreme Gradient Boosting
2023-02-28 01:17:50,209:INFO:Total runtime is 0.3499508619308472 minutes
2023-02-28 01:17:50,214:INFO:SubProcess create_model() called ==================================
2023-02-28 01:17:50,214:INFO:Initializing create_model()
2023-02-28 01:17:50,214:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03C674C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:17:50,214:INFO:Checking exceptions
2023-02-28 01:17:50,214:INFO:Importing libraries
2023-02-28 01:17:50,214:INFO:Copying training dataset
2023-02-28 01:17:50,214:INFO:Defining folds
2023-02-28 01:17:50,221:INFO:Declaring metric variables
2023-02-28 01:17:50,223:INFO:Importing untrained model
2023-02-28 01:17:50,226:INFO:Extreme Gradient Boosting Imported successfully
2023-02-28 01:17:50,232:INFO:Starting cross validation
2023-02-28 01:17:50,238:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:17:50,687:INFO:Calculating mean and std
2023-02-28 01:17:50,689:INFO:Creating metrics dataframe
2023-02-28 01:17:50,691:INFO:Uploading results into container
2023-02-28 01:17:50,691:INFO:Uploading model into container now
2023-02-28 01:17:50,691:INFO:_master_model_container: 17
2023-02-28 01:17:50,695:INFO:_display_container: 2
2023-02-28 01:17:50,695:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=123, ...)
2023-02-28 01:17:50,695:INFO:create_model() successfully completed......................................
2023-02-28 01:17:50,906:INFO:SubProcess create_model() end ==================================
2023-02-28 01:17:50,906:INFO:Creating metrics dataframe
2023-02-28 01:17:50,922:INFO:Initializing Light Gradient Boosting Machine
2023-02-28 01:17:50,922:INFO:Total runtime is 0.36184186140696206 minutes
2023-02-28 01:17:50,930:INFO:SubProcess create_model() called ==================================
2023-02-28 01:17:50,930:INFO:Initializing create_model()
2023-02-28 01:17:50,930:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03C674C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:17:50,930:INFO:Checking exceptions
2023-02-28 01:17:50,930:INFO:Importing libraries
2023-02-28 01:17:50,930:INFO:Copying training dataset
2023-02-28 01:17:50,930:INFO:Defining folds
2023-02-28 01:17:50,930:INFO:Declaring metric variables
2023-02-28 01:17:50,939:INFO:Importing untrained model
2023-02-28 01:17:50,939:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-28 01:17:50,952:INFO:Starting cross validation
2023-02-28 01:17:50,952:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:17:51,394:INFO:Calculating mean and std
2023-02-28 01:17:51,394:INFO:Creating metrics dataframe
2023-02-28 01:17:51,394:INFO:Uploading results into container
2023-02-28 01:17:51,402:INFO:Uploading model into container now
2023-02-28 01:17:51,402:INFO:_master_model_container: 18
2023-02-28 01:17:51,402:INFO:_display_container: 2
2023-02-28 01:17:51,402:INFO:LGBMRegressor(random_state=123)
2023-02-28 01:17:51,402:INFO:create_model() successfully completed......................................
2023-02-28 01:17:51,629:INFO:SubProcess create_model() end ==================================
2023-02-28 01:17:51,629:INFO:Creating metrics dataframe
2023-02-28 01:17:51,645:INFO:Initializing Dummy Regressor
2023-02-28 01:17:51,645:INFO:Total runtime is 0.3738918622334798 minutes
2023-02-28 01:17:51,654:INFO:SubProcess create_model() called ==================================
2023-02-28 01:17:51,654:INFO:Initializing create_model()
2023-02-28 01:17:51,654:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03C674C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:17:51,654:INFO:Checking exceptions
2023-02-28 01:17:51,654:INFO:Importing libraries
2023-02-28 01:17:51,654:INFO:Copying training dataset
2023-02-28 01:17:51,658:INFO:Defining folds
2023-02-28 01:17:51,658:INFO:Declaring metric variables
2023-02-28 01:17:51,665:INFO:Importing untrained model
2023-02-28 01:17:51,670:INFO:Dummy Regressor Imported successfully
2023-02-28 01:17:51,682:INFO:Starting cross validation
2023-02-28 01:17:51,684:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:17:51,969:INFO:Calculating mean and std
2023-02-28 01:17:51,969:INFO:Creating metrics dataframe
2023-02-28 01:17:51,977:INFO:Uploading results into container
2023-02-28 01:17:51,977:INFO:Uploading model into container now
2023-02-28 01:17:51,980:INFO:_master_model_container: 19
2023-02-28 01:17:51,980:INFO:_display_container: 2
2023-02-28 01:17:51,980:INFO:DummyRegressor()
2023-02-28 01:17:51,980:INFO:create_model() successfully completed......................................
2023-02-28 01:17:52,197:INFO:SubProcess create_model() end ==================================
2023-02-28 01:17:52,197:INFO:Creating metrics dataframe
2023-02-28 01:18:14,513:INFO:Initializing compare_models()
2023-02-28 01:18:14,513:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-02-28 01:18:14,513:INFO:Checking exceptions
2023-02-28 01:18:14,513:INFO:Preparing display monitor
2023-02-28 01:18:14,569:INFO:Initializing Linear Regression
2023-02-28 01:18:14,577:INFO:Total runtime is 0.0001337885856628418 minutes
2023-02-28 01:18:14,582:INFO:SubProcess create_model() called ==================================
2023-02-28 01:18:14,582:INFO:Initializing create_model()
2023-02-28 01:18:14,584:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03C3EB20>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:18:14,584:INFO:Checking exceptions
2023-02-28 01:18:14,584:INFO:Importing libraries
2023-02-28 01:18:14,584:INFO:Copying training dataset
2023-02-28 01:18:14,588:INFO:Defining folds
2023-02-28 01:18:14,588:INFO:Declaring metric variables
2023-02-28 01:18:14,595:INFO:Importing untrained model
2023-02-28 01:18:14,602:INFO:Linear Regression Imported successfully
2023-02-28 01:18:14,613:INFO:Starting cross validation
2023-02-28 01:18:14,613:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:18:15,089:INFO:Calculating mean and std
2023-02-28 01:18:15,089:INFO:Creating metrics dataframe
2023-02-28 01:18:15,094:INFO:Uploading results into container
2023-02-28 01:18:15,094:INFO:Uploading model into container now
2023-02-28 01:18:15,094:INFO:_master_model_container: 20
2023-02-28 01:18:15,094:INFO:_display_container: 2
2023-02-28 01:18:15,094:INFO:LinearRegression(n_jobs=-1)
2023-02-28 01:18:15,094:INFO:create_model() successfully completed......................................
2023-02-28 01:18:15,745:INFO:SubProcess create_model() end ==================================
2023-02-28 01:18:15,745:INFO:Creating metrics dataframe
2023-02-28 01:18:15,767:INFO:Initializing Lasso Regression
2023-02-28 01:18:15,767:INFO:Total runtime is 0.019973687330881753 minutes
2023-02-28 01:18:15,775:INFO:SubProcess create_model() called ==================================
2023-02-28 01:18:15,775:INFO:Initializing create_model()
2023-02-28 01:18:15,775:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03C3EB20>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:18:15,775:INFO:Checking exceptions
2023-02-28 01:18:15,775:INFO:Importing libraries
2023-02-28 01:18:15,775:INFO:Copying training dataset
2023-02-28 01:18:15,787:INFO:Defining folds
2023-02-28 01:18:15,789:INFO:Declaring metric variables
2023-02-28 01:18:15,795:INFO:Importing untrained model
2023-02-28 01:18:15,802:INFO:Lasso Regression Imported successfully
2023-02-28 01:18:15,816:INFO:Starting cross validation
2023-02-28 01:18:15,824:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:18:16,326:INFO:Calculating mean and std
2023-02-28 01:18:16,334:INFO:Creating metrics dataframe
2023-02-28 01:18:16,338:INFO:Uploading results into container
2023-02-28 01:18:16,338:INFO:Uploading model into container now
2023-02-28 01:18:16,338:INFO:_master_model_container: 21
2023-02-28 01:18:16,338:INFO:_display_container: 2
2023-02-28 01:18:16,342:INFO:Lasso(random_state=123)
2023-02-28 01:18:16,342:INFO:create_model() successfully completed......................................
2023-02-28 01:18:16,725:INFO:SubProcess create_model() end ==================================
2023-02-28 01:18:16,725:INFO:Creating metrics dataframe
2023-02-28 01:18:16,741:INFO:Initializing Ridge Regression
2023-02-28 01:18:16,741:INFO:Total runtime is 0.036204882462819415 minutes
2023-02-28 01:18:16,741:INFO:SubProcess create_model() called ==================================
2023-02-28 01:18:16,749:INFO:Initializing create_model()
2023-02-28 01:18:16,749:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03C3EB20>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:18:16,749:INFO:Checking exceptions
2023-02-28 01:18:16,749:INFO:Importing libraries
2023-02-28 01:18:16,749:INFO:Copying training dataset
2023-02-28 01:18:16,756:INFO:Defining folds
2023-02-28 01:18:16,756:INFO:Declaring metric variables
2023-02-28 01:18:16,757:INFO:Importing untrained model
2023-02-28 01:18:16,766:INFO:Ridge Regression Imported successfully
2023-02-28 01:18:16,779:INFO:Starting cross validation
2023-02-28 01:18:16,782:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:18:17,170:INFO:Calculating mean and std
2023-02-28 01:18:17,172:INFO:Creating metrics dataframe
2023-02-28 01:18:17,172:INFO:Uploading results into container
2023-02-28 01:18:17,172:INFO:Uploading model into container now
2023-02-28 01:18:17,177:INFO:_master_model_container: 22
2023-02-28 01:18:17,177:INFO:_display_container: 2
2023-02-28 01:18:17,177:INFO:Ridge(random_state=123)
2023-02-28 01:18:17,177:INFO:create_model() successfully completed......................................
2023-02-28 01:18:17,433:INFO:SubProcess create_model() end ==================================
2023-02-28 01:18:17,433:INFO:Creating metrics dataframe
2023-02-28 01:18:17,444:INFO:Initializing Elastic Net
2023-02-28 01:18:17,444:INFO:Total runtime is 0.047921264171600336 minutes
2023-02-28 01:18:17,448:INFO:SubProcess create_model() called ==================================
2023-02-28 01:18:17,448:INFO:Initializing create_model()
2023-02-28 01:18:17,448:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03C3EB20>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:18:17,448:INFO:Checking exceptions
2023-02-28 01:18:17,448:INFO:Importing libraries
2023-02-28 01:18:17,448:INFO:Copying training dataset
2023-02-28 01:18:17,453:INFO:Defining folds
2023-02-28 01:18:17,453:INFO:Declaring metric variables
2023-02-28 01:18:17,458:INFO:Importing untrained model
2023-02-28 01:18:17,460:INFO:Elastic Net Imported successfully
2023-02-28 01:18:17,466:INFO:Starting cross validation
2023-02-28 01:18:17,471:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:18:17,788:INFO:Calculating mean and std
2023-02-28 01:18:17,788:INFO:Creating metrics dataframe
2023-02-28 01:18:17,793:INFO:Uploading results into container
2023-02-28 01:18:17,793:INFO:Uploading model into container now
2023-02-28 01:18:17,793:INFO:_master_model_container: 23
2023-02-28 01:18:17,793:INFO:_display_container: 2
2023-02-28 01:18:17,793:INFO:ElasticNet(random_state=123)
2023-02-28 01:18:17,793:INFO:create_model() successfully completed......................................
2023-02-28 01:18:18,041:INFO:SubProcess create_model() end ==================================
2023-02-28 01:18:18,041:INFO:Creating metrics dataframe
2023-02-28 01:18:18,057:INFO:Initializing Least Angle Regression
2023-02-28 01:18:18,061:INFO:Total runtime is 0.05820190111796061 minutes
2023-02-28 01:18:18,064:INFO:SubProcess create_model() called ==================================
2023-02-28 01:18:18,064:INFO:Initializing create_model()
2023-02-28 01:18:18,064:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03C3EB20>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:18:18,064:INFO:Checking exceptions
2023-02-28 01:18:18,064:INFO:Importing libraries
2023-02-28 01:18:18,064:INFO:Copying training dataset
2023-02-28 01:18:18,068:INFO:Defining folds
2023-02-28 01:18:18,068:INFO:Declaring metric variables
2023-02-28 01:18:18,075:INFO:Importing untrained model
2023-02-28 01:18:18,081:INFO:Least Angle Regression Imported successfully
2023-02-28 01:18:18,089:INFO:Starting cross validation
2023-02-28 01:18:18,093:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:18:18,436:INFO:Calculating mean and std
2023-02-28 01:18:18,436:INFO:Creating metrics dataframe
2023-02-28 01:18:18,436:INFO:Uploading results into container
2023-02-28 01:18:18,436:INFO:Uploading model into container now
2023-02-28 01:18:18,436:INFO:_master_model_container: 24
2023-02-28 01:18:18,436:INFO:_display_container: 2
2023-02-28 01:18:18,436:INFO:Lars(random_state=123)
2023-02-28 01:18:18,436:INFO:create_model() successfully completed......................................
2023-02-28 01:18:18,689:INFO:SubProcess create_model() end ==================================
2023-02-28 01:18:18,689:INFO:Creating metrics dataframe
2023-02-28 01:18:18,695:INFO:Initializing Lasso Least Angle Regression
2023-02-28 01:18:18,695:INFO:Total runtime is 0.06876118580500284 minutes
2023-02-28 01:18:18,703:INFO:SubProcess create_model() called ==================================
2023-02-28 01:18:18,703:INFO:Initializing create_model()
2023-02-28 01:18:18,703:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03C3EB20>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:18:18,703:INFO:Checking exceptions
2023-02-28 01:18:18,703:INFO:Importing libraries
2023-02-28 01:18:18,703:INFO:Copying training dataset
2023-02-28 01:18:18,705:INFO:Defining folds
2023-02-28 01:18:18,705:INFO:Declaring metric variables
2023-02-28 01:18:18,711:INFO:Importing untrained model
2023-02-28 01:18:18,714:INFO:Lasso Least Angle Regression Imported successfully
2023-02-28 01:18:18,720:INFO:Starting cross validation
2023-02-28 01:18:18,720:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:18:19,028:INFO:Calculating mean and std
2023-02-28 01:18:19,028:INFO:Creating metrics dataframe
2023-02-28 01:18:19,032:INFO:Uploading results into container
2023-02-28 01:18:19,032:INFO:Uploading model into container now
2023-02-28 01:18:19,035:INFO:_master_model_container: 25
2023-02-28 01:18:19,035:INFO:_display_container: 2
2023-02-28 01:18:19,035:INFO:LassoLars(random_state=123)
2023-02-28 01:18:19,035:INFO:create_model() successfully completed......................................
2023-02-28 01:18:19,270:INFO:SubProcess create_model() end ==================================
2023-02-28 01:18:19,271:INFO:Creating metrics dataframe
2023-02-28 01:18:19,281:INFO:Initializing Orthogonal Matching Pursuit
2023-02-28 01:18:19,281:INFO:Total runtime is 0.07852955261866251 minutes
2023-02-28 01:18:19,284:INFO:SubProcess create_model() called ==================================
2023-02-28 01:18:19,284:INFO:Initializing create_model()
2023-02-28 01:18:19,284:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03C3EB20>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:18:19,284:INFO:Checking exceptions
2023-02-28 01:18:19,284:INFO:Importing libraries
2023-02-28 01:18:19,284:INFO:Copying training dataset
2023-02-28 01:18:19,288:INFO:Defining folds
2023-02-28 01:18:19,288:INFO:Declaring metric variables
2023-02-28 01:18:19,294:INFO:Importing untrained model
2023-02-28 01:18:19,297:INFO:Orthogonal Matching Pursuit Imported successfully
2023-02-28 01:18:19,304:INFO:Starting cross validation
2023-02-28 01:18:19,307:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:18:19,613:INFO:Calculating mean and std
2023-02-28 01:18:19,615:INFO:Creating metrics dataframe
2023-02-28 01:18:19,618:INFO:Uploading results into container
2023-02-28 01:18:19,618:INFO:Uploading model into container now
2023-02-28 01:18:19,618:INFO:_master_model_container: 26
2023-02-28 01:18:19,618:INFO:_display_container: 2
2023-02-28 01:18:19,618:INFO:OrthogonalMatchingPursuit()
2023-02-28 01:18:19,618:INFO:create_model() successfully completed......................................
2023-02-28 01:18:19,843:INFO:SubProcess create_model() end ==================================
2023-02-28 01:18:19,849:INFO:Creating metrics dataframe
2023-02-28 01:18:19,859:INFO:Initializing Bayesian Ridge
2023-02-28 01:18:19,860:INFO:Total runtime is 0.08818638324737549 minutes
2023-02-28 01:18:19,864:INFO:SubProcess create_model() called ==================================
2023-02-28 01:18:19,864:INFO:Initializing create_model()
2023-02-28 01:18:19,864:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03C3EB20>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:18:19,864:INFO:Checking exceptions
2023-02-28 01:18:19,864:INFO:Importing libraries
2023-02-28 01:18:19,864:INFO:Copying training dataset
2023-02-28 01:18:19,866:INFO:Defining folds
2023-02-28 01:18:19,866:INFO:Declaring metric variables
2023-02-28 01:18:19,871:INFO:Importing untrained model
2023-02-28 01:18:19,877:INFO:Bayesian Ridge Imported successfully
2023-02-28 01:18:19,884:INFO:Starting cross validation
2023-02-28 01:18:19,887:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:18:20,231:INFO:Calculating mean and std
2023-02-28 01:18:20,232:INFO:Creating metrics dataframe
2023-02-28 01:18:20,235:INFO:Uploading results into container
2023-02-28 01:18:20,235:INFO:Uploading model into container now
2023-02-28 01:18:20,235:INFO:_master_model_container: 27
2023-02-28 01:18:20,235:INFO:_display_container: 2
2023-02-28 01:18:20,235:INFO:BayesianRidge()
2023-02-28 01:18:20,235:INFO:create_model() successfully completed......................................
2023-02-28 01:18:20,471:INFO:SubProcess create_model() end ==================================
2023-02-28 01:18:20,471:INFO:Creating metrics dataframe
2023-02-28 01:18:20,482:INFO:Initializing Passive Aggressive Regressor
2023-02-28 01:18:20,482:INFO:Total runtime is 0.09855924050013225 minutes
2023-02-28 01:18:20,486:INFO:SubProcess create_model() called ==================================
2023-02-28 01:18:20,486:INFO:Initializing create_model()
2023-02-28 01:18:20,486:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03C3EB20>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:18:20,487:INFO:Checking exceptions
2023-02-28 01:18:20,487:INFO:Importing libraries
2023-02-28 01:18:20,487:INFO:Copying training dataset
2023-02-28 01:18:20,491:INFO:Defining folds
2023-02-28 01:18:20,491:INFO:Declaring metric variables
2023-02-28 01:18:20,497:INFO:Importing untrained model
2023-02-28 01:18:20,499:INFO:Passive Aggressive Regressor Imported successfully
2023-02-28 01:18:20,507:INFO:Starting cross validation
2023-02-28 01:18:20,507:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:18:20,838:INFO:Calculating mean and std
2023-02-28 01:18:20,843:INFO:Creating metrics dataframe
2023-02-28 01:18:20,845:INFO:Uploading results into container
2023-02-28 01:18:20,845:INFO:Uploading model into container now
2023-02-28 01:18:20,845:INFO:_master_model_container: 28
2023-02-28 01:18:20,845:INFO:_display_container: 2
2023-02-28 01:18:20,845:INFO:PassiveAggressiveRegressor(random_state=123)
2023-02-28 01:18:20,845:INFO:create_model() successfully completed......................................
2023-02-28 01:18:21,082:INFO:SubProcess create_model() end ==================================
2023-02-28 01:18:21,082:INFO:Creating metrics dataframe
2023-02-28 01:18:21,098:INFO:Initializing Huber Regressor
2023-02-28 01:18:21,098:INFO:Total runtime is 0.10882201194763184 minutes
2023-02-28 01:18:21,103:INFO:SubProcess create_model() called ==================================
2023-02-28 01:18:21,103:INFO:Initializing create_model()
2023-02-28 01:18:21,105:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03C3EB20>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:18:21,105:INFO:Checking exceptions
2023-02-28 01:18:21,105:INFO:Importing libraries
2023-02-28 01:18:21,105:INFO:Copying training dataset
2023-02-28 01:18:21,107:INFO:Defining folds
2023-02-28 01:18:21,107:INFO:Declaring metric variables
2023-02-28 01:18:21,113:INFO:Importing untrained model
2023-02-28 01:18:21,117:INFO:Huber Regressor Imported successfully
2023-02-28 01:18:21,124:INFO:Starting cross validation
2023-02-28 01:18:21,126:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:18:21,317:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:18:21,340:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:18:21,348:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:18:21,361:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:18:21,389:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:18:21,397:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:18:21,397:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:18:21,437:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:18:21,437:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:18:21,453:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:18:21,501:INFO:Calculating mean and std
2023-02-28 01:18:21,501:INFO:Creating metrics dataframe
2023-02-28 01:18:21,506:INFO:Uploading results into container
2023-02-28 01:18:21,506:INFO:Uploading model into container now
2023-02-28 01:18:21,509:INFO:_master_model_container: 29
2023-02-28 01:18:21,509:INFO:_display_container: 2
2023-02-28 01:18:21,509:INFO:HuberRegressor()
2023-02-28 01:18:21,509:INFO:create_model() successfully completed......................................
2023-02-28 01:18:21,737:INFO:SubProcess create_model() end ==================================
2023-02-28 01:18:21,737:INFO:Creating metrics dataframe
2023-02-28 01:18:21,754:INFO:Initializing K Neighbors Regressor
2023-02-28 01:18:21,754:INFO:Total runtime is 0.11975326935450237 minutes
2023-02-28 01:18:21,756:INFO:SubProcess create_model() called ==================================
2023-02-28 01:18:21,756:INFO:Initializing create_model()
2023-02-28 01:18:21,756:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03C3EB20>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:18:21,756:INFO:Checking exceptions
2023-02-28 01:18:21,760:INFO:Importing libraries
2023-02-28 01:18:21,760:INFO:Copying training dataset
2023-02-28 01:18:21,762:INFO:Defining folds
2023-02-28 01:18:21,762:INFO:Declaring metric variables
2023-02-28 01:18:21,768:INFO:Importing untrained model
2023-02-28 01:18:21,770:INFO:K Neighbors Regressor Imported successfully
2023-02-28 01:18:21,785:INFO:Starting cross validation
2023-02-28 01:18:21,787:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:18:22,146:INFO:Calculating mean and std
2023-02-28 01:18:22,147:INFO:Creating metrics dataframe
2023-02-28 01:18:22,149:INFO:Uploading results into container
2023-02-28 01:18:22,151:INFO:Uploading model into container now
2023-02-28 01:18:22,151:INFO:_master_model_container: 30
2023-02-28 01:18:22,152:INFO:_display_container: 2
2023-02-28 01:18:22,152:INFO:KNeighborsRegressor(n_jobs=-1)
2023-02-28 01:18:22,152:INFO:create_model() successfully completed......................................
2023-02-28 01:18:22,380:INFO:SubProcess create_model() end ==================================
2023-02-28 01:18:22,380:INFO:Creating metrics dataframe
2023-02-28 01:18:22,389:INFO:Initializing Decision Tree Regressor
2023-02-28 01:18:22,389:INFO:Total runtime is 0.13033115466435752 minutes
2023-02-28 01:18:22,397:INFO:SubProcess create_model() called ==================================
2023-02-28 01:18:22,400:INFO:Initializing create_model()
2023-02-28 01:18:22,400:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03C3EB20>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:18:22,400:INFO:Checking exceptions
2023-02-28 01:18:22,400:INFO:Importing libraries
2023-02-28 01:18:22,400:INFO:Copying training dataset
2023-02-28 01:18:22,405:INFO:Defining folds
2023-02-28 01:18:22,405:INFO:Declaring metric variables
2023-02-28 01:18:22,408:INFO:Importing untrained model
2023-02-28 01:18:22,413:INFO:Decision Tree Regressor Imported successfully
2023-02-28 01:18:22,416:INFO:Starting cross validation
2023-02-28 01:18:22,421:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:18:22,710:INFO:Calculating mean and std
2023-02-28 01:18:22,713:INFO:Creating metrics dataframe
2023-02-28 01:18:22,716:INFO:Uploading results into container
2023-02-28 01:18:22,718:INFO:Uploading model into container now
2023-02-28 01:18:22,718:INFO:_master_model_container: 31
2023-02-28 01:18:22,718:INFO:_display_container: 2
2023-02-28 01:18:22,718:INFO:DecisionTreeRegressor(random_state=123)
2023-02-28 01:18:22,718:INFO:create_model() successfully completed......................................
2023-02-28 01:18:22,942:INFO:SubProcess create_model() end ==================================
2023-02-28 01:18:22,942:INFO:Creating metrics dataframe
2023-02-28 01:18:22,958:INFO:Initializing Random Forest Regressor
2023-02-28 01:18:22,962:INFO:Total runtime is 0.1398815711339315 minutes
2023-02-28 01:18:22,965:INFO:SubProcess create_model() called ==================================
2023-02-28 01:18:22,965:INFO:Initializing create_model()
2023-02-28 01:18:22,965:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03C3EB20>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:18:22,965:INFO:Checking exceptions
2023-02-28 01:18:22,965:INFO:Importing libraries
2023-02-28 01:18:22,965:INFO:Copying training dataset
2023-02-28 01:18:22,969:INFO:Defining folds
2023-02-28 01:18:22,969:INFO:Declaring metric variables
2023-02-28 01:18:22,975:INFO:Importing untrained model
2023-02-28 01:18:22,979:INFO:Random Forest Regressor Imported successfully
2023-02-28 01:18:22,984:INFO:Starting cross validation
2023-02-28 01:18:22,984:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:18:23,429:INFO:Calculating mean and std
2023-02-28 01:18:23,429:INFO:Creating metrics dataframe
2023-02-28 01:18:23,431:INFO:Uploading results into container
2023-02-28 01:18:23,431:INFO:Uploading model into container now
2023-02-28 01:18:23,431:INFO:_master_model_container: 32
2023-02-28 01:18:23,436:INFO:_display_container: 2
2023-02-28 01:18:23,436:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-02-28 01:18:23,436:INFO:create_model() successfully completed......................................
2023-02-28 01:18:23,665:INFO:SubProcess create_model() end ==================================
2023-02-28 01:18:23,665:INFO:Creating metrics dataframe
2023-02-28 01:18:23,673:INFO:Initializing Extra Trees Regressor
2023-02-28 01:18:23,673:INFO:Total runtime is 0.15174203316370646 minutes
2023-02-28 01:18:23,673:INFO:SubProcess create_model() called ==================================
2023-02-28 01:18:23,681:INFO:Initializing create_model()
2023-02-28 01:18:23,681:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03C3EB20>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:18:23,681:INFO:Checking exceptions
2023-02-28 01:18:23,681:INFO:Importing libraries
2023-02-28 01:18:23,681:INFO:Copying training dataset
2023-02-28 01:18:23,681:INFO:Defining folds
2023-02-28 01:18:23,681:INFO:Declaring metric variables
2023-02-28 01:18:23,689:INFO:Importing untrained model
2023-02-28 01:18:23,689:INFO:Extra Trees Regressor Imported successfully
2023-02-28 01:18:23,697:INFO:Starting cross validation
2023-02-28 01:18:23,705:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:18:24,196:INFO:Calculating mean and std
2023-02-28 01:18:24,196:INFO:Creating metrics dataframe
2023-02-28 01:18:24,199:INFO:Uploading results into container
2023-02-28 01:18:24,199:INFO:Uploading model into container now
2023-02-28 01:18:24,199:INFO:_master_model_container: 33
2023-02-28 01:18:24,203:INFO:_display_container: 2
2023-02-28 01:18:24,203:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-02-28 01:18:24,203:INFO:create_model() successfully completed......................................
2023-02-28 01:18:24,439:INFO:SubProcess create_model() end ==================================
2023-02-28 01:18:24,439:INFO:Creating metrics dataframe
2023-02-28 01:18:24,447:INFO:Initializing AdaBoost Regressor
2023-02-28 01:18:24,447:INFO:Total runtime is 0.16464175780614218 minutes
2023-02-28 01:18:24,455:INFO:SubProcess create_model() called ==================================
2023-02-28 01:18:24,455:INFO:Initializing create_model()
2023-02-28 01:18:24,455:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03C3EB20>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:18:24,455:INFO:Checking exceptions
2023-02-28 01:18:24,455:INFO:Importing libraries
2023-02-28 01:18:24,455:INFO:Copying training dataset
2023-02-28 01:18:24,455:INFO:Defining folds
2023-02-28 01:18:24,455:INFO:Declaring metric variables
2023-02-28 01:18:24,464:INFO:Importing untrained model
2023-02-28 01:18:24,464:INFO:AdaBoost Regressor Imported successfully
2023-02-28 01:18:24,471:INFO:Starting cross validation
2023-02-28 01:18:24,471:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:18:24,822:INFO:Calculating mean and std
2023-02-28 01:18:24,826:INFO:Creating metrics dataframe
2023-02-28 01:18:24,826:INFO:Uploading results into container
2023-02-28 01:18:24,826:INFO:Uploading model into container now
2023-02-28 01:18:24,826:INFO:_master_model_container: 34
2023-02-28 01:18:24,826:INFO:_display_container: 2
2023-02-28 01:18:24,826:INFO:AdaBoostRegressor(random_state=123)
2023-02-28 01:18:24,826:INFO:create_model() successfully completed......................................
2023-02-28 01:18:25,061:INFO:SubProcess create_model() end ==================================
2023-02-28 01:18:25,061:INFO:Creating metrics dataframe
2023-02-28 01:18:25,069:INFO:Initializing Gradient Boosting Regressor
2023-02-28 01:18:25,069:INFO:Total runtime is 0.17500503857930502 minutes
2023-02-28 01:18:25,077:INFO:SubProcess create_model() called ==================================
2023-02-28 01:18:25,077:INFO:Initializing create_model()
2023-02-28 01:18:25,077:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03C3EB20>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:18:25,077:INFO:Checking exceptions
2023-02-28 01:18:25,077:INFO:Importing libraries
2023-02-28 01:18:25,077:INFO:Copying training dataset
2023-02-28 01:18:25,077:INFO:Defining folds
2023-02-28 01:18:25,077:INFO:Declaring metric variables
2023-02-28 01:18:25,086:INFO:Importing untrained model
2023-02-28 01:18:25,093:INFO:Gradient Boosting Regressor Imported successfully
2023-02-28 01:18:25,102:INFO:Starting cross validation
2023-02-28 01:18:25,102:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:18:25,527:INFO:Calculating mean and std
2023-02-28 01:18:25,535:INFO:Creating metrics dataframe
2023-02-28 01:18:25,535:INFO:Uploading results into container
2023-02-28 01:18:25,535:INFO:Uploading model into container now
2023-02-28 01:18:25,535:INFO:_master_model_container: 35
2023-02-28 01:18:25,535:INFO:_display_container: 2
2023-02-28 01:18:25,535:INFO:GradientBoostingRegressor(random_state=123)
2023-02-28 01:18:25,535:INFO:create_model() successfully completed......................................
2023-02-28 01:18:25,766:INFO:SubProcess create_model() end ==================================
2023-02-28 01:18:25,766:INFO:Creating metrics dataframe
2023-02-28 01:18:25,780:INFO:Initializing Extreme Gradient Boosting
2023-02-28 01:18:25,780:INFO:Total runtime is 0.18685343662897747 minutes
2023-02-28 01:18:25,780:INFO:SubProcess create_model() called ==================================
2023-02-28 01:18:25,780:INFO:Initializing create_model()
2023-02-28 01:18:25,780:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03C3EB20>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:18:25,780:INFO:Checking exceptions
2023-02-28 01:18:25,780:INFO:Importing libraries
2023-02-28 01:18:25,780:INFO:Copying training dataset
2023-02-28 01:18:25,789:INFO:Defining folds
2023-02-28 01:18:25,789:INFO:Declaring metric variables
2023-02-28 01:18:25,796:INFO:Importing untrained model
2023-02-28 01:18:25,797:INFO:Extreme Gradient Boosting Imported successfully
2023-02-28 01:18:25,806:INFO:Starting cross validation
2023-02-28 01:18:25,806:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:18:26,254:INFO:Calculating mean and std
2023-02-28 01:18:26,262:INFO:Creating metrics dataframe
2023-02-28 01:18:26,262:INFO:Uploading results into container
2023-02-28 01:18:26,262:INFO:Uploading model into container now
2023-02-28 01:18:26,267:INFO:_master_model_container: 36
2023-02-28 01:18:26,267:INFO:_display_container: 2
2023-02-28 01:18:26,267:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=123, ...)
2023-02-28 01:18:26,267:INFO:create_model() successfully completed......................................
2023-02-28 01:18:26,491:INFO:SubProcess create_model() end ==================================
2023-02-28 01:18:26,491:INFO:Creating metrics dataframe
2023-02-28 01:18:26,507:INFO:Initializing Light Gradient Boosting Machine
2023-02-28 01:18:26,507:INFO:Total runtime is 0.1989730676015218 minutes
2023-02-28 01:18:26,507:INFO:SubProcess create_model() called ==================================
2023-02-28 01:18:26,515:INFO:Initializing create_model()
2023-02-28 01:18:26,515:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03C3EB20>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:18:26,515:INFO:Checking exceptions
2023-02-28 01:18:26,515:INFO:Importing libraries
2023-02-28 01:18:26,515:INFO:Copying training dataset
2023-02-28 01:18:26,515:INFO:Defining folds
2023-02-28 01:18:26,515:INFO:Declaring metric variables
2023-02-28 01:18:26,523:INFO:Importing untrained model
2023-02-28 01:18:26,523:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-28 01:18:26,531:INFO:Starting cross validation
2023-02-28 01:18:26,531:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:18:26,925:INFO:Calculating mean and std
2023-02-28 01:18:26,933:INFO:Creating metrics dataframe
2023-02-28 01:18:26,934:INFO:Uploading results into container
2023-02-28 01:18:26,934:INFO:Uploading model into container now
2023-02-28 01:18:26,934:INFO:_master_model_container: 37
2023-02-28 01:18:26,934:INFO:_display_container: 2
2023-02-28 01:18:26,934:INFO:LGBMRegressor(random_state=123)
2023-02-28 01:18:26,934:INFO:create_model() successfully completed......................................
2023-02-28 01:18:27,168:INFO:SubProcess create_model() end ==================================
2023-02-28 01:18:27,168:INFO:Creating metrics dataframe
2023-02-28 01:18:27,177:INFO:Initializing Dummy Regressor
2023-02-28 01:18:27,177:INFO:Total runtime is 0.2101430654525757 minutes
2023-02-28 01:18:27,177:INFO:SubProcess create_model() called ==================================
2023-02-28 01:18:27,177:INFO:Initializing create_model()
2023-02-28 01:18:27,177:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB79857790>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03C3EB20>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:18:27,177:INFO:Checking exceptions
2023-02-28 01:18:27,177:INFO:Importing libraries
2023-02-28 01:18:27,177:INFO:Copying training dataset
2023-02-28 01:18:27,185:INFO:Defining folds
2023-02-28 01:18:27,185:INFO:Declaring metric variables
2023-02-28 01:18:27,193:INFO:Importing untrained model
2023-02-28 01:18:27,193:INFO:Dummy Regressor Imported successfully
2023-02-28 01:18:27,201:INFO:Starting cross validation
2023-02-28 01:18:27,209:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:18:27,518:INFO:Calculating mean and std
2023-02-28 01:18:27,522:INFO:Creating metrics dataframe
2023-02-28 01:18:27,523:INFO:Uploading results into container
2023-02-28 01:18:27,523:INFO:Uploading model into container now
2023-02-28 01:18:27,523:INFO:_master_model_container: 38
2023-02-28 01:18:27,523:INFO:_display_container: 2
2023-02-28 01:18:27,523:INFO:DummyRegressor()
2023-02-28 01:18:27,523:INFO:create_model() successfully completed......................................
2023-02-28 01:18:27,753:INFO:SubProcess create_model() end ==================================
2023-02-28 01:18:27,753:INFO:Creating metrics dataframe
2023-02-28 01:19:59,664:INFO:PyCaret RegressionExperiment
2023-02-28 01:19:59,664:INFO:Logging name: reg-default-name
2023-02-28 01:19:59,666:INFO:ML Usecase: MLUsecase.REGRESSION
2023-02-28 01:19:59,666:INFO:version 3.0.0.rc9
2023-02-28 01:19:59,666:INFO:Initializing setup()
2023-02-28 01:19:59,666:INFO:self.USI: c7b3
2023-02-28 01:19:59,666:INFO:self._variable_keys: {'transform_target_param', 'log_plots_param', 'X_test', 'gpu_n_jobs_param', '_ml_usecase', 'memory', 'data', 'seed', 'y', 'y_test', 'X', 'fold_generator', 'fold_shuffle_param', 'target_param', 'n_jobs_param', 'y_train', 'exp_id', 'logging_param', 'idx', '_available_plots', 'USI', 'X_train', 'fold_groups_param', 'pipeline', 'html_param', 'gpu_param', 'exp_name_log'}
2023-02-28 01:19:59,666:INFO:Checking environment
2023-02-28 01:19:59,666:INFO:python_version: 3.8.16
2023-02-28 01:19:59,666:INFO:python_build: ('default', 'Jan 17 2023 22:25:28')
2023-02-28 01:19:59,666:INFO:machine: AMD64
2023-02-28 01:19:59,666:INFO:platform: Windows-10-10.0.22621-SP0
2023-02-28 01:19:59,676:INFO:Memory: svmem(total=14702026752, available=2007617536, percent=86.3, used=12694409216, free=2007617536)
2023-02-28 01:19:59,676:INFO:Physical Core: 8
2023-02-28 01:19:59,676:INFO:Logical Core: 16
2023-02-28 01:19:59,676:INFO:Checking libraries
2023-02-28 01:19:59,676:INFO:System:
2023-02-28 01:19:59,682:INFO:    python: 3.8.16 (default, Jan 17 2023, 22:25:28) [MSC v.1916 64 bit (AMD64)]
2023-02-28 01:19:59,682:INFO:executable: c:\Users\takis\anaconda3\envs\caretenv\python.exe
2023-02-28 01:19:59,682:INFO:   machine: Windows-10-10.0.22621-SP0
2023-02-28 01:19:59,682:INFO:PyCaret required dependencies:
2023-02-28 01:19:59,682:INFO:                 pip: 22.3.1
2023-02-28 01:19:59,682:INFO:          setuptools: 60.10.0
2023-02-28 01:19:59,682:INFO:             pycaret: 3.0.0rc9
2023-02-28 01:19:59,682:INFO:             IPython: 8.10.0
2023-02-28 01:19:59,682:INFO:          ipywidgets: 8.0.4
2023-02-28 01:19:59,682:INFO:                tqdm: 4.64.1
2023-02-28 01:19:59,682:INFO:               numpy: 1.23.5
2023-02-28 01:19:59,682:INFO:              pandas: 1.5.3
2023-02-28 01:19:59,682:INFO:              jinja2: 3.1.2
2023-02-28 01:19:59,682:INFO:               scipy: 1.10.1
2023-02-28 01:19:59,682:INFO:              joblib: 1.2.0
2023-02-28 01:19:59,682:INFO:             sklearn: 1.2.1
2023-02-28 01:19:59,682:INFO:                pyod: 1.0.7
2023-02-28 01:19:59,682:INFO:            imblearn: 0.10.1
2023-02-28 01:19:59,682:INFO:   category_encoders: 2.6.0
2023-02-28 01:19:59,682:INFO:            lightgbm: 3.3.5
2023-02-28 01:19:59,682:INFO:               numba: 0.56.4
2023-02-28 01:19:59,682:INFO:            requests: 2.28.2
2023-02-28 01:19:59,682:INFO:          matplotlib: 3.7.0
2023-02-28 01:19:59,682:INFO:          scikitplot: 0.3.7
2023-02-28 01:19:59,682:INFO:         yellowbrick: 1.5
2023-02-28 01:19:59,682:INFO:              plotly: 5.13.1
2023-02-28 01:19:59,682:INFO:             kaleido: 0.2.1
2023-02-28 01:19:59,682:INFO:         statsmodels: 0.13.5
2023-02-28 01:19:59,682:INFO:              sktime: 0.16.1
2023-02-28 01:19:59,682:INFO:               tbats: 1.1.2
2023-02-28 01:19:59,682:INFO:            pmdarima: 2.0.2
2023-02-28 01:19:59,682:INFO:              psutil: 5.9.4
2023-02-28 01:19:59,682:INFO:PyCaret optional dependencies:
2023-02-28 01:19:59,682:INFO:                shap: Not installed
2023-02-28 01:19:59,682:INFO:           interpret: Not installed
2023-02-28 01:19:59,682:INFO:                umap: Not installed
2023-02-28 01:19:59,682:INFO:    pandas_profiling: Not installed
2023-02-28 01:19:59,682:INFO:  explainerdashboard: Not installed
2023-02-28 01:19:59,682:INFO:             autoviz: 0.1.58
2023-02-28 01:19:59,682:INFO:           fairlearn: Not installed
2023-02-28 01:19:59,682:INFO:             xgboost: 1.7.4
2023-02-28 01:19:59,682:INFO:            catboost: Not installed
2023-02-28 01:19:59,682:INFO:              kmodes: Not installed
2023-02-28 01:19:59,682:INFO:             mlxtend: Not installed
2023-02-28 01:19:59,682:INFO:       statsforecast: Not installed
2023-02-28 01:19:59,682:INFO:        tune_sklearn: Not installed
2023-02-28 01:19:59,682:INFO:                 ray: Not installed
2023-02-28 01:19:59,682:INFO:            hyperopt: Not installed
2023-02-28 01:19:59,682:INFO:              optuna: Not installed
2023-02-28 01:19:59,682:INFO:               skopt: Not installed
2023-02-28 01:19:59,682:INFO:              mlflow: 1.30.0
2023-02-28 01:19:59,682:INFO:              gradio: 3.19.1
2023-02-28 01:19:59,682:INFO:             fastapi: 0.92.0
2023-02-28 01:19:59,682:INFO:             uvicorn: 0.20.0
2023-02-28 01:19:59,682:INFO:              m2cgen: 0.10.0
2023-02-28 01:19:59,682:INFO:           evidently: 0.2.5
2023-02-28 01:19:59,682:INFO:               fugue: Not installed
2023-02-28 01:19:59,682:INFO:           streamlit: Not installed
2023-02-28 01:19:59,682:INFO:             prophet: Not installed
2023-02-28 01:19:59,682:INFO:None
2023-02-28 01:19:59,682:INFO:Set up data.
2023-02-28 01:19:59,690:INFO:Set up train/test split.
2023-02-28 01:19:59,690:INFO:Set up index.
2023-02-28 01:19:59,698:INFO:Set up folding strategy.
2023-02-28 01:19:59,698:INFO:Assigning column types.
2023-02-28 01:19:59,698:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-28 01:19:59,698:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-28 01:19:59,706:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-28 01:19:59,706:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 01:19:59,770:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:19:59,818:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 01:19:59,818:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:19:59,818:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:19:59,818:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-28 01:19:59,826:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-28 01:19:59,826:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 01:19:59,890:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:19:59,933:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 01:19:59,933:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:19:59,933:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:19:59,933:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-02-28 01:19:59,940:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-28 01:19:59,940:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 01:19:59,999:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:20:00,051:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 01:20:00,051:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:20:00,054:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:20:00,054:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-28 01:20:00,062:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 01:20:00,128:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:20:00,168:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 01:20:00,168:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:20:00,171:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:20:00,171:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-02-28 01:20:00,184:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 01:20:00,289:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:20:00,334:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 01:20:00,334:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:20:00,338:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:20:00,348:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 01:20:00,395:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:20:00,436:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 01:20:00,436:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:20:00,436:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:20:00,436:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-02-28 01:20:00,501:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:20:00,535:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 01:20:00,535:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:20:00,542:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:20:00,607:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:20:00,651:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 01:20:00,652:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:20:00,653:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:20:00,653:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-28 01:20:00,722:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:20:00,768:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:20:00,768:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:20:00,830:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:20:00,870:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:20:00,873:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:20:00,873:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-02-28 01:20:01,003:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:20:01,005:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:20:01,102:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:20:01,102:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:20:01,102:INFO:Preparing preprocessing pipeline...
2023-02-28 01:20:01,102:INFO:Set up simple imputation.
2023-02-28 01:20:01,110:INFO:Set up encoding of ordinal features.
2023-02-28 01:20:01,110:INFO:Set up encoding of categorical features.
2023-02-28 01:20:01,185:INFO:Finished creating preprocessing pipeline.
2023-02-28 01:20:01,215:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\takis\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                     'smoker'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64},
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-02-28 01:20:01,215:INFO:Creating final display dataframe.
2023-02-28 01:20:01,563:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           charges
2                   Target type        Regression
3           Original data shape         (1338, 7)
4        Transformed data shape        (1338, 10)
5   Transformed train set shape         (936, 10)
6    Transformed test set shape         (402, 10)
7              Ordinal features                 2
8              Numeric features                 3
9          Categorical features                 3
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              c7b3
2023-02-28 01:20:01,693:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:20:01,693:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:20:01,821:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:20:01,821:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:20:01,821:INFO:setup() successfully completed in 2.16s...............
2023-02-28 01:20:13,310:INFO:Initializing get_config()
2023-02-28 01:20:13,311:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB0585A640>, variable=X_train)
2023-02-28 01:20:13,311:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2023-02-28 01:20:13,319:INFO:Variable:  returned as      age     sex        bmi  children smoker     region
0     36    male  27.549999         3     no  northeast
1     60  female  35.099998         0     no  southwest
2     30    male  31.570000         3     no  southeast
3     49    male  25.600000         2    yes  southwest
4     26    male  32.900002         2    yes  southwest
..   ...     ...        ...       ...    ...        ...
931   37    male  22.705000         3     no  northeast
932   20  female  31.920000         0     no  northwest
933   19  female  28.400000         1     no  southwest
934   18    male  23.084999         0     no  northeast
935   53  female  36.860001         3    yes  northwest

[936 rows x 6 columns]
2023-02-28 01:20:13,319:INFO:get_config() successfully completed......................................
2023-02-28 01:20:15,855:INFO:Initializing get_config()
2023-02-28 01:20:15,855:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB0585A640>, variable=pipeline)
2023-02-28 01:20:15,920:INFO:Variable:  returned as Pipeline(memory=FastMemory(location=C:\Users\takis\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                     'smoker'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64},
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-02-28 01:20:15,920:INFO:get_config() successfully completed......................................
2023-02-28 01:20:23,027:INFO:Initializing get_config()
2023-02-28 01:20:23,027:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB0585A640>, variable=logging_param)
2023-02-28 01:20:23,027:INFO:Variable: l returned as False
2023-02-28 01:20:23,027:INFO:get_config() successfully completed......................................
2023-02-28 01:20:27,445:INFO:Initializing get_config()
2023-02-28 01:20:27,445:INFO:get_config(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB0585A640>, variable=exp_name_log)
2023-02-28 01:20:27,445:INFO:Variable:  returned as reg-default-name
2023-02-28 01:20:27,445:INFO:get_config() successfully completed......................................
2023-02-28 01:20:35,333:INFO:Initializing compare_models()
2023-02-28 01:20:35,333:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB0585A640>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001AB0585A640>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-02-28 01:20:35,333:INFO:Checking exceptions
2023-02-28 01:20:35,341:INFO:Preparing display monitor
2023-02-28 01:20:35,382:INFO:Initializing Linear Regression
2023-02-28 01:20:35,382:INFO:Total runtime is 0.0 minutes
2023-02-28 01:20:35,389:INFO:SubProcess create_model() called ==================================
2023-02-28 01:20:35,389:INFO:Initializing create_model()
2023-02-28 01:20:35,389:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB0585A640>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03B50550>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:20:35,389:INFO:Checking exceptions
2023-02-28 01:20:35,389:INFO:Importing libraries
2023-02-28 01:20:35,389:INFO:Copying training dataset
2023-02-28 01:20:35,399:INFO:Defining folds
2023-02-28 01:20:35,399:INFO:Declaring metric variables
2023-02-28 01:20:35,408:INFO:Importing untrained model
2023-02-28 01:20:35,415:INFO:Linear Regression Imported successfully
2023-02-28 01:20:35,432:INFO:Starting cross validation
2023-02-28 01:20:35,435:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:20:35,925:INFO:Calculating mean and std
2023-02-28 01:20:35,926:INFO:Creating metrics dataframe
2023-02-28 01:20:35,926:INFO:Uploading results into container
2023-02-28 01:20:35,926:INFO:Uploading model into container now
2023-02-28 01:20:35,934:INFO:_master_model_container: 1
2023-02-28 01:20:35,934:INFO:_display_container: 2
2023-02-28 01:20:35,934:INFO:LinearRegression(n_jobs=-1)
2023-02-28 01:20:35,934:INFO:create_model() successfully completed......................................
2023-02-28 01:20:36,569:INFO:SubProcess create_model() end ==================================
2023-02-28 01:20:36,569:INFO:Creating metrics dataframe
2023-02-28 01:20:36,585:INFO:Initializing Lasso Regression
2023-02-28 01:20:36,585:INFO:Total runtime is 0.02006319761276245 minutes
2023-02-28 01:20:36,594:INFO:SubProcess create_model() called ==================================
2023-02-28 01:20:36,594:INFO:Initializing create_model()
2023-02-28 01:20:36,594:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB0585A640>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03B50550>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:20:36,594:INFO:Checking exceptions
2023-02-28 01:20:36,598:INFO:Importing libraries
2023-02-28 01:20:36,598:INFO:Copying training dataset
2023-02-28 01:20:36,602:INFO:Defining folds
2023-02-28 01:20:36,602:INFO:Declaring metric variables
2023-02-28 01:20:36,613:INFO:Importing untrained model
2023-02-28 01:20:36,620:INFO:Lasso Regression Imported successfully
2023-02-28 01:20:36,626:INFO:Starting cross validation
2023-02-28 01:20:36,635:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:20:37,055:INFO:Calculating mean and std
2023-02-28 01:20:37,056:INFO:Creating metrics dataframe
2023-02-28 01:20:37,059:INFO:Uploading results into container
2023-02-28 01:20:37,059:INFO:Uploading model into container now
2023-02-28 01:20:37,059:INFO:_master_model_container: 2
2023-02-28 01:20:37,059:INFO:_display_container: 2
2023-02-28 01:20:37,063:INFO:Lasso(random_state=123)
2023-02-28 01:20:37,063:INFO:create_model() successfully completed......................................
2023-02-28 01:20:37,316:INFO:SubProcess create_model() end ==================================
2023-02-28 01:20:37,318:INFO:Creating metrics dataframe
2023-02-28 01:20:37,325:INFO:Initializing Ridge Regression
2023-02-28 01:20:37,325:INFO:Total runtime is 0.03239064613978068 minutes
2023-02-28 01:20:37,331:INFO:SubProcess create_model() called ==================================
2023-02-28 01:20:37,331:INFO:Initializing create_model()
2023-02-28 01:20:37,331:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB0585A640>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03B50550>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:20:37,331:INFO:Checking exceptions
2023-02-28 01:20:37,331:INFO:Importing libraries
2023-02-28 01:20:37,331:INFO:Copying training dataset
2023-02-28 01:20:37,333:INFO:Defining folds
2023-02-28 01:20:37,333:INFO:Declaring metric variables
2023-02-28 01:20:37,341:INFO:Importing untrained model
2023-02-28 01:20:37,348:INFO:Ridge Regression Imported successfully
2023-02-28 01:20:37,353:INFO:Starting cross validation
2023-02-28 01:20:37,357:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:20:37,651:INFO:Calculating mean and std
2023-02-28 01:20:37,659:INFO:Creating metrics dataframe
2023-02-28 01:20:37,662:INFO:Uploading results into container
2023-02-28 01:20:37,662:INFO:Uploading model into container now
2023-02-28 01:20:37,664:INFO:_master_model_container: 3
2023-02-28 01:20:37,664:INFO:_display_container: 2
2023-02-28 01:20:37,664:INFO:Ridge(random_state=123)
2023-02-28 01:20:37,664:INFO:create_model() successfully completed......................................
2023-02-28 01:20:37,898:INFO:SubProcess create_model() end ==================================
2023-02-28 01:20:37,898:INFO:Creating metrics dataframe
2023-02-28 01:20:37,905:INFO:Initializing Elastic Net
2023-02-28 01:20:37,907:INFO:Total runtime is 0.04209463993708293 minutes
2023-02-28 01:20:37,907:INFO:SubProcess create_model() called ==================================
2023-02-28 01:20:37,911:INFO:Initializing create_model()
2023-02-28 01:20:37,911:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB0585A640>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03B50550>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:20:37,911:INFO:Checking exceptions
2023-02-28 01:20:37,911:INFO:Importing libraries
2023-02-28 01:20:37,911:INFO:Copying training dataset
2023-02-28 01:20:37,913:INFO:Defining folds
2023-02-28 01:20:37,913:INFO:Declaring metric variables
2023-02-28 01:20:37,919:INFO:Importing untrained model
2023-02-28 01:20:37,924:INFO:Elastic Net Imported successfully
2023-02-28 01:20:37,931:INFO:Starting cross validation
2023-02-28 01:20:37,931:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:20:38,269:INFO:Calculating mean and std
2023-02-28 01:20:38,271:INFO:Creating metrics dataframe
2023-02-28 01:20:38,271:INFO:Uploading results into container
2023-02-28 01:20:38,271:INFO:Uploading model into container now
2023-02-28 01:20:38,271:INFO:_master_model_container: 4
2023-02-28 01:20:38,271:INFO:_display_container: 2
2023-02-28 01:20:38,271:INFO:ElasticNet(random_state=123)
2023-02-28 01:20:38,276:INFO:create_model() successfully completed......................................
2023-02-28 01:20:38,507:INFO:SubProcess create_model() end ==================================
2023-02-28 01:20:38,507:INFO:Creating metrics dataframe
2023-02-28 01:20:38,520:INFO:Initializing Least Angle Regression
2023-02-28 01:20:38,520:INFO:Total runtime is 0.052299817403157554 minutes
2023-02-28 01:20:38,523:INFO:SubProcess create_model() called ==================================
2023-02-28 01:20:38,523:INFO:Initializing create_model()
2023-02-28 01:20:38,523:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB0585A640>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03B50550>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:20:38,523:INFO:Checking exceptions
2023-02-28 01:20:38,523:INFO:Importing libraries
2023-02-28 01:20:38,523:INFO:Copying training dataset
2023-02-28 01:20:38,525:INFO:Defining folds
2023-02-28 01:20:38,525:INFO:Declaring metric variables
2023-02-28 01:20:38,532:INFO:Importing untrained model
2023-02-28 01:20:38,536:INFO:Least Angle Regression Imported successfully
2023-02-28 01:20:38,545:INFO:Starting cross validation
2023-02-28 01:20:38,546:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:20:38,964:INFO:Calculating mean and std
2023-02-28 01:20:38,972:INFO:Creating metrics dataframe
2023-02-28 01:20:38,972:INFO:Uploading results into container
2023-02-28 01:20:38,972:INFO:Uploading model into container now
2023-02-28 01:20:38,972:INFO:_master_model_container: 5
2023-02-28 01:20:38,972:INFO:_display_container: 2
2023-02-28 01:20:38,972:INFO:Lars(random_state=123)
2023-02-28 01:20:38,972:INFO:create_model() successfully completed......................................
2023-02-28 01:20:39,259:INFO:SubProcess create_model() end ==================================
2023-02-28 01:20:39,259:INFO:Creating metrics dataframe
2023-02-28 01:20:39,271:INFO:Initializing Lasso Least Angle Regression
2023-02-28 01:20:39,271:INFO:Total runtime is 0.06482972701390585 minutes
2023-02-28 01:20:39,274:INFO:SubProcess create_model() called ==================================
2023-02-28 01:20:39,276:INFO:Initializing create_model()
2023-02-28 01:20:39,276:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB0585A640>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03B50550>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:20:39,276:INFO:Checking exceptions
2023-02-28 01:20:39,276:INFO:Importing libraries
2023-02-28 01:20:39,276:INFO:Copying training dataset
2023-02-28 01:20:39,280:INFO:Defining folds
2023-02-28 01:20:39,280:INFO:Declaring metric variables
2023-02-28 01:20:39,281:INFO:Importing untrained model
2023-02-28 01:20:39,288:INFO:Lasso Least Angle Regression Imported successfully
2023-02-28 01:20:39,294:INFO:Starting cross validation
2023-02-28 01:20:39,297:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:20:39,666:INFO:Calculating mean and std
2023-02-28 01:20:39,672:INFO:Creating metrics dataframe
2023-02-28 01:20:39,674:INFO:Uploading results into container
2023-02-28 01:20:39,674:INFO:Uploading model into container now
2023-02-28 01:20:39,674:INFO:_master_model_container: 6
2023-02-28 01:20:39,674:INFO:_display_container: 2
2023-02-28 01:20:39,679:INFO:LassoLars(random_state=123)
2023-02-28 01:20:39,679:INFO:create_model() successfully completed......................................
2023-02-28 01:20:39,968:INFO:SubProcess create_model() end ==================================
2023-02-28 01:20:39,968:INFO:Creating metrics dataframe
2023-02-28 01:20:39,982:INFO:Initializing Orthogonal Matching Pursuit
2023-02-28 01:20:39,983:INFO:Total runtime is 0.0766904870669047 minutes
2023-02-28 01:20:39,987:INFO:SubProcess create_model() called ==================================
2023-02-28 01:20:39,987:INFO:Initializing create_model()
2023-02-28 01:20:39,987:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB0585A640>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03B50550>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:20:39,987:INFO:Checking exceptions
2023-02-28 01:20:39,987:INFO:Importing libraries
2023-02-28 01:20:39,987:INFO:Copying training dataset
2023-02-28 01:20:39,992:INFO:Defining folds
2023-02-28 01:20:39,992:INFO:Declaring metric variables
2023-02-28 01:20:39,995:INFO:Importing untrained model
2023-02-28 01:20:40,000:INFO:Orthogonal Matching Pursuit Imported successfully
2023-02-28 01:20:40,008:INFO:Starting cross validation
2023-02-28 01:20:40,008:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:20:40,344:INFO:Calculating mean and std
2023-02-28 01:20:40,344:INFO:Creating metrics dataframe
2023-02-28 01:20:40,348:INFO:Uploading results into container
2023-02-28 01:20:40,348:INFO:Uploading model into container now
2023-02-28 01:20:40,348:INFO:_master_model_container: 7
2023-02-28 01:20:40,348:INFO:_display_container: 2
2023-02-28 01:20:40,348:INFO:OrthogonalMatchingPursuit()
2023-02-28 01:20:40,348:INFO:create_model() successfully completed......................................
2023-02-28 01:20:40,608:INFO:SubProcess create_model() end ==================================
2023-02-28 01:20:40,608:INFO:Creating metrics dataframe
2023-02-28 01:20:40,621:INFO:Initializing Bayesian Ridge
2023-02-28 01:20:40,621:INFO:Total runtime is 0.08732674916585287 minutes
2023-02-28 01:20:40,623:INFO:SubProcess create_model() called ==================================
2023-02-28 01:20:40,623:INFO:Initializing create_model()
2023-02-28 01:20:40,623:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB0585A640>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03B50550>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:20:40,623:INFO:Checking exceptions
2023-02-28 01:20:40,623:INFO:Importing libraries
2023-02-28 01:20:40,623:INFO:Copying training dataset
2023-02-28 01:20:40,632:INFO:Defining folds
2023-02-28 01:20:40,632:INFO:Declaring metric variables
2023-02-28 01:20:40,638:INFO:Importing untrained model
2023-02-28 01:20:40,643:INFO:Bayesian Ridge Imported successfully
2023-02-28 01:20:40,652:INFO:Starting cross validation
2023-02-28 01:20:40,655:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:20:40,958:INFO:Calculating mean and std
2023-02-28 01:20:40,959:INFO:Creating metrics dataframe
2023-02-28 01:20:40,961:INFO:Uploading results into container
2023-02-28 01:20:40,961:INFO:Uploading model into container now
2023-02-28 01:20:40,965:INFO:_master_model_container: 8
2023-02-28 01:20:40,965:INFO:_display_container: 2
2023-02-28 01:20:40,966:INFO:BayesianRidge()
2023-02-28 01:20:40,966:INFO:create_model() successfully completed......................................
2023-02-28 01:20:41,204:INFO:SubProcess create_model() end ==================================
2023-02-28 01:20:41,204:INFO:Creating metrics dataframe
2023-02-28 01:20:41,218:INFO:Initializing Passive Aggressive Regressor
2023-02-28 01:20:41,218:INFO:Total runtime is 0.09727304379145305 minutes
2023-02-28 01:20:41,222:INFO:SubProcess create_model() called ==================================
2023-02-28 01:20:41,222:INFO:Initializing create_model()
2023-02-28 01:20:41,222:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB0585A640>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03B50550>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:20:41,222:INFO:Checking exceptions
2023-02-28 01:20:41,222:INFO:Importing libraries
2023-02-28 01:20:41,222:INFO:Copying training dataset
2023-02-28 01:20:41,222:INFO:Defining folds
2023-02-28 01:20:41,222:INFO:Declaring metric variables
2023-02-28 01:20:41,228:INFO:Importing untrained model
2023-02-28 01:20:41,233:INFO:Passive Aggressive Regressor Imported successfully
2023-02-28 01:20:41,252:INFO:Starting cross validation
2023-02-28 01:20:41,255:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:20:41,613:INFO:Calculating mean and std
2023-02-28 01:20:41,613:INFO:Creating metrics dataframe
2023-02-28 01:20:41,618:INFO:Uploading results into container
2023-02-28 01:20:41,618:INFO:Uploading model into container now
2023-02-28 01:20:41,619:INFO:_master_model_container: 9
2023-02-28 01:20:41,619:INFO:_display_container: 2
2023-02-28 01:20:41,619:INFO:PassiveAggressiveRegressor(random_state=123)
2023-02-28 01:20:41,619:INFO:create_model() successfully completed......................................
2023-02-28 01:20:41,889:INFO:SubProcess create_model() end ==================================
2023-02-28 01:20:41,889:INFO:Creating metrics dataframe
2023-02-28 01:20:41,900:INFO:Initializing Huber Regressor
2023-02-28 01:20:41,900:INFO:Total runtime is 0.10863022406895956 minutes
2023-02-28 01:20:41,906:INFO:SubProcess create_model() called ==================================
2023-02-28 01:20:41,906:INFO:Initializing create_model()
2023-02-28 01:20:41,907:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB0585A640>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03B50550>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:20:41,907:INFO:Checking exceptions
2023-02-28 01:20:41,907:INFO:Importing libraries
2023-02-28 01:20:41,907:INFO:Copying training dataset
2023-02-28 01:20:41,908:INFO:Defining folds
2023-02-28 01:20:41,908:INFO:Declaring metric variables
2023-02-28 01:20:41,916:INFO:Importing untrained model
2023-02-28 01:20:41,918:INFO:Huber Regressor Imported successfully
2023-02-28 01:20:41,928:INFO:Starting cross validation
2023-02-28 01:20:41,935:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:20:42,140:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:20:42,156:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:20:42,164:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:20:42,181:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:20:42,183:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:20:42,188:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:20:42,204:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:20:42,229:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:20:42,237:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:20:42,237:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:20:42,302:INFO:Calculating mean and std
2023-02-28 01:20:42,302:INFO:Creating metrics dataframe
2023-02-28 01:20:42,310:INFO:Uploading results into container
2023-02-28 01:20:42,312:INFO:Uploading model into container now
2023-02-28 01:20:42,312:INFO:_master_model_container: 10
2023-02-28 01:20:42,312:INFO:_display_container: 2
2023-02-28 01:20:42,312:INFO:HuberRegressor()
2023-02-28 01:20:42,312:INFO:create_model() successfully completed......................................
2023-02-28 01:20:42,595:INFO:SubProcess create_model() end ==================================
2023-02-28 01:20:42,595:INFO:Creating metrics dataframe
2023-02-28 01:20:42,609:INFO:Initializing K Neighbors Regressor
2023-02-28 01:20:42,609:INFO:Total runtime is 0.1204508145650228 minutes
2023-02-28 01:20:42,611:INFO:SubProcess create_model() called ==================================
2023-02-28 01:20:42,613:INFO:Initializing create_model()
2023-02-28 01:20:42,613:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB0585A640>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03B50550>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:20:42,613:INFO:Checking exceptions
2023-02-28 01:20:42,613:INFO:Importing libraries
2023-02-28 01:20:42,613:INFO:Copying training dataset
2023-02-28 01:20:42,618:INFO:Defining folds
2023-02-28 01:20:42,618:INFO:Declaring metric variables
2023-02-28 01:20:42,618:INFO:Importing untrained model
2023-02-28 01:20:42,626:INFO:K Neighbors Regressor Imported successfully
2023-02-28 01:20:42,633:INFO:Starting cross validation
2023-02-28 01:20:42,635:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:20:42,971:INFO:Calculating mean and std
2023-02-28 01:20:42,971:INFO:Creating metrics dataframe
2023-02-28 01:20:42,977:INFO:Uploading results into container
2023-02-28 01:20:42,977:INFO:Uploading model into container now
2023-02-28 01:20:42,977:INFO:_master_model_container: 11
2023-02-28 01:20:42,977:INFO:_display_container: 2
2023-02-28 01:20:42,977:INFO:KNeighborsRegressor(n_jobs=-1)
2023-02-28 01:20:42,977:INFO:create_model() successfully completed......................................
2023-02-28 01:20:43,214:INFO:SubProcess create_model() end ==================================
2023-02-28 01:20:43,214:INFO:Creating metrics dataframe
2023-02-28 01:20:43,224:INFO:Initializing Decision Tree Regressor
2023-02-28 01:20:43,224:INFO:Total runtime is 0.1307104031244914 minutes
2023-02-28 01:20:43,228:INFO:SubProcess create_model() called ==================================
2023-02-28 01:20:43,230:INFO:Initializing create_model()
2023-02-28 01:20:43,230:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB0585A640>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03B50550>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:20:43,230:INFO:Checking exceptions
2023-02-28 01:20:43,230:INFO:Importing libraries
2023-02-28 01:20:43,230:INFO:Copying training dataset
2023-02-28 01:20:43,231:INFO:Defining folds
2023-02-28 01:20:43,236:INFO:Declaring metric variables
2023-02-28 01:20:43,240:INFO:Importing untrained model
2023-02-28 01:20:43,246:INFO:Decision Tree Regressor Imported successfully
2023-02-28 01:20:43,253:INFO:Starting cross validation
2023-02-28 01:20:43,258:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:20:43,570:INFO:Calculating mean and std
2023-02-28 01:20:43,570:INFO:Creating metrics dataframe
2023-02-28 01:20:43,575:INFO:Uploading results into container
2023-02-28 01:20:43,575:INFO:Uploading model into container now
2023-02-28 01:20:43,575:INFO:_master_model_container: 12
2023-02-28 01:20:43,575:INFO:_display_container: 2
2023-02-28 01:20:43,577:INFO:DecisionTreeRegressor(random_state=123)
2023-02-28 01:20:43,577:INFO:create_model() successfully completed......................................
2023-02-28 01:20:43,813:INFO:SubProcess create_model() end ==================================
2023-02-28 01:20:43,813:INFO:Creating metrics dataframe
2023-02-28 01:20:43,831:INFO:Initializing Random Forest Regressor
2023-02-28 01:20:43,831:INFO:Total runtime is 0.1408271352450053 minutes
2023-02-28 01:20:43,834:INFO:SubProcess create_model() called ==================================
2023-02-28 01:20:43,836:INFO:Initializing create_model()
2023-02-28 01:20:43,836:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB0585A640>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03B50550>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:20:43,836:INFO:Checking exceptions
2023-02-28 01:20:43,836:INFO:Importing libraries
2023-02-28 01:20:43,836:INFO:Copying training dataset
2023-02-28 01:20:43,838:INFO:Defining folds
2023-02-28 01:20:43,838:INFO:Declaring metric variables
2023-02-28 01:20:43,844:INFO:Importing untrained model
2023-02-28 01:20:43,847:INFO:Random Forest Regressor Imported successfully
2023-02-28 01:20:43,854:INFO:Starting cross validation
2023-02-28 01:20:43,858:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:20:44,301:INFO:Calculating mean and std
2023-02-28 01:20:44,301:INFO:Creating metrics dataframe
2023-02-28 01:20:44,307:INFO:Uploading results into container
2023-02-28 01:20:44,307:INFO:Uploading model into container now
2023-02-28 01:20:44,307:INFO:_master_model_container: 13
2023-02-28 01:20:44,307:INFO:_display_container: 2
2023-02-28 01:20:44,307:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-02-28 01:20:44,309:INFO:create_model() successfully completed......................................
2023-02-28 01:20:44,536:INFO:SubProcess create_model() end ==================================
2023-02-28 01:20:44,536:INFO:Creating metrics dataframe
2023-02-28 01:20:44,552:INFO:Initializing Extra Trees Regressor
2023-02-28 01:20:44,552:INFO:Total runtime is 0.15283746719360353 minutes
2023-02-28 01:20:44,560:INFO:SubProcess create_model() called ==================================
2023-02-28 01:20:44,560:INFO:Initializing create_model()
2023-02-28 01:20:44,560:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB0585A640>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03B50550>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:20:44,560:INFO:Checking exceptions
2023-02-28 01:20:44,560:INFO:Importing libraries
2023-02-28 01:20:44,560:INFO:Copying training dataset
2023-02-28 01:20:44,562:INFO:Defining folds
2023-02-28 01:20:44,562:INFO:Declaring metric variables
2023-02-28 01:20:44,568:INFO:Importing untrained model
2023-02-28 01:20:44,572:INFO:Extra Trees Regressor Imported successfully
2023-02-28 01:20:44,581:INFO:Starting cross validation
2023-02-28 01:20:44,581:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:20:45,083:INFO:Calculating mean and std
2023-02-28 01:20:45,083:INFO:Creating metrics dataframe
2023-02-28 01:20:45,090:INFO:Uploading results into container
2023-02-28 01:20:45,093:INFO:Uploading model into container now
2023-02-28 01:20:45,093:INFO:_master_model_container: 14
2023-02-28 01:20:45,093:INFO:_display_container: 2
2023-02-28 01:20:45,094:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-02-28 01:20:45,094:INFO:create_model() successfully completed......................................
2023-02-28 01:20:45,333:INFO:SubProcess create_model() end ==================================
2023-02-28 01:20:45,333:INFO:Creating metrics dataframe
2023-02-28 01:20:45,349:INFO:Initializing AdaBoost Regressor
2023-02-28 01:20:45,349:INFO:Total runtime is 0.16611476341883344 minutes
2023-02-28 01:20:45,357:INFO:SubProcess create_model() called ==================================
2023-02-28 01:20:45,357:INFO:Initializing create_model()
2023-02-28 01:20:45,357:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB0585A640>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03B50550>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:20:45,357:INFO:Checking exceptions
2023-02-28 01:20:45,357:INFO:Importing libraries
2023-02-28 01:20:45,357:INFO:Copying training dataset
2023-02-28 01:20:45,359:INFO:Defining folds
2023-02-28 01:20:45,359:INFO:Declaring metric variables
2023-02-28 01:20:45,365:INFO:Importing untrained model
2023-02-28 01:20:45,370:INFO:AdaBoost Regressor Imported successfully
2023-02-28 01:20:45,382:INFO:Starting cross validation
2023-02-28 01:20:45,382:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:20:45,739:INFO:Calculating mean and std
2023-02-28 01:20:45,739:INFO:Creating metrics dataframe
2023-02-28 01:20:45,746:INFO:Uploading results into container
2023-02-28 01:20:45,746:INFO:Uploading model into container now
2023-02-28 01:20:45,747:INFO:_master_model_container: 15
2023-02-28 01:20:45,747:INFO:_display_container: 2
2023-02-28 01:20:45,747:INFO:AdaBoostRegressor(random_state=123)
2023-02-28 01:20:45,747:INFO:create_model() successfully completed......................................
2023-02-28 01:20:45,986:INFO:SubProcess create_model() end ==================================
2023-02-28 01:20:45,986:INFO:Creating metrics dataframe
2023-02-28 01:20:45,998:INFO:Initializing Gradient Boosting Regressor
2023-02-28 01:20:45,998:INFO:Total runtime is 0.1769373655319214 minutes
2023-02-28 01:20:46,003:INFO:SubProcess create_model() called ==================================
2023-02-28 01:20:46,003:INFO:Initializing create_model()
2023-02-28 01:20:46,003:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB0585A640>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03B50550>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:20:46,004:INFO:Checking exceptions
2023-02-28 01:20:46,004:INFO:Importing libraries
2023-02-28 01:20:46,004:INFO:Copying training dataset
2023-02-28 01:20:46,008:INFO:Defining folds
2023-02-28 01:20:46,008:INFO:Declaring metric variables
2023-02-28 01:20:46,012:INFO:Importing untrained model
2023-02-28 01:20:46,016:INFO:Gradient Boosting Regressor Imported successfully
2023-02-28 01:20:46,035:INFO:Starting cross validation
2023-02-28 01:20:46,038:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:20:46,444:INFO:Calculating mean and std
2023-02-28 01:20:46,444:INFO:Creating metrics dataframe
2023-02-28 01:20:46,449:INFO:Uploading results into container
2023-02-28 01:20:46,449:INFO:Uploading model into container now
2023-02-28 01:20:46,449:INFO:_master_model_container: 16
2023-02-28 01:20:46,449:INFO:_display_container: 2
2023-02-28 01:20:46,449:INFO:GradientBoostingRegressor(random_state=123)
2023-02-28 01:20:46,449:INFO:create_model() successfully completed......................................
2023-02-28 01:20:46,678:INFO:SubProcess create_model() end ==================================
2023-02-28 01:20:46,678:INFO:Creating metrics dataframe
2023-02-28 01:20:46,686:INFO:Initializing Extreme Gradient Boosting
2023-02-28 01:20:46,686:INFO:Total runtime is 0.18840840657552085 minutes
2023-02-28 01:20:46,696:INFO:SubProcess create_model() called ==================================
2023-02-28 01:20:46,696:INFO:Initializing create_model()
2023-02-28 01:20:46,696:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB0585A640>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03B50550>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:20:46,696:INFO:Checking exceptions
2023-02-28 01:20:46,696:INFO:Importing libraries
2023-02-28 01:20:46,696:INFO:Copying training dataset
2023-02-28 01:20:46,704:INFO:Defining folds
2023-02-28 01:20:46,704:INFO:Declaring metric variables
2023-02-28 01:20:46,705:INFO:Importing untrained model
2023-02-28 01:20:46,713:INFO:Extreme Gradient Boosting Imported successfully
2023-02-28 01:20:46,724:INFO:Starting cross validation
2023-02-28 01:20:46,726:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:20:47,204:INFO:Calculating mean and std
2023-02-28 01:20:47,204:INFO:Creating metrics dataframe
2023-02-28 01:20:47,211:INFO:Uploading results into container
2023-02-28 01:20:47,212:INFO:Uploading model into container now
2023-02-28 01:20:47,212:INFO:_master_model_container: 17
2023-02-28 01:20:47,212:INFO:_display_container: 2
2023-02-28 01:20:47,212:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=123, ...)
2023-02-28 01:20:47,212:INFO:create_model() successfully completed......................................
2023-02-28 01:20:47,438:INFO:SubProcess create_model() end ==================================
2023-02-28 01:20:47,438:INFO:Creating metrics dataframe
2023-02-28 01:20:47,456:INFO:Initializing Light Gradient Boosting Machine
2023-02-28 01:20:47,456:INFO:Total runtime is 0.20124388933181764 minutes
2023-02-28 01:20:47,460:INFO:SubProcess create_model() called ==================================
2023-02-28 01:20:47,460:INFO:Initializing create_model()
2023-02-28 01:20:47,461:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB0585A640>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03B50550>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:20:47,461:INFO:Checking exceptions
2023-02-28 01:20:47,461:INFO:Importing libraries
2023-02-28 01:20:47,461:INFO:Copying training dataset
2023-02-28 01:20:47,465:INFO:Defining folds
2023-02-28 01:20:47,465:INFO:Declaring metric variables
2023-02-28 01:20:47,466:INFO:Importing untrained model
2023-02-28 01:20:47,471:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-28 01:20:47,479:INFO:Starting cross validation
2023-02-28 01:20:47,479:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:20:47,862:INFO:Calculating mean and std
2023-02-28 01:20:47,862:INFO:Creating metrics dataframe
2023-02-28 01:20:47,867:INFO:Uploading results into container
2023-02-28 01:20:47,867:INFO:Uploading model into container now
2023-02-28 01:20:47,869:INFO:_master_model_container: 18
2023-02-28 01:20:47,869:INFO:_display_container: 2
2023-02-28 01:20:47,870:INFO:LGBMRegressor(random_state=123)
2023-02-28 01:20:47,870:INFO:create_model() successfully completed......................................
2023-02-28 01:20:48,104:INFO:SubProcess create_model() end ==================================
2023-02-28 01:20:48,104:INFO:Creating metrics dataframe
2023-02-28 01:20:48,120:INFO:Initializing Dummy Regressor
2023-02-28 01:20:48,120:INFO:Total runtime is 0.21230840682983398 minutes
2023-02-28 01:20:48,124:INFO:SubProcess create_model() called ==================================
2023-02-28 01:20:48,124:INFO:Initializing create_model()
2023-02-28 01:20:48,124:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB0585A640>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03B50550>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:20:48,124:INFO:Checking exceptions
2023-02-28 01:20:48,124:INFO:Importing libraries
2023-02-28 01:20:48,124:INFO:Copying training dataset
2023-02-28 01:20:48,130:INFO:Defining folds
2023-02-28 01:20:48,130:INFO:Declaring metric variables
2023-02-28 01:20:48,135:INFO:Importing untrained model
2023-02-28 01:20:48,138:INFO:Dummy Regressor Imported successfully
2023-02-28 01:20:48,147:INFO:Starting cross validation
2023-02-28 01:20:48,148:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:20:48,430:INFO:Calculating mean and std
2023-02-28 01:20:48,430:INFO:Creating metrics dataframe
2023-02-28 01:20:48,437:INFO:Uploading results into container
2023-02-28 01:20:48,437:INFO:Uploading model into container now
2023-02-28 01:20:48,438:INFO:_master_model_container: 19
2023-02-28 01:20:48,438:INFO:_display_container: 2
2023-02-28 01:20:48,438:INFO:DummyRegressor()
2023-02-28 01:20:48,438:INFO:create_model() successfully completed......................................
2023-02-28 01:20:48,670:INFO:SubProcess create_model() end ==================================
2023-02-28 01:20:48,670:INFO:Creating metrics dataframe
2023-02-28 01:20:48,701:INFO:Initializing create_model()
2023-02-28 01:20:48,701:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB0585A640>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:20:48,701:INFO:Checking exceptions
2023-02-28 01:20:48,702:INFO:Importing libraries
2023-02-28 01:20:48,702:INFO:Copying training dataset
2023-02-28 01:20:48,704:INFO:Defining folds
2023-02-28 01:20:48,704:INFO:Declaring metric variables
2023-02-28 01:20:48,704:INFO:Importing untrained model
2023-02-28 01:20:48,704:INFO:Declaring custom model
2023-02-28 01:20:48,704:INFO:Gradient Boosting Regressor Imported successfully
2023-02-28 01:20:48,704:INFO:Cross validation set to False
2023-02-28 01:20:48,704:INFO:Fitting Model
2023-02-28 01:20:48,885:INFO:GradientBoostingRegressor(random_state=123)
2023-02-28 01:20:48,885:INFO:create_model() successfully completed......................................
2023-02-28 01:20:49,174:INFO:_master_model_container: 19
2023-02-28 01:20:49,174:INFO:_display_container: 2
2023-02-28 01:20:49,174:INFO:GradientBoostingRegressor(random_state=123)
2023-02-28 01:20:49,174:INFO:compare_models() successfully completed......................................
2023-02-28 01:23:26,516:INFO:gpu_param set to False
2023-02-28 01:23:26,670:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:23:26,678:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:23:26,838:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:23:26,840:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:32:28,617:INFO:PyCaret RegressionExperiment
2023-02-28 01:32:28,617:INFO:Logging name: reg-default-name
2023-02-28 01:32:28,617:INFO:ML Usecase: MLUsecase.REGRESSION
2023-02-28 01:32:28,617:INFO:version 3.0.0.rc9
2023-02-28 01:32:28,617:INFO:Initializing setup()
2023-02-28 01:32:28,617:INFO:self.USI: 51dd
2023-02-28 01:32:28,617:INFO:self._variable_keys: {'transform_target_param', 'log_plots_param', 'X_test', 'gpu_n_jobs_param', '_ml_usecase', 'memory', 'data', 'seed', 'y', 'y_test', 'X', 'fold_generator', 'fold_shuffle_param', 'target_param', 'n_jobs_param', 'y_train', 'exp_id', 'logging_param', 'idx', '_available_plots', 'USI', 'X_train', 'fold_groups_param', 'pipeline', 'html_param', 'gpu_param', 'exp_name_log'}
2023-02-28 01:32:28,617:INFO:Checking environment
2023-02-28 01:32:28,617:INFO:python_version: 3.8.16
2023-02-28 01:32:28,617:INFO:python_build: ('default', 'Jan 17 2023 22:25:28')
2023-02-28 01:32:28,617:INFO:machine: AMD64
2023-02-28 01:32:28,617:INFO:platform: Windows-10-10.0.22621-SP0
2023-02-28 01:32:28,634:INFO:Memory: svmem(total=14702026752, available=4462174208, percent=69.6, used=10239852544, free=4462174208)
2023-02-28 01:32:28,634:INFO:Physical Core: 8
2023-02-28 01:32:28,634:INFO:Logical Core: 16
2023-02-28 01:32:28,634:INFO:Checking libraries
2023-02-28 01:32:28,634:INFO:System:
2023-02-28 01:32:28,634:INFO:    python: 3.8.16 (default, Jan 17 2023, 22:25:28) [MSC v.1916 64 bit (AMD64)]
2023-02-28 01:32:28,634:INFO:executable: c:\Users\takis\anaconda3\envs\caretenv\python.exe
2023-02-28 01:32:28,634:INFO:   machine: Windows-10-10.0.22621-SP0
2023-02-28 01:32:28,634:INFO:PyCaret required dependencies:
2023-02-28 01:32:28,634:INFO:                 pip: 22.3.1
2023-02-28 01:32:28,634:INFO:          setuptools: 60.10.0
2023-02-28 01:32:28,634:INFO:             pycaret: 3.0.0rc9
2023-02-28 01:32:28,634:INFO:             IPython: 8.10.0
2023-02-28 01:32:28,634:INFO:          ipywidgets: 8.0.4
2023-02-28 01:32:28,634:INFO:                tqdm: 4.64.1
2023-02-28 01:32:28,634:INFO:               numpy: 1.23.5
2023-02-28 01:32:28,634:INFO:              pandas: 1.5.3
2023-02-28 01:32:28,634:INFO:              jinja2: 3.1.2
2023-02-28 01:32:28,634:INFO:               scipy: 1.10.1
2023-02-28 01:32:28,634:INFO:              joblib: 1.2.0
2023-02-28 01:32:28,642:INFO:             sklearn: 1.2.1
2023-02-28 01:32:28,642:INFO:                pyod: 1.0.7
2023-02-28 01:32:28,642:INFO:            imblearn: 0.10.1
2023-02-28 01:32:28,642:INFO:   category_encoders: 2.6.0
2023-02-28 01:32:28,642:INFO:            lightgbm: 3.3.5
2023-02-28 01:32:28,642:INFO:               numba: 0.56.4
2023-02-28 01:32:28,642:INFO:            requests: 2.28.2
2023-02-28 01:32:28,642:INFO:          matplotlib: 3.7.0
2023-02-28 01:32:28,642:INFO:          scikitplot: 0.3.7
2023-02-28 01:32:28,642:INFO:         yellowbrick: 1.5
2023-02-28 01:32:28,642:INFO:              plotly: 5.13.1
2023-02-28 01:32:28,642:INFO:             kaleido: 0.2.1
2023-02-28 01:32:28,642:INFO:         statsmodels: 0.13.5
2023-02-28 01:32:28,642:INFO:              sktime: 0.16.1
2023-02-28 01:32:28,642:INFO:               tbats: 1.1.2
2023-02-28 01:32:28,642:INFO:            pmdarima: 2.0.2
2023-02-28 01:32:28,642:INFO:              psutil: 5.9.4
2023-02-28 01:32:28,642:INFO:PyCaret optional dependencies:
2023-02-28 01:32:28,642:INFO:                shap: Not installed
2023-02-28 01:32:28,642:INFO:           interpret: Not installed
2023-02-28 01:32:28,642:INFO:                umap: Not installed
2023-02-28 01:32:28,642:INFO:    pandas_profiling: Not installed
2023-02-28 01:32:28,642:INFO:  explainerdashboard: Not installed
2023-02-28 01:32:28,642:INFO:             autoviz: 0.1.58
2023-02-28 01:32:28,642:INFO:           fairlearn: Not installed
2023-02-28 01:32:28,642:INFO:             xgboost: 1.7.4
2023-02-28 01:32:28,642:INFO:            catboost: Not installed
2023-02-28 01:32:28,642:INFO:              kmodes: Not installed
2023-02-28 01:32:28,642:INFO:             mlxtend: Not installed
2023-02-28 01:32:28,642:INFO:       statsforecast: Not installed
2023-02-28 01:32:28,642:INFO:        tune_sklearn: Not installed
2023-02-28 01:32:28,642:INFO:                 ray: Not installed
2023-02-28 01:32:28,642:INFO:            hyperopt: Not installed
2023-02-28 01:32:28,642:INFO:              optuna: Not installed
2023-02-28 01:32:28,642:INFO:               skopt: Not installed
2023-02-28 01:32:28,642:INFO:              mlflow: 1.30.0
2023-02-28 01:32:28,642:INFO:              gradio: 3.19.1
2023-02-28 01:32:28,642:INFO:             fastapi: 0.92.0
2023-02-28 01:32:28,642:INFO:             uvicorn: 0.20.0
2023-02-28 01:32:28,642:INFO:              m2cgen: 0.10.0
2023-02-28 01:32:28,642:INFO:           evidently: 0.2.5
2023-02-28 01:32:28,642:INFO:               fugue: Not installed
2023-02-28 01:32:28,642:INFO:           streamlit: Not installed
2023-02-28 01:32:28,642:INFO:             prophet: Not installed
2023-02-28 01:32:28,642:INFO:None
2023-02-28 01:32:28,642:INFO:Set up data.
2023-02-28 01:32:28,650:INFO:Set up train/test split.
2023-02-28 01:32:28,657:INFO:Set up index.
2023-02-28 01:32:28,657:INFO:Set up folding strategy.
2023-02-28 01:32:28,657:INFO:Assigning column types.
2023-02-28 01:32:28,657:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-28 01:32:28,666:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-28 01:32:28,666:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-28 01:32:28,673:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 01:32:28,749:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:32:28,806:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 01:32:28,806:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:32:28,813:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:32:28,814:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-28 01:32:28,820:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-28 01:32:28,824:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 01:32:28,898:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:32:28,955:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 01:32:28,955:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:32:28,965:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:32:28,968:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-02-28 01:32:28,971:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-28 01:32:28,980:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 01:32:29,062:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:32:29,120:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 01:32:29,128:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:32:29,131:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:32:29,136:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-28 01:32:29,144:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 01:32:29,234:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:32:29,296:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 01:32:29,297:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:32:29,301:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:32:29,301:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-02-28 01:32:29,308:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 01:32:29,388:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:32:29,438:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 01:32:29,438:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:32:29,438:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:32:29,455:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 01:32:29,519:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:32:29,565:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 01:32:29,565:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:32:29,565:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:32:29,565:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-02-28 01:32:29,634:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:32:29,675:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 01:32:29,675:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:32:29,683:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:32:29,748:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:32:29,799:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 01:32:29,799:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:32:29,799:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:32:29,799:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-28 01:32:29,876:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:32:29,921:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:32:29,924:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:32:29,988:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:32:30,040:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:32:30,040:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:32:30,040:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-02-28 01:32:30,178:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:32:30,178:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:32:30,318:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:32:30,320:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:32:30,320:INFO:Preparing preprocessing pipeline...
2023-02-28 01:32:30,320:INFO:Set up simple imputation.
2023-02-28 01:32:30,324:INFO:Set up encoding of ordinal features.
2023-02-28 01:32:30,324:INFO:Set up encoding of categorical features.
2023-02-28 01:32:30,397:INFO:Finished creating preprocessing pipeline.
2023-02-28 01:32:30,422:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\takis\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                     'smoker'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64},
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-02-28 01:32:30,422:INFO:Creating final display dataframe.
2023-02-28 01:32:30,759:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           charges
2                   Target type        Regression
3           Original data shape         (1338, 7)
4        Transformed data shape        (1338, 10)
5   Transformed train set shape         (936, 10)
6    Transformed test set shape         (402, 10)
7              Ordinal features                 2
8              Numeric features                 3
9          Categorical features                 3
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              51dd
2023-02-28 01:32:30,890:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:32:30,890:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:32:31,013:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:32:31,018:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:32:31,018:INFO:setup() successfully completed in 2.4s...............
2023-02-28 01:33:10,023:INFO:gpu_param set to False
2023-02-28 01:33:10,169:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:33:10,178:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:33:10,332:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:33:10,340:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:37:30,046:INFO:PyCaret RegressionExperiment
2023-02-28 01:37:30,046:INFO:Logging name: reg-default-name
2023-02-28 01:37:30,046:INFO:ML Usecase: MLUsecase.REGRESSION
2023-02-28 01:37:30,046:INFO:version 3.0.0.rc9
2023-02-28 01:37:30,046:INFO:Initializing setup()
2023-02-28 01:37:30,046:INFO:self.USI: 01fd
2023-02-28 01:37:30,046:INFO:self._variable_keys: {'transform_target_param', 'log_plots_param', 'X_test', 'gpu_n_jobs_param', '_ml_usecase', 'memory', 'data', 'seed', 'y', 'y_test', 'X', 'fold_generator', 'fold_shuffle_param', 'target_param', 'n_jobs_param', 'y_train', 'exp_id', 'logging_param', 'idx', '_available_plots', 'USI', 'X_train', 'fold_groups_param', 'pipeline', 'html_param', 'gpu_param', 'exp_name_log'}
2023-02-28 01:37:30,046:INFO:Checking environment
2023-02-28 01:37:30,046:INFO:python_version: 3.8.16
2023-02-28 01:37:30,046:INFO:python_build: ('default', 'Jan 17 2023 22:25:28')
2023-02-28 01:37:30,046:INFO:machine: AMD64
2023-02-28 01:37:30,046:INFO:platform: Windows-10-10.0.22621-SP0
2023-02-28 01:37:30,061:INFO:Memory: svmem(total=14702026752, available=4554268672, percent=69.0, used=10147758080, free=4554268672)
2023-02-28 01:37:30,062:INFO:Physical Core: 8
2023-02-28 01:37:30,062:INFO:Logical Core: 16
2023-02-28 01:37:30,062:INFO:Checking libraries
2023-02-28 01:37:30,062:INFO:System:
2023-02-28 01:37:30,062:INFO:    python: 3.8.16 (default, Jan 17 2023, 22:25:28) [MSC v.1916 64 bit (AMD64)]
2023-02-28 01:37:30,062:INFO:executable: c:\Users\takis\anaconda3\envs\caretenv\python.exe
2023-02-28 01:37:30,062:INFO:   machine: Windows-10-10.0.22621-SP0
2023-02-28 01:37:30,062:INFO:PyCaret required dependencies:
2023-02-28 01:37:30,062:INFO:                 pip: 22.3.1
2023-02-28 01:37:30,062:INFO:          setuptools: 60.10.0
2023-02-28 01:37:30,062:INFO:             pycaret: 3.0.0rc9
2023-02-28 01:37:30,062:INFO:             IPython: 8.10.0
2023-02-28 01:37:30,062:INFO:          ipywidgets: 8.0.4
2023-02-28 01:37:30,062:INFO:                tqdm: 4.64.1
2023-02-28 01:37:30,062:INFO:               numpy: 1.23.5
2023-02-28 01:37:30,062:INFO:              pandas: 1.5.3
2023-02-28 01:37:30,062:INFO:              jinja2: 3.1.2
2023-02-28 01:37:30,062:INFO:               scipy: 1.10.1
2023-02-28 01:37:30,062:INFO:              joblib: 1.2.0
2023-02-28 01:37:30,062:INFO:             sklearn: 1.2.1
2023-02-28 01:37:30,062:INFO:                pyod: 1.0.7
2023-02-28 01:37:30,062:INFO:            imblearn: 0.10.1
2023-02-28 01:37:30,062:INFO:   category_encoders: 2.6.0
2023-02-28 01:37:30,062:INFO:            lightgbm: 3.3.5
2023-02-28 01:37:30,062:INFO:               numba: 0.56.4
2023-02-28 01:37:30,062:INFO:            requests: 2.28.2
2023-02-28 01:37:30,062:INFO:          matplotlib: 3.7.0
2023-02-28 01:37:30,062:INFO:          scikitplot: 0.3.7
2023-02-28 01:37:30,062:INFO:         yellowbrick: 1.5
2023-02-28 01:37:30,062:INFO:              plotly: 5.13.1
2023-02-28 01:37:30,065:INFO:             kaleido: 0.2.1
2023-02-28 01:37:30,065:INFO:         statsmodels: 0.13.5
2023-02-28 01:37:30,065:INFO:              sktime: 0.16.1
2023-02-28 01:37:30,065:INFO:               tbats: 1.1.2
2023-02-28 01:37:30,065:INFO:            pmdarima: 2.0.2
2023-02-28 01:37:30,065:INFO:              psutil: 5.9.4
2023-02-28 01:37:30,065:INFO:PyCaret optional dependencies:
2023-02-28 01:37:30,065:INFO:                shap: Not installed
2023-02-28 01:37:30,065:INFO:           interpret: Not installed
2023-02-28 01:37:30,065:INFO:                umap: Not installed
2023-02-28 01:37:30,065:INFO:    pandas_profiling: Not installed
2023-02-28 01:37:30,065:INFO:  explainerdashboard: Not installed
2023-02-28 01:37:30,065:INFO:             autoviz: 0.1.58
2023-02-28 01:37:30,065:INFO:           fairlearn: Not installed
2023-02-28 01:37:30,065:INFO:             xgboost: 1.7.4
2023-02-28 01:37:30,065:INFO:            catboost: Not installed
2023-02-28 01:37:30,065:INFO:              kmodes: Not installed
2023-02-28 01:37:30,065:INFO:             mlxtend: Not installed
2023-02-28 01:37:30,065:INFO:       statsforecast: Not installed
2023-02-28 01:37:30,065:INFO:        tune_sklearn: Not installed
2023-02-28 01:37:30,065:INFO:                 ray: Not installed
2023-02-28 01:37:30,065:INFO:            hyperopt: Not installed
2023-02-28 01:37:30,065:INFO:              optuna: Not installed
2023-02-28 01:37:30,065:INFO:               skopt: Not installed
2023-02-28 01:37:30,065:INFO:              mlflow: 1.30.0
2023-02-28 01:37:30,065:INFO:              gradio: 3.19.1
2023-02-28 01:37:30,065:INFO:             fastapi: 0.92.0
2023-02-28 01:37:30,065:INFO:             uvicorn: 0.20.0
2023-02-28 01:37:30,065:INFO:              m2cgen: 0.10.0
2023-02-28 01:37:30,065:INFO:           evidently: 0.2.5
2023-02-28 01:37:30,065:INFO:               fugue: Not installed
2023-02-28 01:37:30,065:INFO:           streamlit: Not installed
2023-02-28 01:37:30,065:INFO:             prophet: Not installed
2023-02-28 01:37:30,065:INFO:None
2023-02-28 01:37:30,065:INFO:Set up data.
2023-02-28 01:37:30,075:INFO:Set up train/test split.
2023-02-28 01:37:30,079:INFO:Set up index.
2023-02-28 01:37:30,082:INFO:Set up folding strategy.
2023-02-28 01:37:30,082:INFO:Assigning column types.
2023-02-28 01:37:30,082:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-28 01:37:30,082:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-28 01:37:30,091:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-28 01:37:30,096:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 01:37:30,179:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:37:30,235:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 01:37:30,235:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:37:30,244:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:37:30,244:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-28 01:37:30,244:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-28 01:37:30,252:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 01:37:30,333:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:37:30,398:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 01:37:30,398:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:37:30,398:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:37:30,398:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-02-28 01:37:30,409:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-28 01:37:30,417:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 01:37:30,505:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:37:30,552:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 01:37:30,552:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:37:30,559:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:37:30,559:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-28 01:37:30,567:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 01:37:30,631:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:37:30,680:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 01:37:30,680:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:37:30,680:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:37:30,680:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-02-28 01:37:30,696:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 01:37:30,752:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:37:30,801:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 01:37:30,801:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:37:30,801:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:37:30,809:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 01:37:30,866:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:37:30,914:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 01:37:30,914:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:37:30,914:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:37:30,914:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-02-28 01:37:30,980:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:37:31,015:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 01:37:31,015:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:37:31,021:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:37:31,082:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:37:31,127:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 01:37:31,127:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:37:31,127:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:37:31,127:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-28 01:37:31,201:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:37:31,242:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:37:31,251:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:37:31,313:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:37:31,357:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:37:31,360:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:37:31,360:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-02-28 01:37:31,479:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:37:31,479:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:37:31,594:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:37:31,594:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:37:31,602:INFO:Preparing preprocessing pipeline...
2023-02-28 01:37:31,602:INFO:Set up simple imputation.
2023-02-28 01:37:31,602:INFO:Set up encoding of ordinal features.
2023-02-28 01:37:31,602:INFO:Set up encoding of categorical features.
2023-02-28 01:37:31,667:INFO:Finished creating preprocessing pipeline.
2023-02-28 01:37:31,698:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\takis\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                     'smoker'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64},
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-02-28 01:37:31,698:INFO:Creating final display dataframe.
2023-02-28 01:37:32,026:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           charges
2                   Target type        Regression
3           Original data shape         (1338, 7)
4        Transformed data shape        (1338, 10)
5   Transformed train set shape         (936, 10)
6    Transformed test set shape         (402, 10)
7              Ordinal features                 2
8              Numeric features                 3
9          Categorical features                 3
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              01fd
2023-02-28 01:37:32,156:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:37:32,162:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:37:32,259:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:37:32,267:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:37:32,267:INFO:setup() successfully completed in 2.23s...............
2023-02-28 01:39:20,348:INFO:PyCaret RegressionExperiment
2023-02-28 01:39:20,348:INFO:Logging name: reg-default-name
2023-02-28 01:39:20,348:INFO:ML Usecase: MLUsecase.REGRESSION
2023-02-28 01:39:20,348:INFO:version 3.0.0.rc9
2023-02-28 01:39:20,348:INFO:Initializing setup()
2023-02-28 01:39:20,348:INFO:self.USI: 87d4
2023-02-28 01:39:20,348:INFO:self._variable_keys: {'transform_target_param', 'log_plots_param', 'X_test', 'gpu_n_jobs_param', '_ml_usecase', 'memory', 'data', 'seed', 'y', 'y_test', 'X', 'fold_generator', 'fold_shuffle_param', 'target_param', 'n_jobs_param', 'y_train', 'exp_id', 'logging_param', 'idx', '_available_plots', 'USI', 'X_train', 'fold_groups_param', 'pipeline', 'html_param', 'gpu_param', 'exp_name_log'}
2023-02-28 01:39:20,348:INFO:Checking environment
2023-02-28 01:39:20,348:INFO:python_version: 3.8.16
2023-02-28 01:39:20,348:INFO:python_build: ('default', 'Jan 17 2023 22:25:28')
2023-02-28 01:39:20,348:INFO:machine: AMD64
2023-02-28 01:39:20,348:INFO:platform: Windows-10-10.0.22621-SP0
2023-02-28 01:39:20,364:INFO:Memory: svmem(total=14702026752, available=4400087040, percent=70.1, used=10301939712, free=4400087040)
2023-02-28 01:39:20,364:INFO:Physical Core: 8
2023-02-28 01:39:20,364:INFO:Logical Core: 16
2023-02-28 01:39:20,364:INFO:Checking libraries
2023-02-28 01:39:20,364:INFO:System:
2023-02-28 01:39:20,364:INFO:    python: 3.8.16 (default, Jan 17 2023, 22:25:28) [MSC v.1916 64 bit (AMD64)]
2023-02-28 01:39:20,364:INFO:executable: c:\Users\takis\anaconda3\envs\caretenv\python.exe
2023-02-28 01:39:20,364:INFO:   machine: Windows-10-10.0.22621-SP0
2023-02-28 01:39:20,364:INFO:PyCaret required dependencies:
2023-02-28 01:39:20,364:INFO:                 pip: 22.3.1
2023-02-28 01:39:20,364:INFO:          setuptools: 60.10.0
2023-02-28 01:39:20,364:INFO:             pycaret: 3.0.0rc9
2023-02-28 01:39:20,364:INFO:             IPython: 8.10.0
2023-02-28 01:39:20,364:INFO:          ipywidgets: 8.0.4
2023-02-28 01:39:20,364:INFO:                tqdm: 4.64.1
2023-02-28 01:39:20,364:INFO:               numpy: 1.23.5
2023-02-28 01:39:20,364:INFO:              pandas: 1.5.3
2023-02-28 01:39:20,364:INFO:              jinja2: 3.1.2
2023-02-28 01:39:20,364:INFO:               scipy: 1.10.1
2023-02-28 01:39:20,364:INFO:              joblib: 1.2.0
2023-02-28 01:39:20,364:INFO:             sklearn: 1.2.1
2023-02-28 01:39:20,364:INFO:                pyod: 1.0.7
2023-02-28 01:39:20,364:INFO:            imblearn: 0.10.1
2023-02-28 01:39:20,364:INFO:   category_encoders: 2.6.0
2023-02-28 01:39:20,364:INFO:            lightgbm: 3.3.5
2023-02-28 01:39:20,364:INFO:               numba: 0.56.4
2023-02-28 01:39:20,364:INFO:            requests: 2.28.2
2023-02-28 01:39:20,364:INFO:          matplotlib: 3.7.0
2023-02-28 01:39:20,364:INFO:          scikitplot: 0.3.7
2023-02-28 01:39:20,364:INFO:         yellowbrick: 1.5
2023-02-28 01:39:20,364:INFO:              plotly: 5.13.1
2023-02-28 01:39:20,364:INFO:             kaleido: 0.2.1
2023-02-28 01:39:20,364:INFO:         statsmodels: 0.13.5
2023-02-28 01:39:20,364:INFO:              sktime: 0.16.1
2023-02-28 01:39:20,364:INFO:               tbats: 1.1.2
2023-02-28 01:39:20,364:INFO:            pmdarima: 2.0.2
2023-02-28 01:39:20,364:INFO:              psutil: 5.9.4
2023-02-28 01:39:20,364:INFO:PyCaret optional dependencies:
2023-02-28 01:39:20,364:INFO:                shap: Not installed
2023-02-28 01:39:20,364:INFO:           interpret: Not installed
2023-02-28 01:39:20,364:INFO:                umap: Not installed
2023-02-28 01:39:20,364:INFO:    pandas_profiling: Not installed
2023-02-28 01:39:20,364:INFO:  explainerdashboard: Not installed
2023-02-28 01:39:20,364:INFO:             autoviz: 0.1.58
2023-02-28 01:39:20,364:INFO:           fairlearn: Not installed
2023-02-28 01:39:20,364:INFO:             xgboost: 1.7.4
2023-02-28 01:39:20,364:INFO:            catboost: Not installed
2023-02-28 01:39:20,364:INFO:              kmodes: Not installed
2023-02-28 01:39:20,364:INFO:             mlxtend: Not installed
2023-02-28 01:39:20,364:INFO:       statsforecast: Not installed
2023-02-28 01:39:20,364:INFO:        tune_sklearn: Not installed
2023-02-28 01:39:20,364:INFO:                 ray: Not installed
2023-02-28 01:39:20,364:INFO:            hyperopt: Not installed
2023-02-28 01:39:20,364:INFO:              optuna: Not installed
2023-02-28 01:39:20,364:INFO:               skopt: Not installed
2023-02-28 01:39:20,364:INFO:              mlflow: 1.30.0
2023-02-28 01:39:20,372:INFO:              gradio: 3.19.1
2023-02-28 01:39:20,372:INFO:             fastapi: 0.92.0
2023-02-28 01:39:20,372:INFO:             uvicorn: 0.20.0
2023-02-28 01:39:20,372:INFO:              m2cgen: 0.10.0
2023-02-28 01:39:20,372:INFO:           evidently: 0.2.5
2023-02-28 01:39:20,372:INFO:               fugue: Not installed
2023-02-28 01:39:20,372:INFO:           streamlit: Not installed
2023-02-28 01:39:20,372:INFO:             prophet: Not installed
2023-02-28 01:39:20,372:INFO:None
2023-02-28 01:39:20,372:INFO:Set up data.
2023-02-28 01:39:20,380:INFO:Set up train/test split.
2023-02-28 01:39:20,380:INFO:Set up index.
2023-02-28 01:39:20,380:INFO:Set up folding strategy.
2023-02-28 01:39:20,380:INFO:Assigning column types.
2023-02-28 01:39:20,389:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-28 01:39:20,546:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:39:20,552:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:39:20,723:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:39:20,732:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:39:20,733:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-02-28 01:39:20,864:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:39:20,870:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:39:20,992:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:39:20,996:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:39:20,996:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-02-28 01:39:21,110:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:39:21,110:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:39:21,214:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:39:21,222:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:39:21,223:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-02-28 01:39:21,321:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:39:21,321:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:39:21,434:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:39:21,434:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:39:21,434:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-28 01:39:21,530:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:39:21,538:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:39:21,642:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:39:21,642:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:39:21,642:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-02-28 01:39:21,748:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:39:21,748:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:39:21,857:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:39:21,859:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:39:21,859:INFO:Preparing preprocessing pipeline...
2023-02-28 01:39:21,859:INFO:Set up simple imputation.
2023-02-28 01:39:21,863:INFO:Set up encoding of ordinal features.
2023-02-28 01:39:21,863:INFO:Set up encoding of categorical features.
2023-02-28 01:39:21,928:INFO:Finished creating preprocessing pipeline.
2023-02-28 01:39:21,960:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\takis\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                     'smoker'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64},
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-02-28 01:39:21,960:INFO:Creating final display dataframe.
2023-02-28 01:39:22,295:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           charges
2                   Target type        Regression
3           Original data shape         (1338, 7)
4        Transformed data shape        (1338, 10)
5   Transformed train set shape         (936, 10)
6    Transformed test set shape         (402, 10)
7              Ordinal features                 2
8              Numeric features                 3
9          Categorical features                 3
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              87d4
2023-02-28 01:39:22,405:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:39:22,405:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:39:22,523:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:39:22,527:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:39:22,527:INFO:setup() successfully completed in 2.18s...............
2023-02-28 01:39:26,463:INFO:PyCaret RegressionExperiment
2023-02-28 01:39:26,463:INFO:Logging name: reg-default-name
2023-02-28 01:39:26,463:INFO:ML Usecase: MLUsecase.REGRESSION
2023-02-28 01:39:26,463:INFO:version 3.0.0.rc9
2023-02-28 01:39:26,463:INFO:Initializing setup()
2023-02-28 01:39:26,463:INFO:self.USI: 6d8f
2023-02-28 01:39:26,463:INFO:self._variable_keys: {'transform_target_param', 'log_plots_param', 'X_test', 'gpu_n_jobs_param', '_ml_usecase', 'memory', 'data', 'seed', 'y', 'y_test', 'X', 'fold_generator', 'fold_shuffle_param', 'target_param', 'n_jobs_param', 'y_train', 'exp_id', 'logging_param', 'idx', '_available_plots', 'USI', 'X_train', 'fold_groups_param', 'pipeline', 'html_param', 'gpu_param', 'exp_name_log'}
2023-02-28 01:39:26,463:INFO:Checking environment
2023-02-28 01:39:26,463:INFO:python_version: 3.8.16
2023-02-28 01:39:26,463:INFO:python_build: ('default', 'Jan 17 2023 22:25:28')
2023-02-28 01:39:26,463:INFO:machine: AMD64
2023-02-28 01:39:26,465:INFO:platform: Windows-10-10.0.22621-SP0
2023-02-28 01:39:26,474:INFO:Memory: svmem(total=14702026752, available=4380495872, percent=70.2, used=10321530880, free=4380495872)
2023-02-28 01:39:26,474:INFO:Physical Core: 8
2023-02-28 01:39:26,474:INFO:Logical Core: 16
2023-02-28 01:39:26,474:INFO:Checking libraries
2023-02-28 01:39:26,474:INFO:System:
2023-02-28 01:39:26,474:INFO:    python: 3.8.16 (default, Jan 17 2023, 22:25:28) [MSC v.1916 64 bit (AMD64)]
2023-02-28 01:39:26,479:INFO:executable: c:\Users\takis\anaconda3\envs\caretenv\python.exe
2023-02-28 01:39:26,479:INFO:   machine: Windows-10-10.0.22621-SP0
2023-02-28 01:39:26,479:INFO:PyCaret required dependencies:
2023-02-28 01:39:26,479:INFO:                 pip: 22.3.1
2023-02-28 01:39:26,479:INFO:          setuptools: 60.10.0
2023-02-28 01:39:26,479:INFO:             pycaret: 3.0.0rc9
2023-02-28 01:39:26,479:INFO:             IPython: 8.10.0
2023-02-28 01:39:26,479:INFO:          ipywidgets: 8.0.4
2023-02-28 01:39:26,479:INFO:                tqdm: 4.64.1
2023-02-28 01:39:26,479:INFO:               numpy: 1.23.5
2023-02-28 01:39:26,479:INFO:              pandas: 1.5.3
2023-02-28 01:39:26,479:INFO:              jinja2: 3.1.2
2023-02-28 01:39:26,480:INFO:               scipy: 1.10.1
2023-02-28 01:39:26,480:INFO:              joblib: 1.2.0
2023-02-28 01:39:26,480:INFO:             sklearn: 1.2.1
2023-02-28 01:39:26,480:INFO:                pyod: 1.0.7
2023-02-28 01:39:26,480:INFO:            imblearn: 0.10.1
2023-02-28 01:39:26,480:INFO:   category_encoders: 2.6.0
2023-02-28 01:39:26,480:INFO:            lightgbm: 3.3.5
2023-02-28 01:39:26,480:INFO:               numba: 0.56.4
2023-02-28 01:39:26,480:INFO:            requests: 2.28.2
2023-02-28 01:39:26,480:INFO:          matplotlib: 3.7.0
2023-02-28 01:39:26,480:INFO:          scikitplot: 0.3.7
2023-02-28 01:39:26,480:INFO:         yellowbrick: 1.5
2023-02-28 01:39:26,480:INFO:              plotly: 5.13.1
2023-02-28 01:39:26,481:INFO:             kaleido: 0.2.1
2023-02-28 01:39:26,481:INFO:         statsmodels: 0.13.5
2023-02-28 01:39:26,481:INFO:              sktime: 0.16.1
2023-02-28 01:39:26,481:INFO:               tbats: 1.1.2
2023-02-28 01:39:26,481:INFO:            pmdarima: 2.0.2
2023-02-28 01:39:26,481:INFO:              psutil: 5.9.4
2023-02-28 01:39:26,481:INFO:PyCaret optional dependencies:
2023-02-28 01:39:26,481:INFO:                shap: Not installed
2023-02-28 01:39:26,481:INFO:           interpret: Not installed
2023-02-28 01:39:26,481:INFO:                umap: Not installed
2023-02-28 01:39:26,481:INFO:    pandas_profiling: Not installed
2023-02-28 01:39:26,481:INFO:  explainerdashboard: Not installed
2023-02-28 01:39:26,483:INFO:             autoviz: 0.1.58
2023-02-28 01:39:26,483:INFO:           fairlearn: Not installed
2023-02-28 01:39:26,483:INFO:             xgboost: 1.7.4
2023-02-28 01:39:26,483:INFO:            catboost: Not installed
2023-02-28 01:39:26,483:INFO:              kmodes: Not installed
2023-02-28 01:39:26,483:INFO:             mlxtend: Not installed
2023-02-28 01:39:26,483:INFO:       statsforecast: Not installed
2023-02-28 01:39:26,484:INFO:        tune_sklearn: Not installed
2023-02-28 01:39:26,484:INFO:                 ray: Not installed
2023-02-28 01:39:26,484:INFO:            hyperopt: Not installed
2023-02-28 01:39:26,484:INFO:              optuna: Not installed
2023-02-28 01:39:26,484:INFO:               skopt: Not installed
2023-02-28 01:39:26,484:INFO:              mlflow: 1.30.0
2023-02-28 01:39:26,484:INFO:              gradio: 3.19.1
2023-02-28 01:39:26,484:INFO:             fastapi: 0.92.0
2023-02-28 01:39:26,484:INFO:             uvicorn: 0.20.0
2023-02-28 01:39:26,484:INFO:              m2cgen: 0.10.0
2023-02-28 01:39:26,484:INFO:           evidently: 0.2.5
2023-02-28 01:39:26,484:INFO:               fugue: Not installed
2023-02-28 01:39:26,484:INFO:           streamlit: Not installed
2023-02-28 01:39:26,484:INFO:             prophet: Not installed
2023-02-28 01:39:26,484:INFO:None
2023-02-28 01:39:26,484:INFO:Set up data.
2023-02-28 01:39:26,495:INFO:Set up train/test split.
2023-02-28 01:39:26,495:INFO:Set up index.
2023-02-28 01:39:26,495:INFO:Set up folding strategy.
2023-02-28 01:39:26,495:INFO:Assigning column types.
2023-02-28 01:39:26,506:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-28 01:39:26,507:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-28 01:39:26,512:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-28 01:39:26,519:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 01:39:26,593:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:39:26,657:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 01:39:26,657:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:39:26,665:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:39:26,666:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-28 01:39:26,672:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-28 01:39:26,680:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 01:39:26,757:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:39:26,820:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 01:39:26,820:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:39:26,820:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:39:26,820:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-02-28 01:39:26,828:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-28 01:39:26,839:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 01:39:26,911:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:39:26,966:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 01:39:26,966:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:39:26,966:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:39:26,974:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-28 01:39:26,982:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 01:39:27,047:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:39:27,096:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 01:39:27,096:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:39:27,098:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:39:27,098:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-02-28 01:39:27,112:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 01:39:27,172:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:39:27,219:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 01:39:27,219:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:39:27,227:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:39:27,235:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 01:39:27,320:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:39:27,365:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 01:39:27,365:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:39:27,365:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:39:27,365:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-02-28 01:39:27,440:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:39:27,480:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 01:39:27,480:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:39:27,480:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:39:27,544:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:39:27,584:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 01:39:27,584:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:39:27,592:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:39:27,592:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-28 01:39:27,657:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:39:27,698:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:39:27,698:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:39:27,758:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:39:27,794:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:39:27,794:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:39:27,794:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-02-28 01:39:27,902:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:39:27,906:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:39:28,005:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:39:28,015:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:39:28,015:INFO:Preparing preprocessing pipeline...
2023-02-28 01:39:28,016:INFO:Set up simple imputation.
2023-02-28 01:39:28,020:INFO:Set up encoding of ordinal features.
2023-02-28 01:39:28,022:INFO:Set up encoding of categorical features.
2023-02-28 01:39:28,081:INFO:Finished creating preprocessing pipeline.
2023-02-28 01:39:28,112:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\takis\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                     'smoker'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64},
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-02-28 01:39:28,112:INFO:Creating final display dataframe.
2023-02-28 01:39:28,432:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           charges
2                   Target type        Regression
3           Original data shape         (1338, 7)
4        Transformed data shape        (1338, 10)
5   Transformed train set shape         (936, 10)
6    Transformed test set shape         (402, 10)
7              Ordinal features                 2
8              Numeric features                 3
9          Categorical features                 3
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              6d8f
2023-02-28 01:39:28,548:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:39:28,548:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:39:28,674:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:39:28,674:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:39:28,676:INFO:setup() successfully completed in 2.22s...............
2023-02-28 01:41:26,799:INFO:PyCaret RegressionExperiment
2023-02-28 01:41:26,799:INFO:Logging name: reg-default-name
2023-02-28 01:41:26,799:INFO:ML Usecase: MLUsecase.REGRESSION
2023-02-28 01:41:26,799:INFO:version 3.0.0.rc9
2023-02-28 01:41:26,799:INFO:Initializing setup()
2023-02-28 01:41:26,799:INFO:self.USI: 33d2
2023-02-28 01:41:26,799:INFO:self._variable_keys: {'transform_target_param', 'log_plots_param', 'X_test', 'gpu_n_jobs_param', '_ml_usecase', 'memory', 'data', 'seed', 'y', 'y_test', 'X', 'fold_generator', 'fold_shuffle_param', 'target_param', 'n_jobs_param', 'y_train', 'exp_id', 'logging_param', 'idx', '_available_plots', 'USI', 'X_train', 'fold_groups_param', 'pipeline', 'html_param', 'gpu_param', 'exp_name_log'}
2023-02-28 01:41:26,799:INFO:Checking environment
2023-02-28 01:41:26,799:INFO:python_version: 3.8.16
2023-02-28 01:41:26,799:INFO:python_build: ('default', 'Jan 17 2023 22:25:28')
2023-02-28 01:41:26,799:INFO:machine: AMD64
2023-02-28 01:41:26,799:INFO:platform: Windows-10-10.0.22621-SP0
2023-02-28 01:41:26,816:INFO:Memory: svmem(total=14702026752, available=4366864384, percent=70.3, used=10335162368, free=4366864384)
2023-02-28 01:41:26,816:INFO:Physical Core: 8
2023-02-28 01:41:26,816:INFO:Logical Core: 16
2023-02-28 01:41:26,816:INFO:Checking libraries
2023-02-28 01:41:26,816:INFO:System:
2023-02-28 01:41:26,816:INFO:    python: 3.8.16 (default, Jan 17 2023, 22:25:28) [MSC v.1916 64 bit (AMD64)]
2023-02-28 01:41:26,818:INFO:executable: c:\Users\takis\anaconda3\envs\caretenv\python.exe
2023-02-28 01:41:26,818:INFO:   machine: Windows-10-10.0.22621-SP0
2023-02-28 01:41:26,818:INFO:PyCaret required dependencies:
2023-02-28 01:41:26,818:INFO:                 pip: 22.3.1
2023-02-28 01:41:26,818:INFO:          setuptools: 60.10.0
2023-02-28 01:41:26,818:INFO:             pycaret: 3.0.0rc9
2023-02-28 01:41:26,818:INFO:             IPython: 8.10.0
2023-02-28 01:41:26,818:INFO:          ipywidgets: 8.0.4
2023-02-28 01:41:26,818:INFO:                tqdm: 4.64.1
2023-02-28 01:41:26,818:INFO:               numpy: 1.23.5
2023-02-28 01:41:26,818:INFO:              pandas: 1.5.3
2023-02-28 01:41:26,818:INFO:              jinja2: 3.1.2
2023-02-28 01:41:26,819:INFO:               scipy: 1.10.1
2023-02-28 01:41:26,819:INFO:              joblib: 1.2.0
2023-02-28 01:41:26,819:INFO:             sklearn: 1.2.1
2023-02-28 01:41:26,819:INFO:                pyod: 1.0.7
2023-02-28 01:41:26,819:INFO:            imblearn: 0.10.1
2023-02-28 01:41:26,819:INFO:   category_encoders: 2.6.0
2023-02-28 01:41:26,819:INFO:            lightgbm: 3.3.5
2023-02-28 01:41:26,819:INFO:               numba: 0.56.4
2023-02-28 01:41:26,819:INFO:            requests: 2.28.2
2023-02-28 01:41:26,819:INFO:          matplotlib: 3.7.0
2023-02-28 01:41:26,819:INFO:          scikitplot: 0.3.7
2023-02-28 01:41:26,819:INFO:         yellowbrick: 1.5
2023-02-28 01:41:26,819:INFO:              plotly: 5.13.1
2023-02-28 01:41:26,819:INFO:             kaleido: 0.2.1
2023-02-28 01:41:26,819:INFO:         statsmodels: 0.13.5
2023-02-28 01:41:26,819:INFO:              sktime: 0.16.1
2023-02-28 01:41:26,819:INFO:               tbats: 1.1.2
2023-02-28 01:41:26,819:INFO:            pmdarima: 2.0.2
2023-02-28 01:41:26,819:INFO:              psutil: 5.9.4
2023-02-28 01:41:26,819:INFO:PyCaret optional dependencies:
2023-02-28 01:41:26,819:INFO:                shap: Not installed
2023-02-28 01:41:26,819:INFO:           interpret: Not installed
2023-02-28 01:41:26,819:INFO:                umap: Not installed
2023-02-28 01:41:26,819:INFO:    pandas_profiling: Not installed
2023-02-28 01:41:26,821:INFO:  explainerdashboard: Not installed
2023-02-28 01:41:26,821:INFO:             autoviz: 0.1.58
2023-02-28 01:41:26,821:INFO:           fairlearn: Not installed
2023-02-28 01:41:26,821:INFO:             xgboost: 1.7.4
2023-02-28 01:41:26,821:INFO:            catboost: Not installed
2023-02-28 01:41:26,821:INFO:              kmodes: Not installed
2023-02-28 01:41:26,821:INFO:             mlxtend: Not installed
2023-02-28 01:41:26,821:INFO:       statsforecast: Not installed
2023-02-28 01:41:26,821:INFO:        tune_sklearn: Not installed
2023-02-28 01:41:26,821:INFO:                 ray: Not installed
2023-02-28 01:41:26,821:INFO:            hyperopt: Not installed
2023-02-28 01:41:26,821:INFO:              optuna: Not installed
2023-02-28 01:41:26,821:INFO:               skopt: Not installed
2023-02-28 01:41:26,821:INFO:              mlflow: 1.30.0
2023-02-28 01:41:26,821:INFO:              gradio: 3.19.1
2023-02-28 01:41:26,823:INFO:             fastapi: 0.92.0
2023-02-28 01:41:26,823:INFO:             uvicorn: 0.20.0
2023-02-28 01:41:26,823:INFO:              m2cgen: 0.10.0
2023-02-28 01:41:26,823:INFO:           evidently: 0.2.5
2023-02-28 01:41:26,823:INFO:               fugue: Not installed
2023-02-28 01:41:26,823:INFO:           streamlit: Not installed
2023-02-28 01:41:26,823:INFO:             prophet: Not installed
2023-02-28 01:41:26,823:INFO:None
2023-02-28 01:41:26,823:INFO:Set up data.
2023-02-28 01:41:26,832:INFO:Set up train/test split.
2023-02-28 01:41:26,836:INFO:Set up index.
2023-02-28 01:41:26,836:INFO:Set up folding strategy.
2023-02-28 01:41:26,836:INFO:Assigning column types.
2023-02-28 01:41:26,840:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-02-28 01:41:26,840:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-28 01:41:26,847:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-28 01:41:26,851:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 01:41:26,932:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:41:27,006:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 01:41:27,010:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:41:27,010:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:41:27,010:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-02-28 01:41:27,022:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-28 01:41:27,026:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 01:41:27,115:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:41:27,180:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 01:41:27,180:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:41:27,180:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:41:27,180:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-02-28 01:41:27,188:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-28 01:41:27,196:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 01:41:27,269:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:41:27,345:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 01:41:27,345:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:41:27,349:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:41:27,359:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-02-28 01:41:27,366:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 01:41:27,440:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:41:27,502:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 01:41:27,504:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:41:27,506:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:41:27,506:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-02-28 01:41:27,521:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 01:41:27,588:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:41:27,646:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 01:41:27,646:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:41:27,655:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:41:27,663:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-02-28 01:41:27,729:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:41:27,778:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 01:41:27,778:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:41:27,791:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:41:27,791:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-02-28 01:41:27,860:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:41:27,910:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 01:41:27,912:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:41:27,914:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:41:27,976:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:41:28,020:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-02-28 01:41:28,020:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:41:28,021:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:41:28,021:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-02-28 01:41:28,089:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:41:28,129:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:41:28,129:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:41:28,206:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-02-28 01:41:28,245:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:41:28,245:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:41:28,245:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-02-28 01:41:28,355:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:41:28,355:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:41:28,453:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:41:28,453:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:41:28,458:INFO:Preparing preprocessing pipeline...
2023-02-28 01:41:28,458:INFO:Set up simple imputation.
2023-02-28 01:41:28,458:INFO:Set up encoding of ordinal features.
2023-02-28 01:41:28,458:INFO:Set up encoding of categorical features.
2023-02-28 01:41:28,531:INFO:Finished creating preprocessing pipeline.
2023-02-28 01:41:28,572:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\takis\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                     'smoker'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64},
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-02-28 01:41:28,572:INFO:Creating final display dataframe.
2023-02-28 01:41:28,944:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           charges
2                   Target type        Regression
3           Original data shape         (1338, 7)
4        Transformed data shape        (1338, 10)
5   Transformed train set shape         (936, 10)
6    Transformed test set shape         (402, 10)
7              Ordinal features                 2
8              Numeric features                 3
9          Categorical features                 3
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              33d2
2023-02-28 01:41:29,091:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:41:29,097:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:41:29,211:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:41:29,215:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:41:29,215:INFO:setup() successfully completed in 2.42s...............
2023-02-28 01:41:43,229:INFO:gpu_param set to False
2023-02-28 01:41:43,390:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:41:43,398:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:41:43,580:INFO:Soft dependency imported: xgboost: 1.7.4
2023-02-28 01:41:43,588:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-02-28 01:42:28,692:INFO:Initializing compare_models()
2023-02-28 01:42:28,692:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, include=None, fold=None, round=4, cross_validation=True, sort=mape, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'mape', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-02-28 01:42:28,692:INFO:Checking exceptions
2023-02-28 01:42:28,701:INFO:Preparing display monitor
2023-02-28 01:42:28,753:INFO:Initializing Linear Regression
2023-02-28 01:42:28,753:INFO:Total runtime is 0.0 minutes
2023-02-28 01:42:28,756:INFO:SubProcess create_model() called ==================================
2023-02-28 01:42:28,756:INFO:Initializing create_model()
2023-02-28 01:42:28,756:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB070AFA30>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:42:28,756:INFO:Checking exceptions
2023-02-28 01:42:28,756:INFO:Importing libraries
2023-02-28 01:42:28,756:INFO:Copying training dataset
2023-02-28 01:42:28,764:INFO:Defining folds
2023-02-28 01:42:28,764:INFO:Declaring metric variables
2023-02-28 01:42:28,771:INFO:Importing untrained model
2023-02-28 01:42:28,773:INFO:Linear Regression Imported successfully
2023-02-28 01:42:28,784:INFO:Starting cross validation
2023-02-28 01:42:28,789:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:42:34,990:INFO:Calculating mean and std
2023-02-28 01:42:34,998:INFO:Creating metrics dataframe
2023-02-28 01:42:35,006:INFO:Uploading results into container
2023-02-28 01:42:35,008:INFO:Uploading model into container now
2023-02-28 01:42:35,010:INFO:_master_model_container: 1
2023-02-28 01:42:35,010:INFO:_display_container: 2
2023-02-28 01:42:35,011:INFO:LinearRegression(n_jobs=-1)
2023-02-28 01:42:35,011:INFO:create_model() successfully completed......................................
2023-02-28 01:42:35,371:INFO:SubProcess create_model() end ==================================
2023-02-28 01:42:35,371:INFO:Creating metrics dataframe
2023-02-28 01:42:35,380:INFO:Initializing Lasso Regression
2023-02-28 01:42:35,382:INFO:Total runtime is 0.1104867180188497 minutes
2023-02-28 01:42:35,383:INFO:SubProcess create_model() called ==================================
2023-02-28 01:42:35,386:INFO:Initializing create_model()
2023-02-28 01:42:35,386:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB070AFA30>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:42:35,386:INFO:Checking exceptions
2023-02-28 01:42:35,386:INFO:Importing libraries
2023-02-28 01:42:35,386:INFO:Copying training dataset
2023-02-28 01:42:35,388:INFO:Defining folds
2023-02-28 01:42:35,388:INFO:Declaring metric variables
2023-02-28 01:42:35,396:INFO:Importing untrained model
2023-02-28 01:42:35,398:INFO:Lasso Regression Imported successfully
2023-02-28 01:42:35,405:INFO:Starting cross validation
2023-02-28 01:42:35,405:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:42:39,118:INFO:Calculating mean and std
2023-02-28 01:42:39,118:INFO:Creating metrics dataframe
2023-02-28 01:42:39,126:INFO:Uploading results into container
2023-02-28 01:42:39,126:INFO:Uploading model into container now
2023-02-28 01:42:39,126:INFO:_master_model_container: 2
2023-02-28 01:42:39,126:INFO:_display_container: 2
2023-02-28 01:42:39,126:INFO:Lasso(random_state=123)
2023-02-28 01:42:39,126:INFO:create_model() successfully completed......................................
2023-02-28 01:42:39,404:INFO:SubProcess create_model() end ==================================
2023-02-28 01:42:39,404:INFO:Creating metrics dataframe
2023-02-28 01:42:39,420:INFO:Initializing Ridge Regression
2023-02-28 01:42:39,420:INFO:Total runtime is 0.17779319683710734 minutes
2023-02-28 01:42:39,420:INFO:SubProcess create_model() called ==================================
2023-02-28 01:42:39,420:INFO:Initializing create_model()
2023-02-28 01:42:39,420:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB070AFA30>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:42:39,420:INFO:Checking exceptions
2023-02-28 01:42:39,420:INFO:Importing libraries
2023-02-28 01:42:39,420:INFO:Copying training dataset
2023-02-28 01:42:39,429:INFO:Defining folds
2023-02-28 01:42:39,429:INFO:Declaring metric variables
2023-02-28 01:42:39,429:INFO:Importing untrained model
2023-02-28 01:42:39,437:INFO:Ridge Regression Imported successfully
2023-02-28 01:42:39,445:INFO:Starting cross validation
2023-02-28 01:42:39,453:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:42:39,777:INFO:Calculating mean and std
2023-02-28 01:42:39,777:INFO:Creating metrics dataframe
2023-02-28 01:42:39,783:INFO:Uploading results into container
2023-02-28 01:42:39,783:INFO:Uploading model into container now
2023-02-28 01:42:39,783:INFO:_master_model_container: 3
2023-02-28 01:42:39,783:INFO:_display_container: 2
2023-02-28 01:42:39,783:INFO:Ridge(random_state=123)
2023-02-28 01:42:39,783:INFO:create_model() successfully completed......................................
2023-02-28 01:42:40,066:INFO:SubProcess create_model() end ==================================
2023-02-28 01:42:40,074:INFO:Creating metrics dataframe
2023-02-28 01:42:40,083:INFO:Initializing Elastic Net
2023-02-28 01:42:40,083:INFO:Total runtime is 0.18883175849914552 minutes
2023-02-28 01:42:40,087:INFO:SubProcess create_model() called ==================================
2023-02-28 01:42:40,089:INFO:Initializing create_model()
2023-02-28 01:42:40,089:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB070AFA30>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:42:40,089:INFO:Checking exceptions
2023-02-28 01:42:40,089:INFO:Importing libraries
2023-02-28 01:42:40,089:INFO:Copying training dataset
2023-02-28 01:42:40,091:INFO:Defining folds
2023-02-28 01:42:40,091:INFO:Declaring metric variables
2023-02-28 01:42:40,094:INFO:Importing untrained model
2023-02-28 01:42:40,099:INFO:Elastic Net Imported successfully
2023-02-28 01:42:40,107:INFO:Starting cross validation
2023-02-28 01:42:40,110:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:42:40,374:INFO:Calculating mean and std
2023-02-28 01:42:40,378:INFO:Creating metrics dataframe
2023-02-28 01:42:40,382:INFO:Uploading results into container
2023-02-28 01:42:40,382:INFO:Uploading model into container now
2023-02-28 01:42:40,382:INFO:_master_model_container: 4
2023-02-28 01:42:40,384:INFO:_display_container: 2
2023-02-28 01:42:40,384:INFO:ElasticNet(random_state=123)
2023-02-28 01:42:40,384:INFO:create_model() successfully completed......................................
2023-02-28 01:42:40,654:INFO:SubProcess create_model() end ==================================
2023-02-28 01:42:40,654:INFO:Creating metrics dataframe
2023-02-28 01:42:40,668:INFO:Initializing Least Angle Regression
2023-02-28 01:42:40,668:INFO:Total runtime is 0.19857753117879232 minutes
2023-02-28 01:42:40,673:INFO:SubProcess create_model() called ==================================
2023-02-28 01:42:40,673:INFO:Initializing create_model()
2023-02-28 01:42:40,673:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB070AFA30>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:42:40,673:INFO:Checking exceptions
2023-02-28 01:42:40,673:INFO:Importing libraries
2023-02-28 01:42:40,673:INFO:Copying training dataset
2023-02-28 01:42:40,676:INFO:Defining folds
2023-02-28 01:42:40,676:INFO:Declaring metric variables
2023-02-28 01:42:40,681:INFO:Importing untrained model
2023-02-28 01:42:40,685:INFO:Least Angle Regression Imported successfully
2023-02-28 01:42:40,692:INFO:Starting cross validation
2023-02-28 01:42:40,694:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:42:41,036:INFO:Calculating mean and std
2023-02-28 01:42:41,036:INFO:Creating metrics dataframe
2023-02-28 01:42:41,040:INFO:Uploading results into container
2023-02-28 01:42:41,040:INFO:Uploading model into container now
2023-02-28 01:42:41,043:INFO:_master_model_container: 5
2023-02-28 01:42:41,043:INFO:_display_container: 2
2023-02-28 01:42:41,043:INFO:Lars(random_state=123)
2023-02-28 01:42:41,043:INFO:create_model() successfully completed......................................
2023-02-28 01:42:41,319:INFO:SubProcess create_model() end ==================================
2023-02-28 01:42:41,319:INFO:Creating metrics dataframe
2023-02-28 01:42:41,336:INFO:Initializing Lasso Least Angle Regression
2023-02-28 01:42:41,336:INFO:Total runtime is 0.2097137451171875 minutes
2023-02-28 01:42:41,336:INFO:SubProcess create_model() called ==================================
2023-02-28 01:42:41,336:INFO:Initializing create_model()
2023-02-28 01:42:41,336:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB070AFA30>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:42:41,336:INFO:Checking exceptions
2023-02-28 01:42:41,336:INFO:Importing libraries
2023-02-28 01:42:41,336:INFO:Copying training dataset
2023-02-28 01:42:41,344:INFO:Defining folds
2023-02-28 01:42:41,344:INFO:Declaring metric variables
2023-02-28 01:42:41,347:INFO:Importing untrained model
2023-02-28 01:42:41,353:INFO:Lasso Least Angle Regression Imported successfully
2023-02-28 01:42:41,360:INFO:Starting cross validation
2023-02-28 01:42:41,361:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:42:41,704:INFO:Calculating mean and std
2023-02-28 01:42:41,707:INFO:Creating metrics dataframe
2023-02-28 01:42:41,707:INFO:Uploading results into container
2023-02-28 01:42:41,707:INFO:Uploading model into container now
2023-02-28 01:42:41,707:INFO:_master_model_container: 6
2023-02-28 01:42:41,707:INFO:_display_container: 2
2023-02-28 01:42:41,707:INFO:LassoLars(random_state=123)
2023-02-28 01:42:41,707:INFO:create_model() successfully completed......................................
2023-02-28 01:42:41,986:INFO:SubProcess create_model() end ==================================
2023-02-28 01:42:41,986:INFO:Creating metrics dataframe
2023-02-28 01:42:41,994:INFO:Initializing Orthogonal Matching Pursuit
2023-02-28 01:42:41,994:INFO:Total runtime is 0.22068636814753215 minutes
2023-02-28 01:42:41,994:INFO:SubProcess create_model() called ==================================
2023-02-28 01:42:41,994:INFO:Initializing create_model()
2023-02-28 01:42:41,994:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB070AFA30>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:42:41,994:INFO:Checking exceptions
2023-02-28 01:42:41,994:INFO:Importing libraries
2023-02-28 01:42:41,994:INFO:Copying training dataset
2023-02-28 01:42:42,003:INFO:Defining folds
2023-02-28 01:42:42,003:INFO:Declaring metric variables
2023-02-28 01:42:42,011:INFO:Importing untrained model
2023-02-28 01:42:42,011:INFO:Orthogonal Matching Pursuit Imported successfully
2023-02-28 01:42:42,018:INFO:Starting cross validation
2023-02-28 01:42:42,026:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:42:42,365:INFO:Calculating mean and std
2023-02-28 01:42:42,373:INFO:Creating metrics dataframe
2023-02-28 01:42:42,373:INFO:Uploading results into container
2023-02-28 01:42:42,373:INFO:Uploading model into container now
2023-02-28 01:42:42,373:INFO:_master_model_container: 7
2023-02-28 01:42:42,373:INFO:_display_container: 2
2023-02-28 01:42:42,373:INFO:OrthogonalMatchingPursuit()
2023-02-28 01:42:42,373:INFO:create_model() successfully completed......................................
2023-02-28 01:42:42,654:INFO:SubProcess create_model() end ==================================
2023-02-28 01:42:42,654:INFO:Creating metrics dataframe
2023-02-28 01:42:42,668:INFO:Initializing Bayesian Ridge
2023-02-28 01:42:42,668:INFO:Total runtime is 0.2319129427274068 minutes
2023-02-28 01:42:42,672:INFO:SubProcess create_model() called ==================================
2023-02-28 01:42:42,672:INFO:Initializing create_model()
2023-02-28 01:42:42,673:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB070AFA30>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:42:42,673:INFO:Checking exceptions
2023-02-28 01:42:42,673:INFO:Importing libraries
2023-02-28 01:42:42,673:INFO:Copying training dataset
2023-02-28 01:42:42,675:INFO:Defining folds
2023-02-28 01:42:42,675:INFO:Declaring metric variables
2023-02-28 01:42:42,681:INFO:Importing untrained model
2023-02-28 01:42:42,682:INFO:Bayesian Ridge Imported successfully
2023-02-28 01:42:42,689:INFO:Starting cross validation
2023-02-28 01:42:42,689:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:42:43,030:INFO:Calculating mean and std
2023-02-28 01:42:43,038:INFO:Creating metrics dataframe
2023-02-28 01:42:43,041:INFO:Uploading results into container
2023-02-28 01:42:43,041:INFO:Uploading model into container now
2023-02-28 01:42:43,041:INFO:_master_model_container: 8
2023-02-28 01:42:43,041:INFO:_display_container: 2
2023-02-28 01:42:43,041:INFO:BayesianRidge()
2023-02-28 01:42:43,041:INFO:create_model() successfully completed......................................
2023-02-28 01:42:43,319:INFO:SubProcess create_model() end ==================================
2023-02-28 01:42:43,319:INFO:Creating metrics dataframe
2023-02-28 01:42:43,329:INFO:Initializing Passive Aggressive Regressor
2023-02-28 01:42:43,329:INFO:Total runtime is 0.2429304003715515 minutes
2023-02-28 01:42:43,329:INFO:SubProcess create_model() called ==================================
2023-02-28 01:42:43,329:INFO:Initializing create_model()
2023-02-28 01:42:43,329:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB070AFA30>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:42:43,329:INFO:Checking exceptions
2023-02-28 01:42:43,329:INFO:Importing libraries
2023-02-28 01:42:43,329:INFO:Copying training dataset
2023-02-28 01:42:43,339:INFO:Defining folds
2023-02-28 01:42:43,339:INFO:Declaring metric variables
2023-02-28 01:42:43,345:INFO:Importing untrained model
2023-02-28 01:42:43,349:INFO:Passive Aggressive Regressor Imported successfully
2023-02-28 01:42:43,355:INFO:Starting cross validation
2023-02-28 01:42:43,360:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:42:43,699:INFO:Calculating mean and std
2023-02-28 01:42:43,707:INFO:Creating metrics dataframe
2023-02-28 01:42:43,707:INFO:Uploading results into container
2023-02-28 01:42:43,707:INFO:Uploading model into container now
2023-02-28 01:42:43,707:INFO:_master_model_container: 9
2023-02-28 01:42:43,707:INFO:_display_container: 2
2023-02-28 01:42:43,707:INFO:PassiveAggressiveRegressor(random_state=123)
2023-02-28 01:42:43,707:INFO:create_model() successfully completed......................................
2023-02-28 01:42:43,985:INFO:SubProcess create_model() end ==================================
2023-02-28 01:42:43,986:INFO:Creating metrics dataframe
2023-02-28 01:42:43,994:INFO:Initializing Huber Regressor
2023-02-28 01:42:43,994:INFO:Total runtime is 0.2540152867635091 minutes
2023-02-28 01:42:44,001:INFO:SubProcess create_model() called ==================================
2023-02-28 01:42:44,001:INFO:Initializing create_model()
2023-02-28 01:42:44,001:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB070AFA30>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:42:44,001:INFO:Checking exceptions
2023-02-28 01:42:44,001:INFO:Importing libraries
2023-02-28 01:42:44,001:INFO:Copying training dataset
2023-02-28 01:42:44,005:INFO:Defining folds
2023-02-28 01:42:44,005:INFO:Declaring metric variables
2023-02-28 01:42:44,010:INFO:Importing untrained model
2023-02-28 01:42:44,013:INFO:Huber Regressor Imported successfully
2023-02-28 01:42:44,017:INFO:Starting cross validation
2023-02-28 01:42:44,024:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:42:44,219:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:42:44,227:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:42:44,227:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:42:44,268:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:42:44,292:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:42:44,303:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:42:44,316:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:42:44,318:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:42:44,324:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:42:44,332:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:42:44,384:INFO:Calculating mean and std
2023-02-28 01:42:44,384:INFO:Creating metrics dataframe
2023-02-28 01:42:44,388:INFO:Uploading results into container
2023-02-28 01:42:44,398:INFO:Uploading model into container now
2023-02-28 01:42:44,398:INFO:_master_model_container: 10
2023-02-28 01:42:44,398:INFO:_display_container: 2
2023-02-28 01:42:44,398:INFO:HuberRegressor()
2023-02-28 01:42:44,398:INFO:create_model() successfully completed......................................
2023-02-28 01:42:44,674:INFO:SubProcess create_model() end ==================================
2023-02-28 01:42:44,674:INFO:Creating metrics dataframe
2023-02-28 01:42:44,685:INFO:Initializing K Neighbors Regressor
2023-02-28 01:42:44,685:INFO:Total runtime is 0.26553687651952107 minutes
2023-02-28 01:42:44,685:INFO:SubProcess create_model() called ==================================
2023-02-28 01:42:44,685:INFO:Initializing create_model()
2023-02-28 01:42:44,685:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB070AFA30>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:42:44,685:INFO:Checking exceptions
2023-02-28 01:42:44,691:INFO:Importing libraries
2023-02-28 01:42:44,691:INFO:Copying training dataset
2023-02-28 01:42:44,695:INFO:Defining folds
2023-02-28 01:42:44,695:INFO:Declaring metric variables
2023-02-28 01:42:44,700:INFO:Importing untrained model
2023-02-28 01:42:44,705:INFO:K Neighbors Regressor Imported successfully
2023-02-28 01:42:44,713:INFO:Starting cross validation
2023-02-28 01:42:44,715:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:42:45,096:INFO:Calculating mean and std
2023-02-28 01:42:45,096:INFO:Creating metrics dataframe
2023-02-28 01:42:45,101:INFO:Uploading results into container
2023-02-28 01:42:45,101:INFO:Uploading model into container now
2023-02-28 01:42:45,101:INFO:_master_model_container: 11
2023-02-28 01:42:45,101:INFO:_display_container: 2
2023-02-28 01:42:45,103:INFO:KNeighborsRegressor(n_jobs=-1)
2023-02-28 01:42:45,103:INFO:create_model() successfully completed......................................
2023-02-28 01:42:45,385:INFO:SubProcess create_model() end ==================================
2023-02-28 01:42:45,388:INFO:Creating metrics dataframe
2023-02-28 01:42:45,397:INFO:Initializing Decision Tree Regressor
2023-02-28 01:42:45,397:INFO:Total runtime is 0.2773934245109558 minutes
2023-02-28 01:42:45,397:INFO:SubProcess create_model() called ==================================
2023-02-28 01:42:45,397:INFO:Initializing create_model()
2023-02-28 01:42:45,397:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB070AFA30>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:42:45,397:INFO:Checking exceptions
2023-02-28 01:42:45,397:INFO:Importing libraries
2023-02-28 01:42:45,397:INFO:Copying training dataset
2023-02-28 01:42:45,405:INFO:Defining folds
2023-02-28 01:42:45,405:INFO:Declaring metric variables
2023-02-28 01:42:45,405:INFO:Importing untrained model
2023-02-28 01:42:45,413:INFO:Decision Tree Regressor Imported successfully
2023-02-28 01:42:45,421:INFO:Starting cross validation
2023-02-28 01:42:45,421:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:42:45,742:INFO:Calculating mean and std
2023-02-28 01:42:45,750:INFO:Creating metrics dataframe
2023-02-28 01:42:45,766:INFO:Uploading results into container
2023-02-28 01:42:45,766:INFO:Uploading model into container now
2023-02-28 01:42:45,767:INFO:_master_model_container: 12
2023-02-28 01:42:45,767:INFO:_display_container: 2
2023-02-28 01:42:45,767:INFO:DecisionTreeRegressor(random_state=123)
2023-02-28 01:42:45,767:INFO:create_model() successfully completed......................................
2023-02-28 01:42:46,043:INFO:SubProcess create_model() end ==================================
2023-02-28 01:42:46,043:INFO:Creating metrics dataframe
2023-02-28 01:42:46,052:INFO:Initializing Random Forest Regressor
2023-02-28 01:42:46,052:INFO:Total runtime is 0.2883243560791015 minutes
2023-02-28 01:42:46,059:INFO:SubProcess create_model() called ==================================
2023-02-28 01:42:46,059:INFO:Initializing create_model()
2023-02-28 01:42:46,060:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB070AFA30>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:42:46,060:INFO:Checking exceptions
2023-02-28 01:42:46,060:INFO:Importing libraries
2023-02-28 01:42:46,060:INFO:Copying training dataset
2023-02-28 01:42:46,062:INFO:Defining folds
2023-02-28 01:42:46,062:INFO:Declaring metric variables
2023-02-28 01:42:46,068:INFO:Importing untrained model
2023-02-28 01:42:46,071:INFO:Random Forest Regressor Imported successfully
2023-02-28 01:42:46,083:INFO:Starting cross validation
2023-02-28 01:42:46,085:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:42:46,642:INFO:Calculating mean and std
2023-02-28 01:42:46,644:INFO:Creating metrics dataframe
2023-02-28 01:42:46,645:INFO:Uploading results into container
2023-02-28 01:42:46,645:INFO:Uploading model into container now
2023-02-28 01:42:46,645:INFO:_master_model_container: 13
2023-02-28 01:42:46,645:INFO:_display_container: 2
2023-02-28 01:42:46,645:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-02-28 01:42:46,645:INFO:create_model() successfully completed......................................
2023-02-28 01:42:46,925:INFO:SubProcess create_model() end ==================================
2023-02-28 01:42:46,925:INFO:Creating metrics dataframe
2023-02-28 01:42:46,935:INFO:Initializing Extra Trees Regressor
2023-02-28 01:42:46,935:INFO:Total runtime is 0.30302941401799516 minutes
2023-02-28 01:42:46,935:INFO:SubProcess create_model() called ==================================
2023-02-28 01:42:46,935:INFO:Initializing create_model()
2023-02-28 01:42:46,941:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB070AFA30>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:42:46,941:INFO:Checking exceptions
2023-02-28 01:42:46,941:INFO:Importing libraries
2023-02-28 01:42:46,941:INFO:Copying training dataset
2023-02-28 01:42:46,942:INFO:Defining folds
2023-02-28 01:42:46,942:INFO:Declaring metric variables
2023-02-28 01:42:46,949:INFO:Importing untrained model
2023-02-28 01:42:46,952:INFO:Extra Trees Regressor Imported successfully
2023-02-28 01:42:46,957:INFO:Starting cross validation
2023-02-28 01:42:46,961:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:42:47,503:INFO:Calculating mean and std
2023-02-28 01:42:47,505:INFO:Creating metrics dataframe
2023-02-28 01:42:47,509:INFO:Uploading results into container
2023-02-28 01:42:47,509:INFO:Uploading model into container now
2023-02-28 01:42:47,509:INFO:_master_model_container: 14
2023-02-28 01:42:47,509:INFO:_display_container: 2
2023-02-28 01:42:47,509:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-02-28 01:42:47,509:INFO:create_model() successfully completed......................................
2023-02-28 01:42:47,791:INFO:SubProcess create_model() end ==================================
2023-02-28 01:42:47,791:INFO:Creating metrics dataframe
2023-02-28 01:42:47,804:INFO:Initializing AdaBoost Regressor
2023-02-28 01:42:47,804:INFO:Total runtime is 0.3175234079360961 minutes
2023-02-28 01:42:47,809:INFO:SubProcess create_model() called ==================================
2023-02-28 01:42:47,809:INFO:Initializing create_model()
2023-02-28 01:42:47,809:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB070AFA30>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:42:47,809:INFO:Checking exceptions
2023-02-28 01:42:47,809:INFO:Importing libraries
2023-02-28 01:42:47,809:INFO:Copying training dataset
2023-02-28 01:42:47,811:INFO:Defining folds
2023-02-28 01:42:47,811:INFO:Declaring metric variables
2023-02-28 01:42:47,820:INFO:Importing untrained model
2023-02-28 01:42:47,824:INFO:AdaBoost Regressor Imported successfully
2023-02-28 01:42:47,831:INFO:Starting cross validation
2023-02-28 01:42:47,836:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:42:48,211:INFO:Calculating mean and std
2023-02-28 01:42:48,219:INFO:Creating metrics dataframe
2023-02-28 01:42:48,219:INFO:Uploading results into container
2023-02-28 01:42:48,219:INFO:Uploading model into container now
2023-02-28 01:42:48,219:INFO:_master_model_container: 15
2023-02-28 01:42:48,219:INFO:_display_container: 2
2023-02-28 01:42:48,219:INFO:AdaBoostRegressor(random_state=123)
2023-02-28 01:42:48,219:INFO:create_model() successfully completed......................................
2023-02-28 01:42:48,501:INFO:SubProcess create_model() end ==================================
2023-02-28 01:42:48,501:INFO:Creating metrics dataframe
2023-02-28 01:42:48,514:INFO:Initializing Gradient Boosting Regressor
2023-02-28 01:42:48,514:INFO:Total runtime is 0.3293476064999898 minutes
2023-02-28 01:42:48,515:INFO:SubProcess create_model() called ==================================
2023-02-28 01:42:48,518:INFO:Initializing create_model()
2023-02-28 01:42:48,518:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB070AFA30>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:42:48,518:INFO:Checking exceptions
2023-02-28 01:42:48,518:INFO:Importing libraries
2023-02-28 01:42:48,518:INFO:Copying training dataset
2023-02-28 01:42:48,522:INFO:Defining folds
2023-02-28 01:42:48,522:INFO:Declaring metric variables
2023-02-28 01:42:48,527:INFO:Importing untrained model
2023-02-28 01:42:48,529:INFO:Gradient Boosting Regressor Imported successfully
2023-02-28 01:42:48,584:INFO:Starting cross validation
2023-02-28 01:42:48,586:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:42:48,954:INFO:Calculating mean and std
2023-02-28 01:42:48,954:INFO:Creating metrics dataframe
2023-02-28 01:42:48,962:INFO:Uploading results into container
2023-02-28 01:42:48,962:INFO:Uploading model into container now
2023-02-28 01:42:48,962:INFO:_master_model_container: 16
2023-02-28 01:42:48,962:INFO:_display_container: 2
2023-02-28 01:42:48,965:INFO:GradientBoostingRegressor(random_state=123)
2023-02-28 01:42:48,965:INFO:create_model() successfully completed......................................
2023-02-28 01:42:49,234:INFO:SubProcess create_model() end ==================================
2023-02-28 01:42:49,234:INFO:Creating metrics dataframe
2023-02-28 01:42:49,250:INFO:Initializing Extreme Gradient Boosting
2023-02-28 01:42:49,250:INFO:Total runtime is 0.34161596298217767 minutes
2023-02-28 01:42:49,254:INFO:SubProcess create_model() called ==================================
2023-02-28 01:42:49,254:INFO:Initializing create_model()
2023-02-28 01:42:49,254:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB070AFA30>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:42:49,254:INFO:Checking exceptions
2023-02-28 01:42:49,254:INFO:Importing libraries
2023-02-28 01:42:49,256:INFO:Copying training dataset
2023-02-28 01:42:49,256:INFO:Defining folds
2023-02-28 01:42:49,256:INFO:Declaring metric variables
2023-02-28 01:42:49,264:INFO:Importing untrained model
2023-02-28 01:42:49,264:INFO:Extreme Gradient Boosting Imported successfully
2023-02-28 01:42:49,272:INFO:Starting cross validation
2023-02-28 01:42:49,272:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:42:49,747:INFO:Calculating mean and std
2023-02-28 01:42:49,749:INFO:Creating metrics dataframe
2023-02-28 01:42:49,752:INFO:Uploading results into container
2023-02-28 01:42:49,752:INFO:Uploading model into container now
2023-02-28 01:42:49,752:INFO:_master_model_container: 17
2023-02-28 01:42:49,752:INFO:_display_container: 2
2023-02-28 01:42:49,756:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=123, ...)
2023-02-28 01:42:49,756:INFO:create_model() successfully completed......................................
2023-02-28 01:42:50,036:INFO:SubProcess create_model() end ==================================
2023-02-28 01:42:50,036:INFO:Creating metrics dataframe
2023-02-28 01:42:50,048:INFO:Initializing Light Gradient Boosting Machine
2023-02-28 01:42:50,048:INFO:Total runtime is 0.35492344299952183 minutes
2023-02-28 01:42:50,051:INFO:SubProcess create_model() called ==================================
2023-02-28 01:42:50,051:INFO:Initializing create_model()
2023-02-28 01:42:50,051:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB070AFA30>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:42:50,054:INFO:Checking exceptions
2023-02-28 01:42:50,054:INFO:Importing libraries
2023-02-28 01:42:50,054:INFO:Copying training dataset
2023-02-28 01:42:50,056:INFO:Defining folds
2023-02-28 01:42:50,056:INFO:Declaring metric variables
2023-02-28 01:42:50,060:INFO:Importing untrained model
2023-02-28 01:42:50,067:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-28 01:42:50,077:INFO:Starting cross validation
2023-02-28 01:42:50,077:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:42:50,512:INFO:Calculating mean and std
2023-02-28 01:42:50,512:INFO:Creating metrics dataframe
2023-02-28 01:42:50,518:INFO:Uploading results into container
2023-02-28 01:42:50,518:INFO:Uploading model into container now
2023-02-28 01:42:50,518:INFO:_master_model_container: 18
2023-02-28 01:42:50,518:INFO:_display_container: 2
2023-02-28 01:42:50,518:INFO:LGBMRegressor(random_state=123)
2023-02-28 01:42:50,520:INFO:create_model() successfully completed......................................
2023-02-28 01:42:50,791:INFO:SubProcess create_model() end ==================================
2023-02-28 01:42:50,791:INFO:Creating metrics dataframe
2023-02-28 01:42:50,809:INFO:Initializing Dummy Regressor
2023-02-28 01:42:50,809:INFO:Total runtime is 0.3676002144813537 minutes
2023-02-28 01:42:50,813:INFO:SubProcess create_model() called ==================================
2023-02-28 01:42:50,813:INFO:Initializing create_model()
2023-02-28 01:42:50,813:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB070AFA30>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:42:50,814:INFO:Checking exceptions
2023-02-28 01:42:50,814:INFO:Importing libraries
2023-02-28 01:42:50,814:INFO:Copying training dataset
2023-02-28 01:42:50,817:INFO:Defining folds
2023-02-28 01:42:50,817:INFO:Declaring metric variables
2023-02-28 01:42:50,822:INFO:Importing untrained model
2023-02-28 01:42:50,826:INFO:Dummy Regressor Imported successfully
2023-02-28 01:42:50,835:INFO:Starting cross validation
2023-02-28 01:42:50,835:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:42:51,178:INFO:Calculating mean and std
2023-02-28 01:42:51,178:INFO:Creating metrics dataframe
2023-02-28 01:42:51,185:INFO:Uploading results into container
2023-02-28 01:42:51,186:INFO:Uploading model into container now
2023-02-28 01:42:51,187:INFO:_master_model_container: 19
2023-02-28 01:42:51,187:INFO:_display_container: 2
2023-02-28 01:42:51,187:INFO:DummyRegressor()
2023-02-28 01:42:51,187:INFO:create_model() successfully completed......................................
2023-02-28 01:42:51,455:INFO:SubProcess create_model() end ==================================
2023-02-28 01:42:51,455:INFO:Creating metrics dataframe
2023-02-28 01:42:51,487:INFO:Initializing create_model()
2023-02-28 01:42:51,487:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:42:51,487:INFO:Checking exceptions
2023-02-28 01:42:51,487:INFO:Importing libraries
2023-02-28 01:42:51,491:INFO:Copying training dataset
2023-02-28 01:42:51,495:INFO:Defining folds
2023-02-28 01:42:51,495:INFO:Declaring metric variables
2023-02-28 01:42:51,495:INFO:Importing untrained model
2023-02-28 01:42:51,495:INFO:Declaring custom model
2023-02-28 01:42:51,496:INFO:Huber Regressor Imported successfully
2023-02-28 01:42:51,497:INFO:Cross validation set to False
2023-02-28 01:42:51,497:INFO:Fitting Model
2023-02-28 01:42:51,602:INFO:HuberRegressor()
2023-02-28 01:42:51,602:INFO:create_model() successfully completed......................................
2023-02-28 01:42:51,916:INFO:_master_model_container: 19
2023-02-28 01:42:51,916:INFO:_display_container: 2
2023-02-28 01:42:51,916:INFO:HuberRegressor()
2023-02-28 01:42:51,916:INFO:compare_models() successfully completed......................................
2023-02-28 01:48:09,458:INFO:Initializing create_model()
2023-02-28 01:48:09,458:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=LinearRegression(n_jobs=-1), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:48:09,460:INFO:Checking exceptions
2023-02-28 01:48:09,461:INFO:Importing libraries
2023-02-28 01:48:09,461:INFO:Copying training dataset
2023-02-28 01:48:09,465:INFO:Defining folds
2023-02-28 01:48:09,465:INFO:Declaring metric variables
2023-02-28 01:48:09,465:INFO:Importing untrained model
2023-02-28 01:48:09,465:INFO:Declaring custom model
2023-02-28 01:48:09,465:INFO:Linear Regression Imported successfully
2023-02-28 01:48:09,465:INFO:Starting cross validation
2023-02-28 01:48:09,473:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:48:14,469:INFO:Calculating mean and std
2023-02-28 01:48:14,469:INFO:Creating metrics dataframe
2023-02-28 01:48:14,477:INFO:Finalizing model
2023-02-28 01:48:14,574:INFO:Uploading results into container
2023-02-28 01:48:14,582:INFO:_master_model_container: 19
2023-02-28 01:48:14,582:INFO:_display_container: 3
2023-02-28 01:48:14,582:INFO:LinearRegression(n_jobs=-1)
2023-02-28 01:48:14,582:INFO:create_model() successfully completed......................................
2023-02-28 01:48:14,879:INFO:Initializing create_model()
2023-02-28 01:48:14,879:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=Lasso(random_state=123), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:48:14,879:INFO:Checking exceptions
2023-02-28 01:48:14,882:INFO:Importing libraries
2023-02-28 01:48:14,882:INFO:Copying training dataset
2023-02-28 01:48:14,883:INFO:Defining folds
2023-02-28 01:48:14,883:INFO:Declaring metric variables
2023-02-28 01:48:14,883:INFO:Importing untrained model
2023-02-28 01:48:14,883:INFO:Declaring custom model
2023-02-28 01:48:14,885:INFO:Lasso Regression Imported successfully
2023-02-28 01:48:14,885:INFO:Starting cross validation
2023-02-28 01:48:14,886:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:48:17,848:INFO:Calculating mean and std
2023-02-28 01:48:17,851:INFO:Creating metrics dataframe
2023-02-28 01:48:17,852:INFO:Finalizing model
2023-02-28 01:48:17,944:INFO:Uploading results into container
2023-02-28 01:48:17,944:INFO:_master_model_container: 19
2023-02-28 01:48:17,946:INFO:_display_container: 4
2023-02-28 01:48:17,946:INFO:Lasso(random_state=123)
2023-02-28 01:48:17,946:INFO:create_model() successfully completed......................................
2023-02-28 01:48:18,227:INFO:Initializing create_model()
2023-02-28 01:48:18,227:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=Ridge(random_state=123), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:48:18,227:INFO:Checking exceptions
2023-02-28 01:48:18,231:INFO:Importing libraries
2023-02-28 01:48:18,231:INFO:Copying training dataset
2023-02-28 01:48:18,233:INFO:Defining folds
2023-02-28 01:48:18,233:INFO:Declaring metric variables
2023-02-28 01:48:18,233:INFO:Importing untrained model
2023-02-28 01:48:18,233:INFO:Declaring custom model
2023-02-28 01:48:18,233:INFO:Ridge Regression Imported successfully
2023-02-28 01:48:18,233:INFO:Starting cross validation
2023-02-28 01:48:18,233:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:48:18,565:INFO:Calculating mean and std
2023-02-28 01:48:18,573:INFO:Creating metrics dataframe
2023-02-28 01:48:18,573:INFO:Finalizing model
2023-02-28 01:48:18,655:INFO:Uploading results into container
2023-02-28 01:48:18,655:INFO:_master_model_container: 19
2023-02-28 01:48:18,655:INFO:_display_container: 5
2023-02-28 01:48:18,656:INFO:Ridge(random_state=123)
2023-02-28 01:48:18,656:INFO:create_model() successfully completed......................................
2023-02-28 01:48:18,964:INFO:Initializing create_model()
2023-02-28 01:48:18,964:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=ElasticNet(random_state=123), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:48:18,964:INFO:Checking exceptions
2023-02-28 01:48:18,968:INFO:Importing libraries
2023-02-28 01:48:18,968:INFO:Copying training dataset
2023-02-28 01:48:18,968:INFO:Defining folds
2023-02-28 01:48:18,968:INFO:Declaring metric variables
2023-02-28 01:48:18,968:INFO:Importing untrained model
2023-02-28 01:48:18,968:INFO:Declaring custom model
2023-02-28 01:48:18,968:INFO:Elastic Net Imported successfully
2023-02-28 01:48:18,968:INFO:Starting cross validation
2023-02-28 01:48:18,972:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:48:19,305:INFO:Calculating mean and std
2023-02-28 01:48:19,305:INFO:Creating metrics dataframe
2023-02-28 01:48:19,305:INFO:Finalizing model
2023-02-28 01:48:19,390:INFO:Uploading results into container
2023-02-28 01:48:19,390:INFO:_master_model_container: 19
2023-02-28 01:48:19,390:INFO:_display_container: 6
2023-02-28 01:48:19,390:INFO:ElasticNet(random_state=123)
2023-02-28 01:48:19,390:INFO:create_model() successfully completed......................................
2023-02-28 01:48:19,728:INFO:Initializing create_model()
2023-02-28 01:48:19,728:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=Lars(random_state=123), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:48:19,728:INFO:Checking exceptions
2023-02-28 01:48:19,731:INFO:Importing libraries
2023-02-28 01:48:19,731:INFO:Copying training dataset
2023-02-28 01:48:19,731:INFO:Defining folds
2023-02-28 01:48:19,731:INFO:Declaring metric variables
2023-02-28 01:48:19,731:INFO:Importing untrained model
2023-02-28 01:48:19,731:INFO:Declaring custom model
2023-02-28 01:48:19,731:INFO:Least Angle Regression Imported successfully
2023-02-28 01:48:19,731:INFO:Starting cross validation
2023-02-28 01:48:19,731:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:48:20,074:INFO:Calculating mean and std
2023-02-28 01:48:20,075:INFO:Creating metrics dataframe
2023-02-28 01:48:20,077:INFO:Finalizing model
2023-02-28 01:48:20,177:INFO:Uploading results into container
2023-02-28 01:48:20,177:INFO:_master_model_container: 19
2023-02-28 01:48:20,177:INFO:_display_container: 7
2023-02-28 01:48:20,177:INFO:Lars(random_state=123)
2023-02-28 01:48:20,177:INFO:create_model() successfully completed......................................
2023-02-28 01:48:20,480:INFO:Initializing create_model()
2023-02-28 01:48:20,480:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=LassoLars(random_state=123), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:48:20,480:INFO:Checking exceptions
2023-02-28 01:48:20,483:INFO:Importing libraries
2023-02-28 01:48:20,485:INFO:Copying training dataset
2023-02-28 01:48:20,485:INFO:Defining folds
2023-02-28 01:48:20,488:INFO:Declaring metric variables
2023-02-28 01:48:20,488:INFO:Importing untrained model
2023-02-28 01:48:20,488:INFO:Declaring custom model
2023-02-28 01:48:20,488:INFO:Lasso Least Angle Regression Imported successfully
2023-02-28 01:48:20,488:INFO:Starting cross validation
2023-02-28 01:48:20,488:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:48:20,862:INFO:Calculating mean and std
2023-02-28 01:48:20,862:INFO:Creating metrics dataframe
2023-02-28 01:48:20,870:INFO:Finalizing model
2023-02-28 01:48:20,943:INFO:Uploading results into container
2023-02-28 01:48:20,943:INFO:_master_model_container: 19
2023-02-28 01:48:20,943:INFO:_display_container: 8
2023-02-28 01:48:20,943:INFO:LassoLars(random_state=123)
2023-02-28 01:48:20,943:INFO:create_model() successfully completed......................................
2023-02-28 01:48:21,229:INFO:Initializing create_model()
2023-02-28 01:48:21,229:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=OrthogonalMatchingPursuit(), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:48:21,229:INFO:Checking exceptions
2023-02-28 01:48:21,236:INFO:Importing libraries
2023-02-28 01:48:21,236:INFO:Copying training dataset
2023-02-28 01:48:21,238:INFO:Defining folds
2023-02-28 01:48:21,238:INFO:Declaring metric variables
2023-02-28 01:48:21,238:INFO:Importing untrained model
2023-02-28 01:48:21,238:INFO:Declaring custom model
2023-02-28 01:48:21,238:INFO:Orthogonal Matching Pursuit Imported successfully
2023-02-28 01:48:21,238:INFO:Starting cross validation
2023-02-28 01:48:21,238:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:48:21,554:INFO:Calculating mean and std
2023-02-28 01:48:21,554:INFO:Creating metrics dataframe
2023-02-28 01:48:21,554:INFO:Finalizing model
2023-02-28 01:48:21,631:INFO:Uploading results into container
2023-02-28 01:48:21,631:INFO:_master_model_container: 19
2023-02-28 01:48:21,631:INFO:_display_container: 9
2023-02-28 01:48:21,631:INFO:OrthogonalMatchingPursuit()
2023-02-28 01:48:21,631:INFO:create_model() successfully completed......................................
2023-02-28 01:48:21,921:INFO:Initializing create_model()
2023-02-28 01:48:21,921:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=BayesianRidge(), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:48:21,921:INFO:Checking exceptions
2023-02-28 01:48:21,921:INFO:Importing libraries
2023-02-28 01:48:21,921:INFO:Copying training dataset
2023-02-28 01:48:21,921:INFO:Defining folds
2023-02-28 01:48:21,921:INFO:Declaring metric variables
2023-02-28 01:48:21,921:INFO:Importing untrained model
2023-02-28 01:48:21,921:INFO:Declaring custom model
2023-02-28 01:48:21,929:INFO:Bayesian Ridge Imported successfully
2023-02-28 01:48:21,929:INFO:Starting cross validation
2023-02-28 01:48:21,929:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:48:22,244:INFO:Calculating mean and std
2023-02-28 01:48:22,245:INFO:Creating metrics dataframe
2023-02-28 01:48:22,245:INFO:Finalizing model
2023-02-28 01:48:22,326:INFO:Uploading results into container
2023-02-28 01:48:22,326:INFO:_master_model_container: 19
2023-02-28 01:48:22,326:INFO:_display_container: 10
2023-02-28 01:48:22,326:INFO:BayesianRidge()
2023-02-28 01:48:22,326:INFO:create_model() successfully completed......................................
2023-02-28 01:48:22,624:INFO:Initializing create_model()
2023-02-28 01:48:22,624:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=PassiveAggressiveRegressor(random_state=123), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:48:22,624:INFO:Checking exceptions
2023-02-28 01:48:22,632:INFO:Importing libraries
2023-02-28 01:48:22,632:INFO:Copying training dataset
2023-02-28 01:48:22,635:INFO:Defining folds
2023-02-28 01:48:22,635:INFO:Declaring metric variables
2023-02-28 01:48:22,635:INFO:Importing untrained model
2023-02-28 01:48:22,635:INFO:Declaring custom model
2023-02-28 01:48:22,635:INFO:Passive Aggressive Regressor Imported successfully
2023-02-28 01:48:22,635:INFO:Starting cross validation
2023-02-28 01:48:22,637:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:48:22,958:INFO:Calculating mean and std
2023-02-28 01:48:22,958:INFO:Creating metrics dataframe
2023-02-28 01:48:22,958:INFO:Finalizing model
2023-02-28 01:48:23,040:INFO:Uploading results into container
2023-02-28 01:48:23,040:INFO:_master_model_container: 19
2023-02-28 01:48:23,040:INFO:_display_container: 11
2023-02-28 01:48:23,040:INFO:PassiveAggressiveRegressor(random_state=123)
2023-02-28 01:48:23,040:INFO:create_model() successfully completed......................................
2023-02-28 01:48:23,327:INFO:Initializing create_model()
2023-02-28 01:48:23,327:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=HuberRegressor(), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:48:23,327:INFO:Checking exceptions
2023-02-28 01:48:23,328:INFO:Importing libraries
2023-02-28 01:48:23,328:INFO:Copying training dataset
2023-02-28 01:48:23,332:INFO:Defining folds
2023-02-28 01:48:23,332:INFO:Declaring metric variables
2023-02-28 01:48:23,332:INFO:Importing untrained model
2023-02-28 01:48:23,332:INFO:Declaring custom model
2023-02-28 01:48:23,332:INFO:Huber Regressor Imported successfully
2023-02-28 01:48:23,332:INFO:Starting cross validation
2023-02-28 01:48:23,332:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:48:23,533:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:48:23,541:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:48:23,590:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:48:23,630:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:48:23,630:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:48:23,647:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:48:23,655:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:48:23,672:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:48:23,672:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:48:23,739:INFO:Calculating mean and std
2023-02-28 01:48:23,739:INFO:Creating metrics dataframe
2023-02-28 01:48:23,744:INFO:Finalizing model
2023-02-28 01:48:23,853:INFO:Uploading results into container
2023-02-28 01:48:23,853:INFO:_master_model_container: 19
2023-02-28 01:48:23,853:INFO:_display_container: 12
2023-02-28 01:48:23,855:INFO:HuberRegressor()
2023-02-28 01:48:23,855:INFO:create_model() successfully completed......................................
2023-02-28 01:48:24,160:INFO:Initializing create_model()
2023-02-28 01:48:24,161:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=KNeighborsRegressor(n_jobs=-1), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:48:24,161:INFO:Checking exceptions
2023-02-28 01:48:24,164:INFO:Importing libraries
2023-02-28 01:48:24,164:INFO:Copying training dataset
2023-02-28 01:48:24,167:INFO:Defining folds
2023-02-28 01:48:24,167:INFO:Declaring metric variables
2023-02-28 01:48:24,167:INFO:Importing untrained model
2023-02-28 01:48:24,167:INFO:Declaring custom model
2023-02-28 01:48:24,167:INFO:K Neighbors Regressor Imported successfully
2023-02-28 01:48:24,167:INFO:Starting cross validation
2023-02-28 01:48:24,167:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:48:24,536:INFO:Calculating mean and std
2023-02-28 01:48:24,536:INFO:Creating metrics dataframe
2023-02-28 01:48:24,539:INFO:Finalizing model
2023-02-28 01:48:24,612:INFO:Uploading results into container
2023-02-28 01:48:24,612:INFO:_master_model_container: 19
2023-02-28 01:48:24,612:INFO:_display_container: 13
2023-02-28 01:48:24,612:INFO:KNeighborsRegressor(n_jobs=-1)
2023-02-28 01:48:24,612:INFO:create_model() successfully completed......................................
2023-02-28 01:48:24,904:INFO:Initializing create_model()
2023-02-28 01:48:24,904:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=DecisionTreeRegressor(random_state=123), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:48:24,904:INFO:Checking exceptions
2023-02-28 01:48:24,904:INFO:Importing libraries
2023-02-28 01:48:24,904:INFO:Copying training dataset
2023-02-28 01:48:24,912:INFO:Defining folds
2023-02-28 01:48:24,912:INFO:Declaring metric variables
2023-02-28 01:48:24,912:INFO:Importing untrained model
2023-02-28 01:48:24,912:INFO:Declaring custom model
2023-02-28 01:48:24,912:INFO:Decision Tree Regressor Imported successfully
2023-02-28 01:48:24,912:INFO:Starting cross validation
2023-02-28 01:48:24,912:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:48:25,264:INFO:Calculating mean and std
2023-02-28 01:48:25,264:INFO:Creating metrics dataframe
2023-02-28 01:48:25,266:INFO:Finalizing model
2023-02-28 01:48:25,349:INFO:Uploading results into container
2023-02-28 01:48:25,349:INFO:_master_model_container: 19
2023-02-28 01:48:25,349:INFO:_display_container: 14
2023-02-28 01:48:25,349:INFO:DecisionTreeRegressor(random_state=123)
2023-02-28 01:48:25,349:INFO:create_model() successfully completed......................................
2023-02-28 01:48:25,655:INFO:Initializing create_model()
2023-02-28 01:48:25,655:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:48:25,655:INFO:Checking exceptions
2023-02-28 01:48:25,655:INFO:Importing libraries
2023-02-28 01:48:25,655:INFO:Copying training dataset
2023-02-28 01:48:25,663:INFO:Defining folds
2023-02-28 01:48:25,663:INFO:Declaring metric variables
2023-02-28 01:48:25,663:INFO:Importing untrained model
2023-02-28 01:48:25,663:INFO:Declaring custom model
2023-02-28 01:48:25,663:INFO:Random Forest Regressor Imported successfully
2023-02-28 01:48:25,663:INFO:Starting cross validation
2023-02-28 01:48:25,663:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:48:26,162:INFO:Calculating mean and std
2023-02-28 01:48:26,165:INFO:Creating metrics dataframe
2023-02-28 01:48:26,165:INFO:Finalizing model
2023-02-28 01:48:26,506:INFO:Uploading results into container
2023-02-28 01:48:26,506:INFO:_master_model_container: 19
2023-02-28 01:48:26,506:INFO:_display_container: 15
2023-02-28 01:48:26,506:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-02-28 01:48:26,506:INFO:create_model() successfully completed......................................
2023-02-28 01:48:26,795:INFO:Initializing create_model()
2023-02-28 01:48:26,795:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:48:26,795:INFO:Checking exceptions
2023-02-28 01:48:26,799:INFO:Importing libraries
2023-02-28 01:48:26,799:INFO:Copying training dataset
2023-02-28 01:48:26,804:INFO:Defining folds
2023-02-28 01:48:26,804:INFO:Declaring metric variables
2023-02-28 01:48:26,804:INFO:Importing untrained model
2023-02-28 01:48:26,804:INFO:Declaring custom model
2023-02-28 01:48:26,804:INFO:Extra Trees Regressor Imported successfully
2023-02-28 01:48:26,804:INFO:Starting cross validation
2023-02-28 01:48:26,804:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:48:27,255:INFO:Calculating mean and std
2023-02-28 01:48:27,255:INFO:Creating metrics dataframe
2023-02-28 01:48:27,255:INFO:Finalizing model
2023-02-28 01:48:27,554:INFO:Uploading results into container
2023-02-28 01:48:27,554:INFO:_master_model_container: 19
2023-02-28 01:48:27,554:INFO:_display_container: 16
2023-02-28 01:48:27,554:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-02-28 01:48:27,554:INFO:create_model() successfully completed......................................
2023-02-28 01:48:27,846:INFO:Initializing create_model()
2023-02-28 01:48:27,846:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=AdaBoostRegressor(random_state=123), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:48:27,846:INFO:Checking exceptions
2023-02-28 01:48:27,853:INFO:Importing libraries
2023-02-28 01:48:27,853:INFO:Copying training dataset
2023-02-28 01:48:27,854:INFO:Defining folds
2023-02-28 01:48:27,854:INFO:Declaring metric variables
2023-02-28 01:48:27,854:INFO:Importing untrained model
2023-02-28 01:48:27,854:INFO:Declaring custom model
2023-02-28 01:48:27,854:INFO:str Imported successfully
2023-02-28 01:48:27,854:INFO:Starting cross validation
2023-02-28 01:48:27,854:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:48:28,199:INFO:Calculating mean and std
2023-02-28 01:48:28,199:INFO:Creating metrics dataframe
2023-02-28 01:48:28,202:INFO:Finalizing model
2023-02-28 01:48:28,289:INFO:Uploading results into container
2023-02-28 01:48:28,297:INFO:_master_model_container: 19
2023-02-28 01:48:28,297:INFO:_display_container: 17
2023-02-28 01:48:28,297:INFO:AdaBoostRegressor(random_state=123)
2023-02-28 01:48:28,297:INFO:create_model() successfully completed......................................
2023-02-28 01:48:28,653:INFO:Initializing create_model()
2023-02-28 01:48:28,653:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=GradientBoostingRegressor(random_state=123), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:48:28,653:INFO:Checking exceptions
2023-02-28 01:48:28,653:INFO:Importing libraries
2023-02-28 01:48:28,653:INFO:Copying training dataset
2023-02-28 01:48:28,653:INFO:Defining folds
2023-02-28 01:48:28,653:INFO:Declaring metric variables
2023-02-28 01:48:28,653:INFO:Importing untrained model
2023-02-28 01:48:28,653:INFO:Declaring custom model
2023-02-28 01:48:28,653:INFO:Gradient Boosting Regressor Imported successfully
2023-02-28 01:48:28,653:INFO:Starting cross validation
2023-02-28 01:48:28,661:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:48:29,047:INFO:Calculating mean and std
2023-02-28 01:48:29,047:INFO:Creating metrics dataframe
2023-02-28 01:48:29,047:INFO:Finalizing model
2023-02-28 01:48:29,207:INFO:Uploading results into container
2023-02-28 01:48:29,207:INFO:_master_model_container: 19
2023-02-28 01:48:29,207:INFO:_display_container: 18
2023-02-28 01:48:29,207:INFO:GradientBoostingRegressor(random_state=123)
2023-02-28 01:48:29,207:INFO:create_model() successfully completed......................................
2023-02-28 01:48:29,507:INFO:Initializing create_model()
2023-02-28 01:48:29,507:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=123, ...), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:48:29,507:INFO:Checking exceptions
2023-02-28 01:48:29,507:INFO:Importing libraries
2023-02-28 01:48:29,507:INFO:Copying training dataset
2023-02-28 01:48:29,515:INFO:Defining folds
2023-02-28 01:48:29,515:INFO:Declaring metric variables
2023-02-28 01:48:29,515:INFO:Importing untrained model
2023-02-28 01:48:29,515:INFO:Declaring custom model
2023-02-28 01:48:29,515:INFO:Extreme Gradient Boosting Imported successfully
2023-02-28 01:48:29,515:INFO:Starting cross validation
2023-02-28 01:48:29,515:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:48:30,042:INFO:Calculating mean and std
2023-02-28 01:48:30,042:INFO:Creating metrics dataframe
2023-02-28 01:48:30,050:INFO:Finalizing model
2023-02-28 01:48:30,229:INFO:Uploading results into container
2023-02-28 01:48:30,229:INFO:_master_model_container: 19
2023-02-28 01:48:30,229:INFO:_display_container: 19
2023-02-28 01:48:30,229:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=123, ...)
2023-02-28 01:48:30,229:INFO:create_model() successfully completed......................................
2023-02-28 01:48:30,533:INFO:Initializing create_model()
2023-02-28 01:48:30,533:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=LGBMRegressor(random_state=123), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:48:30,533:INFO:Checking exceptions
2023-02-28 01:48:30,536:INFO:Importing libraries
2023-02-28 01:48:30,536:INFO:Copying training dataset
2023-02-28 01:48:30,537:INFO:Defining folds
2023-02-28 01:48:30,537:INFO:Declaring metric variables
2023-02-28 01:48:30,537:INFO:Importing untrained model
2023-02-28 01:48:30,537:INFO:Declaring custom model
2023-02-28 01:48:30,537:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-28 01:48:30,537:INFO:Starting cross validation
2023-02-28 01:48:30,537:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:48:30,963:INFO:Calculating mean and std
2023-02-28 01:48:30,963:INFO:Creating metrics dataframe
2023-02-28 01:48:30,963:INFO:Finalizing model
2023-02-28 01:48:31,175:INFO:Uploading results into container
2023-02-28 01:48:31,181:INFO:_master_model_container: 19
2023-02-28 01:48:31,181:INFO:_display_container: 20
2023-02-28 01:48:31,181:INFO:LGBMRegressor(random_state=123)
2023-02-28 01:48:31,181:INFO:create_model() successfully completed......................................
2023-02-28 01:48:31,479:INFO:Initializing create_model()
2023-02-28 01:48:31,479:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=DummyRegressor(), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:48:31,479:INFO:Checking exceptions
2023-02-28 01:48:31,479:INFO:Importing libraries
2023-02-28 01:48:31,479:INFO:Copying training dataset
2023-02-28 01:48:31,488:INFO:Defining folds
2023-02-28 01:48:31,488:INFO:Declaring metric variables
2023-02-28 01:48:31,488:INFO:Importing untrained model
2023-02-28 01:48:31,488:INFO:Declaring custom model
2023-02-28 01:48:31,488:INFO:Dummy Regressor Imported successfully
2023-02-28 01:48:31,488:INFO:Starting cross validation
2023-02-28 01:48:31,488:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:48:31,840:INFO:Calculating mean and std
2023-02-28 01:48:31,840:INFO:Creating metrics dataframe
2023-02-28 01:48:31,841:INFO:Finalizing model
2023-02-28 01:48:31,922:INFO:Uploading results into container
2023-02-28 01:48:31,922:INFO:_master_model_container: 19
2023-02-28 01:48:31,922:INFO:_display_container: 21
2023-02-28 01:48:31,922:INFO:DummyRegressor()
2023-02-28 01:48:31,922:INFO:create_model() successfully completed......................................
2023-02-28 01:53:15,518:INFO:Initializing compare_models()
2023-02-28 01:53:15,518:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, include=['catboost'], fold=None, round=4, cross_validation=True, sort=R2, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, 'include': ['catboost'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-02-28 01:53:15,518:INFO:Checking exceptions
2023-02-28 01:53:34,357:INFO:Initializing compare_models()
2023-02-28 01:53:34,357:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-02-28 01:53:34,357:INFO:Checking exceptions
2023-02-28 01:53:34,366:INFO:Preparing display monitor
2023-02-28 01:53:34,398:INFO:Initializing Linear Regression
2023-02-28 01:53:34,398:INFO:Total runtime is 0.0 minutes
2023-02-28 01:53:34,402:INFO:SubProcess create_model() called ==================================
2023-02-28 01:53:34,402:INFO:Initializing create_model()
2023-02-28 01:53:34,402:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB088E4C40>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:53:34,402:INFO:Checking exceptions
2023-02-28 01:53:34,402:INFO:Importing libraries
2023-02-28 01:53:34,402:INFO:Copying training dataset
2023-02-28 01:53:34,406:INFO:Defining folds
2023-02-28 01:53:34,406:INFO:Declaring metric variables
2023-02-28 01:53:34,414:INFO:Importing untrained model
2023-02-28 01:53:34,414:INFO:Linear Regression Imported successfully
2023-02-28 01:53:34,422:INFO:Starting cross validation
2023-02-28 01:53:34,430:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:53:41,197:INFO:Calculating mean and std
2023-02-28 01:53:41,203:INFO:Creating metrics dataframe
2023-02-28 01:53:41,207:INFO:Uploading results into container
2023-02-28 01:53:41,209:INFO:Uploading model into container now
2023-02-28 01:53:41,209:INFO:_master_model_container: 20
2023-02-28 01:53:41,209:INFO:_display_container: 22
2023-02-28 01:53:41,209:INFO:LinearRegression(n_jobs=-1)
2023-02-28 01:53:41,209:INFO:create_model() successfully completed......................................
2023-02-28 01:53:41,502:INFO:SubProcess create_model() end ==================================
2023-02-28 01:53:41,502:INFO:Creating metrics dataframe
2023-02-28 01:53:41,508:INFO:Initializing Lasso Regression
2023-02-28 01:53:41,508:INFO:Total runtime is 0.11850562095642089 minutes
2023-02-28 01:53:41,513:INFO:SubProcess create_model() called ==================================
2023-02-28 01:53:41,513:INFO:Initializing create_model()
2023-02-28 01:53:41,513:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB088E4C40>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:53:41,513:INFO:Checking exceptions
2023-02-28 01:53:41,513:INFO:Importing libraries
2023-02-28 01:53:41,513:INFO:Copying training dataset
2023-02-28 01:53:41,518:INFO:Defining folds
2023-02-28 01:53:41,518:INFO:Declaring metric variables
2023-02-28 01:53:41,525:INFO:Importing untrained model
2023-02-28 01:53:41,527:INFO:Lasso Regression Imported successfully
2023-02-28 01:53:41,538:INFO:Starting cross validation
2023-02-28 01:53:41,540:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:53:44,361:INFO:Calculating mean and std
2023-02-28 01:53:44,361:INFO:Creating metrics dataframe
2023-02-28 01:53:44,367:INFO:Uploading results into container
2023-02-28 01:53:44,367:INFO:Uploading model into container now
2023-02-28 01:53:44,367:INFO:_master_model_container: 21
2023-02-28 01:53:44,367:INFO:_display_container: 22
2023-02-28 01:53:44,370:INFO:Lasso(random_state=123)
2023-02-28 01:53:44,370:INFO:create_model() successfully completed......................................
2023-02-28 01:53:44,654:INFO:SubProcess create_model() end ==================================
2023-02-28 01:53:44,654:INFO:Creating metrics dataframe
2023-02-28 01:53:44,663:INFO:Initializing Ridge Regression
2023-02-28 01:53:44,663:INFO:Total runtime is 0.17108542919158937 minutes
2023-02-28 01:53:44,663:INFO:SubProcess create_model() called ==================================
2023-02-28 01:53:44,663:INFO:Initializing create_model()
2023-02-28 01:53:44,663:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB088E4C40>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:53:44,663:INFO:Checking exceptions
2023-02-28 01:53:44,663:INFO:Importing libraries
2023-02-28 01:53:44,669:INFO:Copying training dataset
2023-02-28 01:53:44,671:INFO:Defining folds
2023-02-28 01:53:44,671:INFO:Declaring metric variables
2023-02-28 01:53:44,671:INFO:Importing untrained model
2023-02-28 01:53:44,680:INFO:Ridge Regression Imported successfully
2023-02-28 01:53:44,687:INFO:Starting cross validation
2023-02-28 01:53:44,691:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:53:44,996:INFO:Calculating mean and std
2023-02-28 01:53:44,996:INFO:Creating metrics dataframe
2023-02-28 01:53:45,005:INFO:Uploading results into container
2023-02-28 01:53:45,006:INFO:Uploading model into container now
2023-02-28 01:53:45,006:INFO:_master_model_container: 22
2023-02-28 01:53:45,006:INFO:_display_container: 22
2023-02-28 01:53:45,006:INFO:Ridge(random_state=123)
2023-02-28 01:53:45,006:INFO:create_model() successfully completed......................................
2023-02-28 01:53:45,274:INFO:SubProcess create_model() end ==================================
2023-02-28 01:53:45,274:INFO:Creating metrics dataframe
2023-02-28 01:53:45,290:INFO:Initializing Elastic Net
2023-02-28 01:53:45,290:INFO:Total runtime is 0.1815393368403117 minutes
2023-02-28 01:53:45,294:INFO:SubProcess create_model() called ==================================
2023-02-28 01:53:45,294:INFO:Initializing create_model()
2023-02-28 01:53:45,294:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB088E4C40>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:53:45,294:INFO:Checking exceptions
2023-02-28 01:53:45,294:INFO:Importing libraries
2023-02-28 01:53:45,294:INFO:Copying training dataset
2023-02-28 01:53:45,298:INFO:Defining folds
2023-02-28 01:53:45,298:INFO:Declaring metric variables
2023-02-28 01:53:45,304:INFO:Importing untrained model
2023-02-28 01:53:45,306:INFO:Elastic Net Imported successfully
2023-02-28 01:53:45,315:INFO:Starting cross validation
2023-02-28 01:53:45,315:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:53:45,655:INFO:Calculating mean and std
2023-02-28 01:53:45,655:INFO:Creating metrics dataframe
2023-02-28 01:53:45,663:INFO:Uploading results into container
2023-02-28 01:53:45,663:INFO:Uploading model into container now
2023-02-28 01:53:45,663:INFO:_master_model_container: 23
2023-02-28 01:53:45,663:INFO:_display_container: 22
2023-02-28 01:53:45,663:INFO:ElasticNet(random_state=123)
2023-02-28 01:53:45,663:INFO:create_model() successfully completed......................................
2023-02-28 01:53:45,941:INFO:SubProcess create_model() end ==================================
2023-02-28 01:53:45,941:INFO:Creating metrics dataframe
2023-02-28 01:53:45,953:INFO:Initializing Least Angle Regression
2023-02-28 01:53:45,953:INFO:Total runtime is 0.1925853689511617 minutes
2023-02-28 01:53:45,957:INFO:SubProcess create_model() called ==================================
2023-02-28 01:53:45,957:INFO:Initializing create_model()
2023-02-28 01:53:45,959:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB088E4C40>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:53:45,959:INFO:Checking exceptions
2023-02-28 01:53:45,959:INFO:Importing libraries
2023-02-28 01:53:45,959:INFO:Copying training dataset
2023-02-28 01:53:45,963:INFO:Defining folds
2023-02-28 01:53:45,963:INFO:Declaring metric variables
2023-02-28 01:53:45,968:INFO:Importing untrained model
2023-02-28 01:53:45,974:INFO:Least Angle Regression Imported successfully
2023-02-28 01:53:45,980:INFO:Starting cross validation
2023-02-28 01:53:45,980:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:53:46,307:INFO:Calculating mean and std
2023-02-28 01:53:46,314:INFO:Creating metrics dataframe
2023-02-28 01:53:46,317:INFO:Uploading results into container
2023-02-28 01:53:46,317:INFO:Uploading model into container now
2023-02-28 01:53:46,317:INFO:_master_model_container: 24
2023-02-28 01:53:46,317:INFO:_display_container: 22
2023-02-28 01:53:46,317:INFO:Lars(random_state=123)
2023-02-28 01:53:46,317:INFO:create_model() successfully completed......................................
2023-02-28 01:53:46,618:INFO:SubProcess create_model() end ==================================
2023-02-28 01:53:46,618:INFO:Creating metrics dataframe
2023-02-28 01:53:46,628:INFO:Initializing Lasso Least Angle Regression
2023-02-28 01:53:46,630:INFO:Total runtime is 0.20387741724650066 minutes
2023-02-28 01:53:46,630:INFO:SubProcess create_model() called ==================================
2023-02-28 01:53:46,634:INFO:Initializing create_model()
2023-02-28 01:53:46,634:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB088E4C40>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:53:46,634:INFO:Checking exceptions
2023-02-28 01:53:46,634:INFO:Importing libraries
2023-02-28 01:53:46,635:INFO:Copying training dataset
2023-02-28 01:53:46,638:INFO:Defining folds
2023-02-28 01:53:46,638:INFO:Declaring metric variables
2023-02-28 01:53:46,643:INFO:Importing untrained model
2023-02-28 01:53:46,650:INFO:Lasso Least Angle Regression Imported successfully
2023-02-28 01:53:46,659:INFO:Starting cross validation
2023-02-28 01:53:46,661:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:53:46,987:INFO:Calculating mean and std
2023-02-28 01:53:46,991:INFO:Creating metrics dataframe
2023-02-28 01:53:46,995:INFO:Uploading results into container
2023-02-28 01:53:46,995:INFO:Uploading model into container now
2023-02-28 01:53:46,995:INFO:_master_model_container: 25
2023-02-28 01:53:46,995:INFO:_display_container: 22
2023-02-28 01:53:46,995:INFO:LassoLars(random_state=123)
2023-02-28 01:53:46,995:INFO:create_model() successfully completed......................................
2023-02-28 01:53:47,294:INFO:SubProcess create_model() end ==================================
2023-02-28 01:53:47,294:INFO:Creating metrics dataframe
2023-02-28 01:53:47,309:INFO:Initializing Orthogonal Matching Pursuit
2023-02-28 01:53:47,309:INFO:Total runtime is 0.21518107255299887 minutes
2023-02-28 01:53:47,310:INFO:SubProcess create_model() called ==================================
2023-02-28 01:53:47,310:INFO:Initializing create_model()
2023-02-28 01:53:47,310:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB088E4C40>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:53:47,310:INFO:Checking exceptions
2023-02-28 01:53:47,310:INFO:Importing libraries
2023-02-28 01:53:47,310:INFO:Copying training dataset
2023-02-28 01:53:47,316:INFO:Defining folds
2023-02-28 01:53:47,316:INFO:Declaring metric variables
2023-02-28 01:53:47,322:INFO:Importing untrained model
2023-02-28 01:53:47,322:INFO:Orthogonal Matching Pursuit Imported successfully
2023-02-28 01:53:47,329:INFO:Starting cross validation
2023-02-28 01:53:47,334:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:53:47,667:INFO:Calculating mean and std
2023-02-28 01:53:47,668:INFO:Creating metrics dataframe
2023-02-28 01:53:47,668:INFO:Uploading results into container
2023-02-28 01:53:47,668:INFO:Uploading model into container now
2023-02-28 01:53:47,668:INFO:_master_model_container: 26
2023-02-28 01:53:47,668:INFO:_display_container: 22
2023-02-28 01:53:47,668:INFO:OrthogonalMatchingPursuit()
2023-02-28 01:53:47,668:INFO:create_model() successfully completed......................................
2023-02-28 01:53:47,953:INFO:SubProcess create_model() end ==================================
2023-02-28 01:53:47,953:INFO:Creating metrics dataframe
2023-02-28 01:53:47,966:INFO:Initializing Bayesian Ridge
2023-02-28 01:53:47,966:INFO:Total runtime is 0.22614045143127443 minutes
2023-02-28 01:53:47,969:INFO:SubProcess create_model() called ==================================
2023-02-28 01:53:47,971:INFO:Initializing create_model()
2023-02-28 01:53:47,971:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB088E4C40>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:53:47,971:INFO:Checking exceptions
2023-02-28 01:53:47,971:INFO:Importing libraries
2023-02-28 01:53:47,971:INFO:Copying training dataset
2023-02-28 01:53:47,976:INFO:Defining folds
2023-02-28 01:53:47,976:INFO:Declaring metric variables
2023-02-28 01:53:47,981:INFO:Importing untrained model
2023-02-28 01:53:47,984:INFO:Bayesian Ridge Imported successfully
2023-02-28 01:53:47,992:INFO:Starting cross validation
2023-02-28 01:53:47,992:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:53:48,339:INFO:Calculating mean and std
2023-02-28 01:53:48,341:INFO:Creating metrics dataframe
2023-02-28 01:53:48,356:INFO:Uploading results into container
2023-02-28 01:53:48,356:INFO:Uploading model into container now
2023-02-28 01:53:48,356:INFO:_master_model_container: 27
2023-02-28 01:53:48,356:INFO:_display_container: 22
2023-02-28 01:53:48,356:INFO:BayesianRidge()
2023-02-28 01:53:48,356:INFO:create_model() successfully completed......................................
2023-02-28 01:53:48,631:INFO:SubProcess create_model() end ==================================
2023-02-28 01:53:48,631:INFO:Creating metrics dataframe
2023-02-28 01:53:48,639:INFO:Initializing Passive Aggressive Regressor
2023-02-28 01:53:48,639:INFO:Total runtime is 0.23735934893290203 minutes
2023-02-28 01:53:48,649:INFO:SubProcess create_model() called ==================================
2023-02-28 01:53:48,649:INFO:Initializing create_model()
2023-02-28 01:53:48,649:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB088E4C40>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:53:48,649:INFO:Checking exceptions
2023-02-28 01:53:48,649:INFO:Importing libraries
2023-02-28 01:53:48,649:INFO:Copying training dataset
2023-02-28 01:53:48,653:INFO:Defining folds
2023-02-28 01:53:48,653:INFO:Declaring metric variables
2023-02-28 01:53:48,658:INFO:Importing untrained model
2023-02-28 01:53:48,661:INFO:Passive Aggressive Regressor Imported successfully
2023-02-28 01:53:48,667:INFO:Starting cross validation
2023-02-28 01:53:48,672:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:53:48,987:INFO:Calculating mean and std
2023-02-28 01:53:48,988:INFO:Creating metrics dataframe
2023-02-28 01:53:48,993:INFO:Uploading results into container
2023-02-28 01:53:48,994:INFO:Uploading model into container now
2023-02-28 01:53:48,995:INFO:_master_model_container: 28
2023-02-28 01:53:48,995:INFO:_display_container: 22
2023-02-28 01:53:48,995:INFO:PassiveAggressiveRegressor(random_state=123)
2023-02-28 01:53:48,995:INFO:create_model() successfully completed......................................
2023-02-28 01:53:49,274:INFO:SubProcess create_model() end ==================================
2023-02-28 01:53:49,274:INFO:Creating metrics dataframe
2023-02-28 01:53:49,285:INFO:Initializing Huber Regressor
2023-02-28 01:53:49,285:INFO:Total runtime is 0.24811817407608033 minutes
2023-02-28 01:53:49,290:INFO:SubProcess create_model() called ==================================
2023-02-28 01:53:49,291:INFO:Initializing create_model()
2023-02-28 01:53:49,291:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB088E4C40>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:53:49,291:INFO:Checking exceptions
2023-02-28 01:53:49,291:INFO:Importing libraries
2023-02-28 01:53:49,291:INFO:Copying training dataset
2023-02-28 01:53:49,294:INFO:Defining folds
2023-02-28 01:53:49,294:INFO:Declaring metric variables
2023-02-28 01:53:49,298:INFO:Importing untrained model
2023-02-28 01:53:49,301:INFO:Huber Regressor Imported successfully
2023-02-28 01:53:49,309:INFO:Starting cross validation
2023-02-28 01:53:49,312:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:53:49,517:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:53:49,550:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:53:49,558:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:53:49,575:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:53:49,584:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:53:49,592:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:53:49,592:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:53:49,603:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:53:49,623:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:53:49,623:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:53:49,679:INFO:Calculating mean and std
2023-02-28 01:53:49,679:INFO:Creating metrics dataframe
2023-02-28 01:53:49,687:INFO:Uploading results into container
2023-02-28 01:53:49,689:INFO:Uploading model into container now
2023-02-28 01:53:49,689:INFO:_master_model_container: 29
2023-02-28 01:53:49,689:INFO:_display_container: 22
2023-02-28 01:53:49,689:INFO:HuberRegressor()
2023-02-28 01:53:49,689:INFO:create_model() successfully completed......................................
2023-02-28 01:53:49,972:INFO:SubProcess create_model() end ==================================
2023-02-28 01:53:49,972:INFO:Creating metrics dataframe
2023-02-28 01:53:49,988:INFO:Initializing K Neighbors Regressor
2023-02-28 01:53:49,990:INFO:Total runtime is 0.2598663926124573 minutes
2023-02-28 01:53:49,994:INFO:SubProcess create_model() called ==================================
2023-02-28 01:53:49,994:INFO:Initializing create_model()
2023-02-28 01:53:49,994:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB088E4C40>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:53:49,994:INFO:Checking exceptions
2023-02-28 01:53:49,994:INFO:Importing libraries
2023-02-28 01:53:49,994:INFO:Copying training dataset
2023-02-28 01:53:49,997:INFO:Defining folds
2023-02-28 01:53:49,997:INFO:Declaring metric variables
2023-02-28 01:53:50,001:INFO:Importing untrained model
2023-02-28 01:53:50,004:INFO:K Neighbors Regressor Imported successfully
2023-02-28 01:53:50,012:INFO:Starting cross validation
2023-02-28 01:53:50,018:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:53:50,382:INFO:Calculating mean and std
2023-02-28 01:53:50,382:INFO:Creating metrics dataframe
2023-02-28 01:53:50,382:INFO:Uploading results into container
2023-02-28 01:53:50,390:INFO:Uploading model into container now
2023-02-28 01:53:50,390:INFO:_master_model_container: 30
2023-02-28 01:53:50,390:INFO:_display_container: 22
2023-02-28 01:53:50,390:INFO:KNeighborsRegressor(n_jobs=-1)
2023-02-28 01:53:50,390:INFO:create_model() successfully completed......................................
2023-02-28 01:53:50,670:INFO:SubProcess create_model() end ==================================
2023-02-28 01:53:50,670:INFO:Creating metrics dataframe
2023-02-28 01:53:50,680:INFO:Initializing Decision Tree Regressor
2023-02-28 01:53:50,680:INFO:Total runtime is 0.2713799675305685 minutes
2023-02-28 01:53:50,684:INFO:SubProcess create_model() called ==================================
2023-02-28 01:53:50,684:INFO:Initializing create_model()
2023-02-28 01:53:50,686:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB088E4C40>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:53:50,686:INFO:Checking exceptions
2023-02-28 01:53:50,686:INFO:Importing libraries
2023-02-28 01:53:50,686:INFO:Copying training dataset
2023-02-28 01:53:50,689:INFO:Defining folds
2023-02-28 01:53:50,689:INFO:Declaring metric variables
2023-02-28 01:53:50,693:INFO:Importing untrained model
2023-02-28 01:53:50,697:INFO:Decision Tree Regressor Imported successfully
2023-02-28 01:53:50,710:INFO:Starting cross validation
2023-02-28 01:53:50,711:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:53:51,060:INFO:Calculating mean and std
2023-02-28 01:53:51,060:INFO:Creating metrics dataframe
2023-02-28 01:53:51,068:INFO:Uploading results into container
2023-02-28 01:53:51,068:INFO:Uploading model into container now
2023-02-28 01:53:51,068:INFO:_master_model_container: 31
2023-02-28 01:53:51,068:INFO:_display_container: 22
2023-02-28 01:53:51,068:INFO:DecisionTreeRegressor(random_state=123)
2023-02-28 01:53:51,068:INFO:create_model() successfully completed......................................
2023-02-28 01:53:51,350:INFO:SubProcess create_model() end ==================================
2023-02-28 01:53:51,352:INFO:Creating metrics dataframe
2023-02-28 01:53:51,359:INFO:Initializing Random Forest Regressor
2023-02-28 01:53:51,359:INFO:Total runtime is 0.2826820055643718 minutes
2023-02-28 01:53:51,359:INFO:SubProcess create_model() called ==================================
2023-02-28 01:53:51,367:INFO:Initializing create_model()
2023-02-28 01:53:51,367:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB088E4C40>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:53:51,367:INFO:Checking exceptions
2023-02-28 01:53:51,367:INFO:Importing libraries
2023-02-28 01:53:51,367:INFO:Copying training dataset
2023-02-28 01:53:51,370:INFO:Defining folds
2023-02-28 01:53:51,370:INFO:Declaring metric variables
2023-02-28 01:53:51,377:INFO:Importing untrained model
2023-02-28 01:53:51,379:INFO:Random Forest Regressor Imported successfully
2023-02-28 01:53:51,386:INFO:Starting cross validation
2023-02-28 01:53:51,386:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:53:51,874:INFO:Calculating mean and std
2023-02-28 01:53:51,874:INFO:Creating metrics dataframe
2023-02-28 01:53:51,874:INFO:Uploading results into container
2023-02-28 01:53:51,874:INFO:Uploading model into container now
2023-02-28 01:53:51,874:INFO:_master_model_container: 32
2023-02-28 01:53:51,874:INFO:_display_container: 22
2023-02-28 01:53:51,882:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-02-28 01:53:51,882:INFO:create_model() successfully completed......................................
2023-02-28 01:53:52,169:INFO:SubProcess create_model() end ==================================
2023-02-28 01:53:52,170:INFO:Creating metrics dataframe
2023-02-28 01:53:52,181:INFO:Initializing Extra Trees Regressor
2023-02-28 01:53:52,181:INFO:Total runtime is 0.29638728300730394 minutes
2023-02-28 01:53:52,186:INFO:SubProcess create_model() called ==================================
2023-02-28 01:53:52,186:INFO:Initializing create_model()
2023-02-28 01:53:52,186:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB088E4C40>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:53:52,186:INFO:Checking exceptions
2023-02-28 01:53:52,186:INFO:Importing libraries
2023-02-28 01:53:52,186:INFO:Copying training dataset
2023-02-28 01:53:52,189:INFO:Defining folds
2023-02-28 01:53:52,189:INFO:Declaring metric variables
2023-02-28 01:53:52,194:INFO:Importing untrained model
2023-02-28 01:53:52,198:INFO:Extra Trees Regressor Imported successfully
2023-02-28 01:53:52,205:INFO:Starting cross validation
2023-02-28 01:53:52,209:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:53:52,690:INFO:Calculating mean and std
2023-02-28 01:53:52,690:INFO:Creating metrics dataframe
2023-02-28 01:53:52,698:INFO:Uploading results into container
2023-02-28 01:53:52,698:INFO:Uploading model into container now
2023-02-28 01:53:52,698:INFO:_master_model_container: 33
2023-02-28 01:53:52,698:INFO:_display_container: 22
2023-02-28 01:53:52,698:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-02-28 01:53:52,698:INFO:create_model() successfully completed......................................
2023-02-28 01:53:52,981:INFO:SubProcess create_model() end ==================================
2023-02-28 01:53:52,981:INFO:Creating metrics dataframe
2023-02-28 01:53:52,988:INFO:Initializing AdaBoost Regressor
2023-02-28 01:53:52,988:INFO:Total runtime is 0.30984525680541997 minutes
2023-02-28 01:53:52,996:INFO:SubProcess create_model() called ==================================
2023-02-28 01:53:52,996:INFO:Initializing create_model()
2023-02-28 01:53:52,998:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB088E4C40>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:53:52,998:INFO:Checking exceptions
2023-02-28 01:53:52,998:INFO:Importing libraries
2023-02-28 01:53:52,998:INFO:Copying training dataset
2023-02-28 01:53:53,001:INFO:Defining folds
2023-02-28 01:53:53,001:INFO:Declaring metric variables
2023-02-28 01:53:53,009:INFO:Importing untrained model
2023-02-28 01:53:53,010:INFO:AdaBoost Regressor Imported successfully
2023-02-28 01:53:53,017:INFO:Starting cross validation
2023-02-28 01:53:53,021:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:53:53,383:INFO:Calculating mean and std
2023-02-28 01:53:53,383:INFO:Creating metrics dataframe
2023-02-28 01:53:53,383:INFO:Uploading results into container
2023-02-28 01:53:53,391:INFO:Uploading model into container now
2023-02-28 01:53:53,391:INFO:_master_model_container: 34
2023-02-28 01:53:53,391:INFO:_display_container: 22
2023-02-28 01:53:53,391:INFO:AdaBoostRegressor(random_state=123)
2023-02-28 01:53:53,391:INFO:create_model() successfully completed......................................
2023-02-28 01:53:53,671:INFO:SubProcess create_model() end ==================================
2023-02-28 01:53:53,671:INFO:Creating metrics dataframe
2023-02-28 01:53:53,685:INFO:Initializing Gradient Boosting Regressor
2023-02-28 01:53:53,685:INFO:Total runtime is 0.3214511235555014 minutes
2023-02-28 01:53:53,689:INFO:SubProcess create_model() called ==================================
2023-02-28 01:53:53,689:INFO:Initializing create_model()
2023-02-28 01:53:53,689:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB088E4C40>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:53:53,689:INFO:Checking exceptions
2023-02-28 01:53:53,689:INFO:Importing libraries
2023-02-28 01:53:53,689:INFO:Copying training dataset
2023-02-28 01:53:53,693:INFO:Defining folds
2023-02-28 01:53:53,693:INFO:Declaring metric variables
2023-02-28 01:53:53,697:INFO:Importing untrained model
2023-02-28 01:53:53,700:INFO:Gradient Boosting Regressor Imported successfully
2023-02-28 01:53:53,714:INFO:Starting cross validation
2023-02-28 01:53:53,714:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:53:54,131:INFO:Calculating mean and std
2023-02-28 01:53:54,131:INFO:Creating metrics dataframe
2023-02-28 01:53:54,139:INFO:Uploading results into container
2023-02-28 01:53:54,139:INFO:Uploading model into container now
2023-02-28 01:53:54,139:INFO:_master_model_container: 35
2023-02-28 01:53:54,139:INFO:_display_container: 22
2023-02-28 01:53:54,139:INFO:GradientBoostingRegressor(random_state=123)
2023-02-28 01:53:54,139:INFO:create_model() successfully completed......................................
2023-02-28 01:53:54,413:INFO:SubProcess create_model() end ==================================
2023-02-28 01:53:54,413:INFO:Creating metrics dataframe
2023-02-28 01:53:54,429:INFO:Initializing Extreme Gradient Boosting
2023-02-28 01:53:54,429:INFO:Total runtime is 0.33385301828384406 minutes
2023-02-28 01:53:54,436:INFO:SubProcess create_model() called ==================================
2023-02-28 01:53:54,436:INFO:Initializing create_model()
2023-02-28 01:53:54,436:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB088E4C40>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:53:54,437:INFO:Checking exceptions
2023-02-28 01:53:54,437:INFO:Importing libraries
2023-02-28 01:53:54,437:INFO:Copying training dataset
2023-02-28 01:53:54,439:INFO:Defining folds
2023-02-28 01:53:54,439:INFO:Declaring metric variables
2023-02-28 01:53:54,446:INFO:Importing untrained model
2023-02-28 01:53:54,451:INFO:Extreme Gradient Boosting Imported successfully
2023-02-28 01:53:54,454:INFO:Starting cross validation
2023-02-28 01:53:54,460:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:53:54,906:INFO:Calculating mean and std
2023-02-28 01:53:54,906:INFO:Creating metrics dataframe
2023-02-28 01:53:54,914:INFO:Uploading results into container
2023-02-28 01:53:54,914:INFO:Uploading model into container now
2023-02-28 01:53:54,914:INFO:_master_model_container: 36
2023-02-28 01:53:54,914:INFO:_display_container: 22
2023-02-28 01:53:54,914:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=123, ...)
2023-02-28 01:53:54,914:INFO:create_model() successfully completed......................................
2023-02-28 01:53:55,196:INFO:SubProcess create_model() end ==================================
2023-02-28 01:53:55,196:INFO:Creating metrics dataframe
2023-02-28 01:53:55,212:INFO:Initializing Light Gradient Boosting Machine
2023-02-28 01:53:55,212:INFO:Total runtime is 0.3469070196151734 minutes
2023-02-28 01:53:55,212:INFO:SubProcess create_model() called ==================================
2023-02-28 01:53:55,212:INFO:Initializing create_model()
2023-02-28 01:53:55,212:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB088E4C40>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:53:55,217:INFO:Checking exceptions
2023-02-28 01:53:55,217:INFO:Importing libraries
2023-02-28 01:53:55,217:INFO:Copying training dataset
2023-02-28 01:53:55,221:INFO:Defining folds
2023-02-28 01:53:55,222:INFO:Declaring metric variables
2023-02-28 01:53:55,226:INFO:Importing untrained model
2023-02-28 01:53:55,229:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-28 01:53:55,237:INFO:Starting cross validation
2023-02-28 01:53:55,238:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:53:55,688:INFO:Calculating mean and std
2023-02-28 01:53:55,688:INFO:Creating metrics dataframe
2023-02-28 01:53:55,688:INFO:Uploading results into container
2023-02-28 01:53:55,688:INFO:Uploading model into container now
2023-02-28 01:53:55,688:INFO:_master_model_container: 37
2023-02-28 01:53:55,688:INFO:_display_container: 22
2023-02-28 01:53:55,688:INFO:LGBMRegressor(random_state=123)
2023-02-28 01:53:55,688:INFO:create_model() successfully completed......................................
2023-02-28 01:53:55,969:INFO:SubProcess create_model() end ==================================
2023-02-28 01:53:55,969:INFO:Creating metrics dataframe
2023-02-28 01:53:55,986:INFO:Initializing Dummy Regressor
2023-02-28 01:53:55,986:INFO:Total runtime is 0.3597978512446086 minutes
2023-02-28 01:53:55,988:INFO:SubProcess create_model() called ==================================
2023-02-28 01:53:55,988:INFO:Initializing create_model()
2023-02-28 01:53:55,988:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB088E4C40>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:53:55,988:INFO:Checking exceptions
2023-02-28 01:53:55,988:INFO:Importing libraries
2023-02-28 01:53:55,988:INFO:Copying training dataset
2023-02-28 01:53:55,994:INFO:Defining folds
2023-02-28 01:53:55,994:INFO:Declaring metric variables
2023-02-28 01:53:56,001:INFO:Importing untrained model
2023-02-28 01:53:56,005:INFO:Dummy Regressor Imported successfully
2023-02-28 01:53:56,011:INFO:Starting cross validation
2023-02-28 01:53:56,015:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:53:56,356:INFO:Calculating mean and std
2023-02-28 01:53:56,356:INFO:Creating metrics dataframe
2023-02-28 01:53:56,356:INFO:Uploading results into container
2023-02-28 01:53:56,356:INFO:Uploading model into container now
2023-02-28 01:53:56,356:INFO:_master_model_container: 38
2023-02-28 01:53:56,356:INFO:_display_container: 22
2023-02-28 01:53:56,356:INFO:DummyRegressor()
2023-02-28 01:53:56,356:INFO:create_model() successfully completed......................................
2023-02-28 01:53:56,638:INFO:SubProcess create_model() end ==================================
2023-02-28 01:53:56,638:INFO:Creating metrics dataframe
2023-02-28 01:53:56,663:INFO:Initializing create_model()
2023-02-28 01:53:56,663:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:53:56,663:INFO:Checking exceptions
2023-02-28 01:53:56,665:INFO:Importing libraries
2023-02-28 01:53:56,665:INFO:Copying training dataset
2023-02-28 01:53:56,667:INFO:Defining folds
2023-02-28 01:53:56,667:INFO:Declaring metric variables
2023-02-28 01:53:56,667:INFO:Importing untrained model
2023-02-28 01:53:56,667:INFO:Declaring custom model
2023-02-28 01:53:56,669:INFO:Gradient Boosting Regressor Imported successfully
2023-02-28 01:53:56,669:INFO:Cross validation set to False
2023-02-28 01:53:56,669:INFO:Fitting Model
2023-02-28 01:53:56,840:INFO:GradientBoostingRegressor(random_state=123)
2023-02-28 01:53:56,840:INFO:create_model() successfully completed......................................
2023-02-28 01:53:57,151:INFO:Initializing create_model()
2023-02-28 01:53:57,151:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:53:57,151:INFO:Checking exceptions
2023-02-28 01:53:57,151:INFO:Importing libraries
2023-02-28 01:53:57,151:INFO:Copying training dataset
2023-02-28 01:53:57,157:INFO:Defining folds
2023-02-28 01:53:57,157:INFO:Declaring metric variables
2023-02-28 01:53:57,157:INFO:Importing untrained model
2023-02-28 01:53:57,157:INFO:Declaring custom model
2023-02-28 01:53:57,157:INFO:Random Forest Regressor Imported successfully
2023-02-28 01:53:57,157:INFO:Cross validation set to False
2023-02-28 01:53:57,157:INFO:Fitting Model
2023-02-28 01:53:57,286:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-02-28 01:53:57,286:INFO:create_model() successfully completed......................................
2023-02-28 01:53:57,571:INFO:Initializing create_model()
2023-02-28 01:53:57,574:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=LGBMRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:53:57,574:INFO:Checking exceptions
2023-02-28 01:53:57,576:INFO:Importing libraries
2023-02-28 01:53:57,576:INFO:Copying training dataset
2023-02-28 01:53:57,579:INFO:Defining folds
2023-02-28 01:53:57,579:INFO:Declaring metric variables
2023-02-28 01:53:57,579:INFO:Importing untrained model
2023-02-28 01:53:57,579:INFO:Declaring custom model
2023-02-28 01:53:57,579:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-28 01:53:57,579:INFO:Cross validation set to False
2023-02-28 01:53:57,579:INFO:Fitting Model
2023-02-28 01:53:57,670:INFO:LGBMRegressor(random_state=123)
2023-02-28 01:53:57,670:INFO:create_model() successfully completed......................................
2023-02-28 01:53:57,970:INFO:Initializing create_model()
2023-02-28 01:53:57,970:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:53:57,970:INFO:Checking exceptions
2023-02-28 01:53:57,978:INFO:Importing libraries
2023-02-28 01:53:57,978:INFO:Copying training dataset
2023-02-28 01:53:57,978:INFO:Defining folds
2023-02-28 01:53:57,978:INFO:Declaring metric variables
2023-02-28 01:53:57,978:INFO:Importing untrained model
2023-02-28 01:53:57,978:INFO:Declaring custom model
2023-02-28 01:53:57,978:INFO:Extra Trees Regressor Imported successfully
2023-02-28 01:53:57,978:INFO:Cross validation set to False
2023-02-28 01:53:57,978:INFO:Fitting Model
2023-02-28 01:53:58,109:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-02-28 01:53:58,109:INFO:create_model() successfully completed......................................
2023-02-28 01:53:58,386:INFO:Initializing create_model()
2023-02-28 01:53:58,394:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=AdaBoostRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:53:58,394:INFO:Checking exceptions
2023-02-28 01:53:58,396:INFO:Importing libraries
2023-02-28 01:53:58,396:INFO:Copying training dataset
2023-02-28 01:53:58,396:INFO:Defining folds
2023-02-28 01:53:58,396:INFO:Declaring metric variables
2023-02-28 01:53:58,396:INFO:Importing untrained model
2023-02-28 01:53:58,396:INFO:Declaring custom model
2023-02-28 01:53:58,396:INFO:str Imported successfully
2023-02-28 01:53:58,401:INFO:Cross validation set to False
2023-02-28 01:53:58,401:INFO:Fitting Model
2023-02-28 01:53:58,491:INFO:AdaBoostRegressor(random_state=123)
2023-02-28 01:53:58,491:INFO:create_model() successfully completed......................................
2023-02-28 01:53:58,818:INFO:_master_model_container: 38
2023-02-28 01:53:58,818:INFO:_display_container: 22
2023-02-28 01:53:58,822:INFO:[GradientBoostingRegressor(random_state=123), RandomForestRegressor(n_jobs=-1, random_state=123), LGBMRegressor(random_state=123), ExtraTreesRegressor(n_jobs=-1, random_state=123), AdaBoostRegressor(random_state=123)]
2023-02-28 01:53:58,822:INFO:compare_models() successfully completed......................................
2023-02-28 01:59:29,608:INFO:Initializing create_model()
2023-02-28 01:59:29,608:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=huber, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 01:59:29,608:INFO:Checking exceptions
2023-02-28 01:59:29,623:INFO:Importing libraries
2023-02-28 01:59:29,629:INFO:Copying training dataset
2023-02-28 01:59:29,636:INFO:Defining folds
2023-02-28 01:59:29,636:INFO:Declaring metric variables
2023-02-28 01:59:29,639:INFO:Importing untrained model
2023-02-28 01:59:29,646:INFO:Huber Regressor Imported successfully
2023-02-28 01:59:29,658:INFO:Starting cross validation
2023-02-28 01:59:29,663:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 01:59:29,894:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:59:30,251:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:59:30,552:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:59:30,857:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:59:31,193:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:59:31,536:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:59:34,095:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:59:34,095:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:59:34,100:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:59:34,112:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 01:59:34,183:INFO:Calculating mean and std
2023-02-28 01:59:34,183:INFO:Creating metrics dataframe
2023-02-28 01:59:34,194:INFO:Finalizing model
2023-02-28 01:59:34,312:INFO:Uploading results into container
2023-02-28 01:59:34,317:INFO:Uploading model into container now
2023-02-28 01:59:34,322:INFO:_master_model_container: 39
2023-02-28 01:59:34,322:INFO:_display_container: 23
2023-02-28 01:59:34,327:INFO:HuberRegressor()
2023-02-28 01:59:34,327:INFO:create_model() successfully completed......................................
2023-02-28 02:02:34,742:INFO:Initializing compare_models()
2023-02-28 02:02:34,742:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-02-28 02:02:34,742:INFO:Checking exceptions
2023-02-28 02:02:34,751:INFO:Preparing display monitor
2023-02-28 02:02:34,785:INFO:Initializing Linear Regression
2023-02-28 02:02:34,785:INFO:Total runtime is 0.0 minutes
2023-02-28 02:02:34,793:INFO:SubProcess create_model() called ==================================
2023-02-28 02:02:34,793:INFO:Initializing create_model()
2023-02-28 02:02:34,793:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB07B354C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:02:34,793:INFO:Checking exceptions
2023-02-28 02:02:34,793:INFO:Importing libraries
2023-02-28 02:02:34,793:INFO:Copying training dataset
2023-02-28 02:02:34,800:INFO:Defining folds
2023-02-28 02:02:34,800:INFO:Declaring metric variables
2023-02-28 02:02:34,800:INFO:Importing untrained model
2023-02-28 02:02:34,808:INFO:Linear Regression Imported successfully
2023-02-28 02:02:34,819:INFO:Starting cross validation
2023-02-28 02:02:34,824:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:02:38,373:INFO:Calculating mean and std
2023-02-28 02:02:38,373:INFO:Creating metrics dataframe
2023-02-28 02:02:38,373:INFO:Uploading results into container
2023-02-28 02:02:38,381:INFO:Uploading model into container now
2023-02-28 02:02:38,381:INFO:_master_model_container: 40
2023-02-28 02:02:38,381:INFO:_display_container: 24
2023-02-28 02:02:38,383:INFO:LinearRegression(n_jobs=-1)
2023-02-28 02:02:38,383:INFO:create_model() successfully completed......................................
2023-02-28 02:02:38,691:INFO:SubProcess create_model() end ==================================
2023-02-28 02:02:38,691:INFO:Creating metrics dataframe
2023-02-28 02:02:38,697:INFO:Initializing Lasso Regression
2023-02-28 02:02:38,697:INFO:Total runtime is 0.06519733667373658 minutes
2023-02-28 02:02:38,706:INFO:SubProcess create_model() called ==================================
2023-02-28 02:02:38,706:INFO:Initializing create_model()
2023-02-28 02:02:38,706:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB07B354C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:02:38,706:INFO:Checking exceptions
2023-02-28 02:02:38,706:INFO:Importing libraries
2023-02-28 02:02:38,706:INFO:Copying training dataset
2023-02-28 02:02:38,708:INFO:Defining folds
2023-02-28 02:02:38,708:INFO:Declaring metric variables
2023-02-28 02:02:38,713:INFO:Importing untrained model
2023-02-28 02:02:38,718:INFO:Lasso Regression Imported successfully
2023-02-28 02:02:38,721:INFO:Starting cross validation
2023-02-28 02:02:38,731:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:02:41,283:INFO:Calculating mean and std
2023-02-28 02:02:41,283:INFO:Creating metrics dataframe
2023-02-28 02:02:41,292:INFO:Uploading results into container
2023-02-28 02:02:41,292:INFO:Uploading model into container now
2023-02-28 02:02:41,292:INFO:_master_model_container: 41
2023-02-28 02:02:41,292:INFO:_display_container: 24
2023-02-28 02:02:41,292:INFO:Lasso(random_state=123)
2023-02-28 02:02:41,292:INFO:create_model() successfully completed......................................
2023-02-28 02:02:41,659:INFO:SubProcess create_model() end ==================================
2023-02-28 02:02:41,659:INFO:Creating metrics dataframe
2023-02-28 02:02:41,672:INFO:Initializing Ridge Regression
2023-02-28 02:02:41,672:INFO:Total runtime is 0.1147841731707255 minutes
2023-02-28 02:02:41,673:INFO:SubProcess create_model() called ==================================
2023-02-28 02:02:41,673:INFO:Initializing create_model()
2023-02-28 02:02:41,673:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB07B354C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:02:41,673:INFO:Checking exceptions
2023-02-28 02:02:41,673:INFO:Importing libraries
2023-02-28 02:02:41,673:INFO:Copying training dataset
2023-02-28 02:02:41,680:INFO:Defining folds
2023-02-28 02:02:41,680:INFO:Declaring metric variables
2023-02-28 02:02:41,680:INFO:Importing untrained model
2023-02-28 02:02:41,691:INFO:Ridge Regression Imported successfully
2023-02-28 02:02:41,696:INFO:Starting cross validation
2023-02-28 02:02:41,700:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:02:42,043:INFO:Calculating mean and std
2023-02-28 02:02:42,043:INFO:Creating metrics dataframe
2023-02-28 02:02:42,051:INFO:Uploading results into container
2023-02-28 02:02:42,051:INFO:Uploading model into container now
2023-02-28 02:02:42,051:INFO:_master_model_container: 42
2023-02-28 02:02:42,051:INFO:_display_container: 24
2023-02-28 02:02:42,051:INFO:Ridge(random_state=123)
2023-02-28 02:02:42,051:INFO:create_model() successfully completed......................................
2023-02-28 02:02:42,406:INFO:SubProcess create_model() end ==================================
2023-02-28 02:02:42,406:INFO:Creating metrics dataframe
2023-02-28 02:02:42,422:INFO:Initializing Elastic Net
2023-02-28 02:02:42,422:INFO:Total runtime is 0.12728944619496663 minutes
2023-02-28 02:02:42,422:INFO:SubProcess create_model() called ==================================
2023-02-28 02:02:42,422:INFO:Initializing create_model()
2023-02-28 02:02:42,422:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB07B354C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:02:42,422:INFO:Checking exceptions
2023-02-28 02:02:42,422:INFO:Importing libraries
2023-02-28 02:02:42,422:INFO:Copying training dataset
2023-02-28 02:02:42,432:INFO:Defining folds
2023-02-28 02:02:42,432:INFO:Declaring metric variables
2023-02-28 02:02:42,432:INFO:Importing untrained model
2023-02-28 02:02:42,439:INFO:Elastic Net Imported successfully
2023-02-28 02:02:42,447:INFO:Starting cross validation
2023-02-28 02:02:42,450:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:02:42,811:INFO:Calculating mean and std
2023-02-28 02:02:42,816:INFO:Creating metrics dataframe
2023-02-28 02:02:42,819:INFO:Uploading results into container
2023-02-28 02:02:42,819:INFO:Uploading model into container now
2023-02-28 02:02:42,819:INFO:_master_model_container: 43
2023-02-28 02:02:42,819:INFO:_display_container: 24
2023-02-28 02:02:42,819:INFO:ElasticNet(random_state=123)
2023-02-28 02:02:42,819:INFO:create_model() successfully completed......................................
2023-02-28 02:02:43,142:INFO:SubProcess create_model() end ==================================
2023-02-28 02:02:43,142:INFO:Creating metrics dataframe
2023-02-28 02:02:43,162:INFO:Initializing Least Angle Regression
2023-02-28 02:02:43,162:INFO:Total runtime is 0.13961749871571857 minutes
2023-02-28 02:02:43,167:INFO:SubProcess create_model() called ==================================
2023-02-28 02:02:43,167:INFO:Initializing create_model()
2023-02-28 02:02:43,167:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB07B354C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:02:43,167:INFO:Checking exceptions
2023-02-28 02:02:43,167:INFO:Importing libraries
2023-02-28 02:02:43,167:INFO:Copying training dataset
2023-02-28 02:02:43,172:INFO:Defining folds
2023-02-28 02:02:43,172:INFO:Declaring metric variables
2023-02-28 02:02:43,176:INFO:Importing untrained model
2023-02-28 02:02:43,182:INFO:Least Angle Regression Imported successfully
2023-02-28 02:02:43,191:INFO:Starting cross validation
2023-02-28 02:02:43,194:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:02:43,554:INFO:Calculating mean and std
2023-02-28 02:02:43,555:INFO:Creating metrics dataframe
2023-02-28 02:02:43,555:INFO:Uploading results into container
2023-02-28 02:02:43,555:INFO:Uploading model into container now
2023-02-28 02:02:43,555:INFO:_master_model_container: 44
2023-02-28 02:02:43,555:INFO:_display_container: 24
2023-02-28 02:02:43,555:INFO:Lars(random_state=123)
2023-02-28 02:02:43,555:INFO:create_model() successfully completed......................................
2023-02-28 02:02:43,863:INFO:SubProcess create_model() end ==================================
2023-02-28 02:02:43,863:INFO:Creating metrics dataframe
2023-02-28 02:02:43,879:INFO:Initializing Lasso Least Angle Regression
2023-02-28 02:02:43,879:INFO:Total runtime is 0.15156642993291217 minutes
2023-02-28 02:02:43,887:INFO:SubProcess create_model() called ==================================
2023-02-28 02:02:43,887:INFO:Initializing create_model()
2023-02-28 02:02:43,887:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB07B354C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:02:43,887:INFO:Checking exceptions
2023-02-28 02:02:43,887:INFO:Importing libraries
2023-02-28 02:02:43,887:INFO:Copying training dataset
2023-02-28 02:02:43,896:INFO:Defining folds
2023-02-28 02:02:43,896:INFO:Declaring metric variables
2023-02-28 02:02:43,902:INFO:Importing untrained model
2023-02-28 02:02:43,909:INFO:Lasso Least Angle Regression Imported successfully
2023-02-28 02:02:43,912:INFO:Starting cross validation
2023-02-28 02:02:43,917:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:02:44,283:INFO:Calculating mean and std
2023-02-28 02:02:44,283:INFO:Creating metrics dataframe
2023-02-28 02:02:44,291:INFO:Uploading results into container
2023-02-28 02:02:44,291:INFO:Uploading model into container now
2023-02-28 02:02:44,291:INFO:_master_model_container: 45
2023-02-28 02:02:44,291:INFO:_display_container: 24
2023-02-28 02:02:44,291:INFO:LassoLars(random_state=123)
2023-02-28 02:02:44,291:INFO:create_model() successfully completed......................................
2023-02-28 02:02:44,591:INFO:SubProcess create_model() end ==================================
2023-02-28 02:02:44,591:INFO:Creating metrics dataframe
2023-02-28 02:02:44,606:INFO:Initializing Orthogonal Matching Pursuit
2023-02-28 02:02:44,606:INFO:Total runtime is 0.16368198792139688 minutes
2023-02-28 02:02:44,610:INFO:SubProcess create_model() called ==================================
2023-02-28 02:02:44,610:INFO:Initializing create_model()
2023-02-28 02:02:44,610:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB07B354C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:02:44,610:INFO:Checking exceptions
2023-02-28 02:02:44,610:INFO:Importing libraries
2023-02-28 02:02:44,610:INFO:Copying training dataset
2023-02-28 02:02:44,615:INFO:Defining folds
2023-02-28 02:02:44,615:INFO:Declaring metric variables
2023-02-28 02:02:44,619:INFO:Importing untrained model
2023-02-28 02:02:44,623:INFO:Orthogonal Matching Pursuit Imported successfully
2023-02-28 02:02:44,625:INFO:Starting cross validation
2023-02-28 02:02:44,632:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:02:44,956:INFO:Calculating mean and std
2023-02-28 02:02:44,956:INFO:Creating metrics dataframe
2023-02-28 02:02:44,956:INFO:Uploading results into container
2023-02-28 02:02:44,964:INFO:Uploading model into container now
2023-02-28 02:02:44,964:INFO:_master_model_container: 46
2023-02-28 02:02:44,964:INFO:_display_container: 24
2023-02-28 02:02:44,964:INFO:OrthogonalMatchingPursuit()
2023-02-28 02:02:44,964:INFO:create_model() successfully completed......................................
2023-02-28 02:02:45,275:INFO:SubProcess create_model() end ==================================
2023-02-28 02:02:45,275:INFO:Creating metrics dataframe
2023-02-28 02:02:45,290:INFO:Initializing Bayesian Ridge
2023-02-28 02:02:45,292:INFO:Total runtime is 0.17511038382848101 minutes
2023-02-28 02:02:45,292:INFO:SubProcess create_model() called ==================================
2023-02-28 02:02:45,292:INFO:Initializing create_model()
2023-02-28 02:02:45,292:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB07B354C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:02:45,292:INFO:Checking exceptions
2023-02-28 02:02:45,292:INFO:Importing libraries
2023-02-28 02:02:45,292:INFO:Copying training dataset
2023-02-28 02:02:45,300:INFO:Defining folds
2023-02-28 02:02:45,300:INFO:Declaring metric variables
2023-02-28 02:02:45,300:INFO:Importing untrained model
2023-02-28 02:02:45,309:INFO:Bayesian Ridge Imported successfully
2023-02-28 02:02:45,316:INFO:Starting cross validation
2023-02-28 02:02:45,317:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:02:45,620:INFO:Calculating mean and std
2023-02-28 02:02:45,620:INFO:Creating metrics dataframe
2023-02-28 02:02:45,625:INFO:Uploading results into container
2023-02-28 02:02:45,625:INFO:Uploading model into container now
2023-02-28 02:02:45,625:INFO:_master_model_container: 47
2023-02-28 02:02:45,625:INFO:_display_container: 24
2023-02-28 02:02:45,625:INFO:BayesianRidge()
2023-02-28 02:02:45,625:INFO:create_model() successfully completed......................................
2023-02-28 02:02:45,925:INFO:SubProcess create_model() end ==================================
2023-02-28 02:02:45,925:INFO:Creating metrics dataframe
2023-02-28 02:02:45,942:INFO:Initializing Passive Aggressive Regressor
2023-02-28 02:02:45,942:INFO:Total runtime is 0.18594308694203693 minutes
2023-02-28 02:02:45,950:INFO:SubProcess create_model() called ==================================
2023-02-28 02:02:45,950:INFO:Initializing create_model()
2023-02-28 02:02:45,950:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB07B354C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:02:45,950:INFO:Checking exceptions
2023-02-28 02:02:45,950:INFO:Importing libraries
2023-02-28 02:02:45,950:INFO:Copying training dataset
2023-02-28 02:02:45,951:INFO:Defining folds
2023-02-28 02:02:45,951:INFO:Declaring metric variables
2023-02-28 02:02:45,958:INFO:Importing untrained model
2023-02-28 02:02:45,958:INFO:Passive Aggressive Regressor Imported successfully
2023-02-28 02:02:45,967:INFO:Starting cross validation
2023-02-28 02:02:45,972:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:02:46,313:INFO:Calculating mean and std
2023-02-28 02:02:46,313:INFO:Creating metrics dataframe
2023-02-28 02:02:46,313:INFO:Uploading results into container
2023-02-28 02:02:46,313:INFO:Uploading model into container now
2023-02-28 02:02:46,313:INFO:_master_model_container: 48
2023-02-28 02:02:46,313:INFO:_display_container: 24
2023-02-28 02:02:46,313:INFO:PassiveAggressiveRegressor(random_state=123)
2023-02-28 02:02:46,313:INFO:create_model() successfully completed......................................
2023-02-28 02:02:46,620:INFO:SubProcess create_model() end ==================================
2023-02-28 02:02:46,620:INFO:Creating metrics dataframe
2023-02-28 02:02:46,632:INFO:Initializing Huber Regressor
2023-02-28 02:02:46,632:INFO:Total runtime is 0.19744783639907834 minutes
2023-02-28 02:02:46,640:INFO:SubProcess create_model() called ==================================
2023-02-28 02:02:46,640:INFO:Initializing create_model()
2023-02-28 02:02:46,640:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB07B354C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:02:46,640:INFO:Checking exceptions
2023-02-28 02:02:46,640:INFO:Importing libraries
2023-02-28 02:02:46,640:INFO:Copying training dataset
2023-02-28 02:02:46,640:INFO:Defining folds
2023-02-28 02:02:46,640:INFO:Declaring metric variables
2023-02-28 02:02:46,651:INFO:Importing untrained model
2023-02-28 02:02:46,656:INFO:Huber Regressor Imported successfully
2023-02-28 02:02:46,660:INFO:Starting cross validation
2023-02-28 02:02:46,664:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:02:46,861:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:02:46,872:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:02:46,878:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:02:46,902:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:02:46,912:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:02:46,919:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:02:46,935:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:02:46,943:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:02:46,959:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:02:47,015:INFO:Calculating mean and std
2023-02-28 02:02:47,015:INFO:Creating metrics dataframe
2023-02-28 02:02:47,023:INFO:Uploading results into container
2023-02-28 02:02:47,023:INFO:Uploading model into container now
2023-02-28 02:02:47,023:INFO:_master_model_container: 49
2023-02-28 02:02:47,023:INFO:_display_container: 24
2023-02-28 02:02:47,023:INFO:HuberRegressor()
2023-02-28 02:02:47,023:INFO:create_model() successfully completed......................................
2023-02-28 02:02:47,315:INFO:SubProcess create_model() end ==================================
2023-02-28 02:02:47,315:INFO:Creating metrics dataframe
2023-02-28 02:02:47,324:INFO:Initializing K Neighbors Regressor
2023-02-28 02:02:47,324:INFO:Total runtime is 0.20898732741673784 minutes
2023-02-28 02:02:47,331:INFO:SubProcess create_model() called ==================================
2023-02-28 02:02:47,331:INFO:Initializing create_model()
2023-02-28 02:02:47,331:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB07B354C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:02:47,331:INFO:Checking exceptions
2023-02-28 02:02:47,331:INFO:Importing libraries
2023-02-28 02:02:47,331:INFO:Copying training dataset
2023-02-28 02:02:47,339:INFO:Defining folds
2023-02-28 02:02:47,339:INFO:Declaring metric variables
2023-02-28 02:02:47,339:INFO:Importing untrained model
2023-02-28 02:02:47,339:INFO:K Neighbors Regressor Imported successfully
2023-02-28 02:02:47,347:INFO:Starting cross validation
2023-02-28 02:02:47,355:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:02:47,675:INFO:Calculating mean and std
2023-02-28 02:02:47,675:INFO:Creating metrics dataframe
2023-02-28 02:02:47,681:INFO:Uploading results into container
2023-02-28 02:02:47,681:INFO:Uploading model into container now
2023-02-28 02:02:47,681:INFO:_master_model_container: 50
2023-02-28 02:02:47,681:INFO:_display_container: 24
2023-02-28 02:02:47,681:INFO:KNeighborsRegressor(n_jobs=-1)
2023-02-28 02:02:47,681:INFO:create_model() successfully completed......................................
2023-02-28 02:02:47,973:INFO:SubProcess create_model() end ==================================
2023-02-28 02:02:47,973:INFO:Creating metrics dataframe
2023-02-28 02:02:47,980:INFO:Initializing Decision Tree Regressor
2023-02-28 02:02:47,980:INFO:Total runtime is 0.21991581916809078 minutes
2023-02-28 02:02:47,988:INFO:SubProcess create_model() called ==================================
2023-02-28 02:02:47,989:INFO:Initializing create_model()
2023-02-28 02:02:47,989:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB07B354C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:02:47,989:INFO:Checking exceptions
2023-02-28 02:02:47,989:INFO:Importing libraries
2023-02-28 02:02:47,989:INFO:Copying training dataset
2023-02-28 02:02:47,993:INFO:Defining folds
2023-02-28 02:02:47,993:INFO:Declaring metric variables
2023-02-28 02:02:47,996:INFO:Importing untrained model
2023-02-28 02:02:47,996:INFO:Decision Tree Regressor Imported successfully
2023-02-28 02:02:48,006:INFO:Starting cross validation
2023-02-28 02:02:48,006:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:02:48,326:INFO:Calculating mean and std
2023-02-28 02:02:48,326:INFO:Creating metrics dataframe
2023-02-28 02:02:48,334:INFO:Uploading results into container
2023-02-28 02:02:48,334:INFO:Uploading model into container now
2023-02-28 02:02:48,334:INFO:_master_model_container: 51
2023-02-28 02:02:48,334:INFO:_display_container: 24
2023-02-28 02:02:48,334:INFO:DecisionTreeRegressor(random_state=123)
2023-02-28 02:02:48,334:INFO:create_model() successfully completed......................................
2023-02-28 02:02:48,643:INFO:SubProcess create_model() end ==================================
2023-02-28 02:02:48,643:INFO:Creating metrics dataframe
2023-02-28 02:02:48,651:INFO:Initializing Random Forest Regressor
2023-02-28 02:02:48,651:INFO:Total runtime is 0.23110609849294023 minutes
2023-02-28 02:02:48,661:INFO:SubProcess create_model() called ==================================
2023-02-28 02:02:48,661:INFO:Initializing create_model()
2023-02-28 02:02:48,661:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB07B354C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:02:48,661:INFO:Checking exceptions
2023-02-28 02:02:48,661:INFO:Importing libraries
2023-02-28 02:02:48,661:INFO:Copying training dataset
2023-02-28 02:02:48,668:INFO:Defining folds
2023-02-28 02:02:48,668:INFO:Declaring metric variables
2023-02-28 02:02:48,676:INFO:Importing untrained model
2023-02-28 02:02:48,678:INFO:Random Forest Regressor Imported successfully
2023-02-28 02:02:48,692:INFO:Starting cross validation
2023-02-28 02:02:48,694:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:02:49,208:INFO:Calculating mean and std
2023-02-28 02:02:49,208:INFO:Creating metrics dataframe
2023-02-28 02:02:49,217:INFO:Uploading results into container
2023-02-28 02:02:49,217:INFO:Uploading model into container now
2023-02-28 02:02:49,217:INFO:_master_model_container: 52
2023-02-28 02:02:49,217:INFO:_display_container: 24
2023-02-28 02:02:49,220:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-02-28 02:02:49,220:INFO:create_model() successfully completed......................................
2023-02-28 02:02:49,542:INFO:SubProcess create_model() end ==================================
2023-02-28 02:02:49,542:INFO:Creating metrics dataframe
2023-02-28 02:02:49,562:INFO:Initializing Extra Trees Regressor
2023-02-28 02:02:49,562:INFO:Total runtime is 0.24628829558690385 minutes
2023-02-28 02:02:49,569:INFO:SubProcess create_model() called ==================================
2023-02-28 02:02:49,569:INFO:Initializing create_model()
2023-02-28 02:02:49,569:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB07B354C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:02:49,569:INFO:Checking exceptions
2023-02-28 02:02:49,569:INFO:Importing libraries
2023-02-28 02:02:49,569:INFO:Copying training dataset
2023-02-28 02:02:49,575:INFO:Defining folds
2023-02-28 02:02:49,575:INFO:Declaring metric variables
2023-02-28 02:02:49,581:INFO:Importing untrained model
2023-02-28 02:02:49,583:INFO:Extra Trees Regressor Imported successfully
2023-02-28 02:02:49,591:INFO:Starting cross validation
2023-02-28 02:02:49,591:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:02:50,072:INFO:Calculating mean and std
2023-02-28 02:02:50,072:INFO:Creating metrics dataframe
2023-02-28 02:02:50,075:INFO:Uploading results into container
2023-02-28 02:02:50,075:INFO:Uploading model into container now
2023-02-28 02:02:50,075:INFO:_master_model_container: 53
2023-02-28 02:02:50,075:INFO:_display_container: 24
2023-02-28 02:02:50,075:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-02-28 02:02:50,075:INFO:create_model() successfully completed......................................
2023-02-28 02:02:50,364:INFO:SubProcess create_model() end ==================================
2023-02-28 02:02:50,364:INFO:Creating metrics dataframe
2023-02-28 02:02:50,380:INFO:Initializing AdaBoost Regressor
2023-02-28 02:02:50,380:INFO:Total runtime is 0.25991638501485187 minutes
2023-02-28 02:02:50,380:INFO:SubProcess create_model() called ==================================
2023-02-28 02:02:50,385:INFO:Initializing create_model()
2023-02-28 02:02:50,385:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB07B354C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:02:50,385:INFO:Checking exceptions
2023-02-28 02:02:50,385:INFO:Importing libraries
2023-02-28 02:02:50,385:INFO:Copying training dataset
2023-02-28 02:02:50,388:INFO:Defining folds
2023-02-28 02:02:50,388:INFO:Declaring metric variables
2023-02-28 02:02:50,396:INFO:Importing untrained model
2023-02-28 02:02:50,399:INFO:AdaBoost Regressor Imported successfully
2023-02-28 02:02:50,406:INFO:Starting cross validation
2023-02-28 02:02:50,409:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:02:50,756:INFO:Calculating mean and std
2023-02-28 02:02:50,756:INFO:Creating metrics dataframe
2023-02-28 02:02:50,759:INFO:Uploading results into container
2023-02-28 02:02:50,759:INFO:Uploading model into container now
2023-02-28 02:02:50,759:INFO:_master_model_container: 54
2023-02-28 02:02:50,759:INFO:_display_container: 24
2023-02-28 02:02:50,759:INFO:AdaBoostRegressor(random_state=123)
2023-02-28 02:02:50,759:INFO:create_model() successfully completed......................................
2023-02-28 02:02:51,058:INFO:SubProcess create_model() end ==================================
2023-02-28 02:02:51,058:INFO:Creating metrics dataframe
2023-02-28 02:02:51,075:INFO:Initializing Gradient Boosting Regressor
2023-02-28 02:02:51,075:INFO:Total runtime is 0.27149500052134196 minutes
2023-02-28 02:02:51,083:INFO:SubProcess create_model() called ==================================
2023-02-28 02:02:51,083:INFO:Initializing create_model()
2023-02-28 02:02:51,083:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB07B354C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:02:51,083:INFO:Checking exceptions
2023-02-28 02:02:51,083:INFO:Importing libraries
2023-02-28 02:02:51,083:INFO:Copying training dataset
2023-02-28 02:02:51,089:INFO:Defining folds
2023-02-28 02:02:51,091:INFO:Declaring metric variables
2023-02-28 02:02:51,093:INFO:Importing untrained model
2023-02-28 02:02:51,099:INFO:Gradient Boosting Regressor Imported successfully
2023-02-28 02:02:51,107:INFO:Starting cross validation
2023-02-28 02:02:51,107:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:02:51,489:INFO:Calculating mean and std
2023-02-28 02:02:51,491:INFO:Creating metrics dataframe
2023-02-28 02:02:51,494:INFO:Uploading results into container
2023-02-28 02:02:51,494:INFO:Uploading model into container now
2023-02-28 02:02:51,496:INFO:_master_model_container: 55
2023-02-28 02:02:51,496:INFO:_display_container: 24
2023-02-28 02:02:51,496:INFO:GradientBoostingRegressor(random_state=123)
2023-02-28 02:02:51,496:INFO:create_model() successfully completed......................................
2023-02-28 02:02:51,794:INFO:SubProcess create_model() end ==================================
2023-02-28 02:02:51,794:INFO:Creating metrics dataframe
2023-02-28 02:02:51,810:INFO:Initializing Extreme Gradient Boosting
2023-02-28 02:02:51,810:INFO:Total runtime is 0.283752977848053 minutes
2023-02-28 02:02:51,817:INFO:SubProcess create_model() called ==================================
2023-02-28 02:02:51,817:INFO:Initializing create_model()
2023-02-28 02:02:51,818:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB07B354C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:02:51,818:INFO:Checking exceptions
2023-02-28 02:02:51,818:INFO:Importing libraries
2023-02-28 02:02:51,818:INFO:Copying training dataset
2023-02-28 02:02:51,820:INFO:Defining folds
2023-02-28 02:02:51,820:INFO:Declaring metric variables
2023-02-28 02:02:51,828:INFO:Importing untrained model
2023-02-28 02:02:51,830:INFO:Extreme Gradient Boosting Imported successfully
2023-02-28 02:02:51,843:INFO:Starting cross validation
2023-02-28 02:02:51,845:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:02:52,377:INFO:Calculating mean and std
2023-02-28 02:02:52,377:INFO:Creating metrics dataframe
2023-02-28 02:02:52,377:INFO:Uploading results into container
2023-02-28 02:02:52,377:INFO:Uploading model into container now
2023-02-28 02:02:52,377:INFO:_master_model_container: 56
2023-02-28 02:02:52,377:INFO:_display_container: 24
2023-02-28 02:02:52,385:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=123, ...)
2023-02-28 02:02:52,385:INFO:create_model() successfully completed......................................
2023-02-28 02:02:52,695:INFO:SubProcess create_model() end ==================================
2023-02-28 02:02:52,695:INFO:Creating metrics dataframe
2023-02-28 02:02:52,712:INFO:Initializing Light Gradient Boosting Machine
2023-02-28 02:02:52,712:INFO:Total runtime is 0.29877748489379885 minutes
2023-02-28 02:02:52,712:INFO:SubProcess create_model() called ==================================
2023-02-28 02:02:52,712:INFO:Initializing create_model()
2023-02-28 02:02:52,718:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB07B354C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:02:52,718:INFO:Checking exceptions
2023-02-28 02:02:52,718:INFO:Importing libraries
2023-02-28 02:02:52,718:INFO:Copying training dataset
2023-02-28 02:02:52,722:INFO:Defining folds
2023-02-28 02:02:52,723:INFO:Declaring metric variables
2023-02-28 02:02:52,726:INFO:Importing untrained model
2023-02-28 02:02:52,728:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-28 02:02:52,737:INFO:Starting cross validation
2023-02-28 02:02:52,737:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:02:53,135:INFO:Calculating mean and std
2023-02-28 02:02:53,138:INFO:Creating metrics dataframe
2023-02-28 02:02:53,138:INFO:Uploading results into container
2023-02-28 02:02:53,138:INFO:Uploading model into container now
2023-02-28 02:02:53,138:INFO:_master_model_container: 57
2023-02-28 02:02:53,144:INFO:_display_container: 24
2023-02-28 02:02:53,144:INFO:LGBMRegressor(random_state=123)
2023-02-28 02:02:53,144:INFO:create_model() successfully completed......................................
2023-02-28 02:02:53,426:INFO:SubProcess create_model() end ==================================
2023-02-28 02:02:53,428:INFO:Creating metrics dataframe
2023-02-28 02:02:53,441:INFO:Initializing Dummy Regressor
2023-02-28 02:02:53,441:INFO:Total runtime is 0.31094197829564413 minutes
2023-02-28 02:02:53,448:INFO:SubProcess create_model() called ==================================
2023-02-28 02:02:53,448:INFO:Initializing create_model()
2023-02-28 02:02:53,448:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB07B354C0>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:02:53,448:INFO:Checking exceptions
2023-02-28 02:02:53,448:INFO:Importing libraries
2023-02-28 02:02:53,448:INFO:Copying training dataset
2023-02-28 02:02:53,451:INFO:Defining folds
2023-02-28 02:02:53,453:INFO:Declaring metric variables
2023-02-28 02:02:53,456:INFO:Importing untrained model
2023-02-28 02:02:53,461:INFO:Dummy Regressor Imported successfully
2023-02-28 02:02:53,469:INFO:Starting cross validation
2023-02-28 02:02:53,469:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:02:53,834:INFO:Calculating mean and std
2023-02-28 02:02:53,834:INFO:Creating metrics dataframe
2023-02-28 02:02:53,834:INFO:Uploading results into container
2023-02-28 02:02:53,834:INFO:Uploading model into container now
2023-02-28 02:02:53,834:INFO:_master_model_container: 58
2023-02-28 02:02:53,834:INFO:_display_container: 24
2023-02-28 02:02:53,834:INFO:DummyRegressor()
2023-02-28 02:02:53,834:INFO:create_model() successfully completed......................................
2023-02-28 02:02:54,139:INFO:SubProcess create_model() end ==================================
2023-02-28 02:02:54,139:INFO:Creating metrics dataframe
2023-02-28 02:02:54,163:INFO:Initializing create_model()
2023-02-28 02:02:54,163:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:02:54,163:INFO:Checking exceptions
2023-02-28 02:02:54,165:INFO:Importing libraries
2023-02-28 02:02:54,165:INFO:Copying training dataset
2023-02-28 02:02:54,166:INFO:Defining folds
2023-02-28 02:02:54,166:INFO:Declaring metric variables
2023-02-28 02:02:54,166:INFO:Importing untrained model
2023-02-28 02:02:54,168:INFO:Declaring custom model
2023-02-28 02:02:54,168:INFO:Gradient Boosting Regressor Imported successfully
2023-02-28 02:02:54,168:INFO:Cross validation set to False
2023-02-28 02:02:54,168:INFO:Fitting Model
2023-02-28 02:02:54,345:INFO:GradientBoostingRegressor(random_state=123)
2023-02-28 02:02:54,345:INFO:create_model() successfully completed......................................
2023-02-28 02:02:54,658:INFO:Initializing create_model()
2023-02-28 02:02:54,658:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:02:54,658:INFO:Checking exceptions
2023-02-28 02:02:54,660:INFO:Importing libraries
2023-02-28 02:02:54,660:INFO:Copying training dataset
2023-02-28 02:02:54,665:INFO:Defining folds
2023-02-28 02:02:54,666:INFO:Declaring metric variables
2023-02-28 02:02:54,666:INFO:Importing untrained model
2023-02-28 02:02:54,666:INFO:Declaring custom model
2023-02-28 02:02:54,666:INFO:Random Forest Regressor Imported successfully
2023-02-28 02:02:54,667:INFO:Cross validation set to False
2023-02-28 02:02:54,667:INFO:Fitting Model
2023-02-28 02:02:54,791:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-02-28 02:02:54,791:INFO:create_model() successfully completed......................................
2023-02-28 02:02:55,092:INFO:Initializing create_model()
2023-02-28 02:02:55,092:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=LGBMRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:02:55,092:INFO:Checking exceptions
2023-02-28 02:02:55,096:INFO:Importing libraries
2023-02-28 02:02:55,096:INFO:Copying training dataset
2023-02-28 02:02:55,097:INFO:Defining folds
2023-02-28 02:02:55,097:INFO:Declaring metric variables
2023-02-28 02:02:55,097:INFO:Importing untrained model
2023-02-28 02:02:55,097:INFO:Declaring custom model
2023-02-28 02:02:55,097:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-28 02:02:55,097:INFO:Cross validation set to False
2023-02-28 02:02:55,097:INFO:Fitting Model
2023-02-28 02:02:55,186:INFO:LGBMRegressor(random_state=123)
2023-02-28 02:02:55,186:INFO:create_model() successfully completed......................................
2023-02-28 02:02:55,502:INFO:Initializing create_model()
2023-02-28 02:02:55,502:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:02:55,502:INFO:Checking exceptions
2023-02-28 02:02:55,503:INFO:Importing libraries
2023-02-28 02:02:55,503:INFO:Copying training dataset
2023-02-28 02:02:55,503:INFO:Defining folds
2023-02-28 02:02:55,503:INFO:Declaring metric variables
2023-02-28 02:02:55,503:INFO:Importing untrained model
2023-02-28 02:02:55,503:INFO:Declaring custom model
2023-02-28 02:02:55,503:INFO:Extra Trees Regressor Imported successfully
2023-02-28 02:02:55,503:INFO:Cross validation set to False
2023-02-28 02:02:55,503:INFO:Fitting Model
2023-02-28 02:02:55,648:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-02-28 02:02:55,648:INFO:create_model() successfully completed......................................
2023-02-28 02:02:55,954:INFO:Initializing create_model()
2023-02-28 02:02:55,954:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=AdaBoostRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:02:55,954:INFO:Checking exceptions
2023-02-28 02:02:55,954:INFO:Importing libraries
2023-02-28 02:02:55,957:INFO:Copying training dataset
2023-02-28 02:02:55,958:INFO:Defining folds
2023-02-28 02:02:55,960:INFO:Declaring metric variables
2023-02-28 02:02:55,960:INFO:Importing untrained model
2023-02-28 02:02:55,960:INFO:Declaring custom model
2023-02-28 02:02:55,960:INFO:str Imported successfully
2023-02-28 02:02:55,960:INFO:Cross validation set to False
2023-02-28 02:02:55,960:INFO:Fitting Model
2023-02-28 02:02:56,065:INFO:AdaBoostRegressor(random_state=123)
2023-02-28 02:02:56,065:INFO:create_model() successfully completed......................................
2023-02-28 02:02:56,425:INFO:_master_model_container: 58
2023-02-28 02:02:56,425:INFO:_display_container: 24
2023-02-28 02:02:56,425:INFO:[GradientBoostingRegressor(random_state=123), RandomForestRegressor(n_jobs=-1, random_state=123), LGBMRegressor(random_state=123), ExtraTreesRegressor(n_jobs=-1, random_state=123), AdaBoostRegressor(random_state=123)]
2023-02-28 02:02:56,425:INFO:compare_models() successfully completed......................................
2023-02-28 02:03:31,283:INFO:Initializing create_model()
2023-02-28 02:03:31,283:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=huber, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:03:31,283:INFO:Checking exceptions
2023-02-28 02:03:31,323:INFO:Importing libraries
2023-02-28 02:03:31,323:INFO:Copying training dataset
2023-02-28 02:03:31,331:INFO:Defining folds
2023-02-28 02:03:31,333:INFO:Declaring metric variables
2023-02-28 02:03:31,339:INFO:Importing untrained model
2023-02-28 02:03:31,339:INFO:Huber Regressor Imported successfully
2023-02-28 02:03:31,356:INFO:Starting cross validation
2023-02-28 02:03:31,356:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:03:31,622:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:03:31,630:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:03:31,646:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:03:31,662:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:03:31,670:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:03:31,694:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:03:31,726:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:03:31,734:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:03:31,738:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:03:31,751:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:03:31,807:INFO:Calculating mean and std
2023-02-28 02:03:31,815:INFO:Creating metrics dataframe
2023-02-28 02:03:31,815:INFO:Finalizing model
2023-02-28 02:03:31,953:INFO:Uploading results into container
2023-02-28 02:03:31,953:INFO:Uploading model into container now
2023-02-28 02:03:31,967:INFO:_master_model_container: 59
2023-02-28 02:03:31,967:INFO:_display_container: 25
2023-02-28 02:03:31,967:INFO:HuberRegressor()
2023-02-28 02:03:31,967:INFO:create_model() successfully completed......................................
2023-02-28 02:07:08,318:INFO:Initializing ensemble_model()
2023-02-28 02:07:08,320:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=GradientBoostingRegressor(random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-02-28 02:07:08,320:INFO:Checking exceptions
2023-02-28 02:07:08,355:INFO:Importing libraries
2023-02-28 02:07:08,355:INFO:Copying training dataset
2023-02-28 02:07:08,355:INFO:Checking base model
2023-02-28 02:07:08,355:INFO:Base model : Gradient Boosting Regressor
2023-02-28 02:07:08,367:INFO:Importing untrained ensembler
2023-02-28 02:07:08,367:INFO:Ensemble method set to Bagging
2023-02-28 02:07:08,367:INFO:SubProcess create_model() called ==================================
2023-02-28 02:07:08,369:INFO:Initializing create_model()
2023-02-28 02:07:08,369:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB05124610>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:07:08,369:INFO:Checking exceptions
2023-02-28 02:07:08,369:INFO:Importing libraries
2023-02-28 02:07:08,369:INFO:Copying training dataset
2023-02-28 02:07:08,369:INFO:Defining folds
2023-02-28 02:07:08,369:INFO:Declaring metric variables
2023-02-28 02:07:08,377:INFO:Importing untrained model
2023-02-28 02:07:08,377:INFO:Declaring custom model
2023-02-28 02:07:08,387:INFO:str Imported successfully
2023-02-28 02:07:08,400:INFO:Starting cross validation
2023-02-28 02:07:08,404:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:07:10,321:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-28 02:07:10,321:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-28 02:07:10,336:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-28 02:07:10,344:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-28 02:07:10,352:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-28 02:07:10,400:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-28 02:07:10,943:INFO:Calculating mean and std
2023-02-28 02:07:10,948:INFO:Creating metrics dataframe
2023-02-28 02:07:10,955:INFO:Finalizing model
2023-02-28 02:07:12,271:INFO:Uploading results into container
2023-02-28 02:07:12,274:INFO:Uploading model into container now
2023-02-28 02:07:12,274:INFO:_master_model_container: 60
2023-02-28 02:07:12,274:INFO:_display_container: 26
2023-02-28 02:07:12,274:INFO:BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                 random_state=123)
2023-02-28 02:07:12,274:INFO:create_model() successfully completed......................................
2023-02-28 02:07:12,585:INFO:SubProcess create_model() end ==================================
2023-02-28 02:07:12,599:INFO:_master_model_container: 60
2023-02-28 02:07:12,599:INFO:_display_container: 26
2023-02-28 02:07:12,600:INFO:BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                 random_state=123)
2023-02-28 02:07:12,600:INFO:ensemble_model() successfully completed......................................
2023-02-28 02:07:27,380:INFO:Initializing ensemble_model()
2023-02-28 02:07:27,386:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=GradientBoostingRegressor(random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=True, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-02-28 02:07:27,386:INFO:Checking exceptions
2023-02-28 02:07:27,406:INFO:Importing libraries
2023-02-28 02:07:27,406:INFO:Copying training dataset
2023-02-28 02:07:27,410:INFO:Checking base model
2023-02-28 02:07:27,410:INFO:Base model : Gradient Boosting Regressor
2023-02-28 02:07:27,418:INFO:Importing untrained ensembler
2023-02-28 02:07:27,418:INFO:Ensemble method set to Bagging
2023-02-28 02:07:27,418:INFO:SubProcess create_model() called ==================================
2023-02-28 02:07:27,418:INFO:Initializing create_model()
2023-02-28 02:07:27,418:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB07986DC0>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:07:27,418:INFO:Checking exceptions
2023-02-28 02:07:27,418:INFO:Importing libraries
2023-02-28 02:07:27,418:INFO:Copying training dataset
2023-02-28 02:07:27,418:INFO:Defining folds
2023-02-28 02:07:27,418:INFO:Declaring metric variables
2023-02-28 02:07:27,426:INFO:Importing untrained model
2023-02-28 02:07:27,426:INFO:Declaring custom model
2023-02-28 02:07:27,434:INFO:str Imported successfully
2023-02-28 02:07:27,438:INFO:Starting cross validation
2023-02-28 02:07:27,443:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:07:28,384:INFO:Calculating mean and std
2023-02-28 02:07:28,384:INFO:Creating metrics dataframe
2023-02-28 02:07:28,394:INFO:Finalizing model
2023-02-28 02:07:28,554:INFO:Uploading results into container
2023-02-28 02:07:28,554:INFO:Uploading model into container now
2023-02-28 02:07:28,554:INFO:_master_model_container: 61
2023-02-28 02:07:28,554:INFO:_display_container: 27
2023-02-28 02:07:28,554:INFO:BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                 random_state=123)
2023-02-28 02:07:28,554:INFO:create_model() successfully completed......................................
2023-02-28 02:07:28,894:INFO:SubProcess create_model() end ==================================
2023-02-28 02:07:28,894:INFO:choose_better activated
2023-02-28 02:07:28,898:INFO:SubProcess create_model() called ==================================
2023-02-28 02:07:28,898:INFO:Initializing create_model()
2023-02-28 02:07:28,901:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:07:28,901:INFO:Checking exceptions
2023-02-28 02:07:28,901:INFO:Importing libraries
2023-02-28 02:07:28,901:INFO:Copying training dataset
2023-02-28 02:07:28,906:INFO:Defining folds
2023-02-28 02:07:28,906:INFO:Declaring metric variables
2023-02-28 02:07:28,906:INFO:Importing untrained model
2023-02-28 02:07:28,906:INFO:Declaring custom model
2023-02-28 02:07:28,906:INFO:Gradient Boosting Regressor Imported successfully
2023-02-28 02:07:28,906:INFO:Starting cross validation
2023-02-28 02:07:28,906:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:07:29,341:INFO:Calculating mean and std
2023-02-28 02:07:29,341:INFO:Creating metrics dataframe
2023-02-28 02:07:29,341:INFO:Finalizing model
2023-02-28 02:07:29,520:INFO:Uploading results into container
2023-02-28 02:07:29,520:INFO:Uploading model into container now
2023-02-28 02:07:29,520:INFO:_master_model_container: 62
2023-02-28 02:07:29,520:INFO:_display_container: 28
2023-02-28 02:07:29,520:INFO:GradientBoostingRegressor(random_state=123)
2023-02-28 02:07:29,520:INFO:create_model() successfully completed......................................
2023-02-28 02:07:29,870:INFO:SubProcess create_model() end ==================================
2023-02-28 02:07:29,870:INFO:GradientBoostingRegressor(random_state=123) result for R2 is 0.832
2023-02-28 02:07:29,870:INFO:BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                 random_state=123) result for R2 is 0.8395
2023-02-28 02:07:29,870:INFO:BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                 random_state=123) is best model
2023-02-28 02:07:29,870:INFO:choose_better completed
2023-02-28 02:07:29,891:INFO:_master_model_container: 62
2023-02-28 02:07:29,891:INFO:_display_container: 27
2023-02-28 02:07:29,891:INFO:BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                 random_state=123)
2023-02-28 02:07:29,891:INFO:ensemble_model() successfully completed......................................
2023-02-28 02:11:55,521:INFO:Initializing tune_model()
2023-02-28 02:11:55,521:INFO:tune_model(estimator=GradientBoostingRegressor(random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>)
2023-02-28 02:11:55,521:INFO:Checking exceptions
2023-02-28 02:11:55,545:INFO:Copying training dataset
2023-02-28 02:11:55,550:INFO:Checking base model
2023-02-28 02:11:55,550:INFO:Base model : Gradient Boosting Regressor
2023-02-28 02:11:55,555:INFO:Declaring metric variables
2023-02-28 02:11:55,559:INFO:Defining Hyperparameters
2023-02-28 02:11:55,881:INFO:Tuning with n_jobs=-1
2023-02-28 02:11:55,881:INFO:Initializing RandomizedSearchCV
2023-02-28 02:12:01,252:INFO:best_params: {'actual_estimator__subsample': 0.85, 'actual_estimator__n_estimators': 230, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.02, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.15}
2023-02-28 02:12:01,252:INFO:Hyperparameter search completed
2023-02-28 02:12:01,252:INFO:SubProcess create_model() called ==================================
2023-02-28 02:12:01,252:INFO:Initializing create_model()
2023-02-28 02:12:01,252:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB089F0550>, model_only=True, return_train_score=False, kwargs={'subsample': 0.85, 'n_estimators': 230, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.02, 'max_features': 1.0, 'max_depth': 7, 'learning_rate': 0.15})
2023-02-28 02:12:01,252:INFO:Checking exceptions
2023-02-28 02:12:01,252:INFO:Importing libraries
2023-02-28 02:12:01,252:INFO:Copying training dataset
2023-02-28 02:12:01,261:INFO:Defining folds
2023-02-28 02:12:01,261:INFO:Declaring metric variables
2023-02-28 02:12:01,262:INFO:Importing untrained model
2023-02-28 02:12:01,265:INFO:Declaring custom model
2023-02-28 02:12:01,265:INFO:Gradient Boosting Regressor Imported successfully
2023-02-28 02:12:01,276:INFO:Starting cross validation
2023-02-28 02:12:01,278:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:12:01,749:INFO:Calculating mean and std
2023-02-28 02:12:01,749:INFO:Creating metrics dataframe
2023-02-28 02:12:01,749:INFO:Finalizing model
2023-02-28 02:12:02,227:INFO:Uploading results into container
2023-02-28 02:12:02,227:INFO:Uploading model into container now
2023-02-28 02:12:02,227:INFO:_master_model_container: 63
2023-02-28 02:12:02,227:INFO:_display_container: 28
2023-02-28 02:12:02,227:INFO:GradientBoostingRegressor(learning_rate=0.15, max_depth=7, max_features=1.0,
                          min_impurity_decrease=0.02, min_samples_leaf=5,
                          min_samples_split=5, n_estimators=230,
                          random_state=123, subsample=0.85)
2023-02-28 02:12:02,227:INFO:create_model() successfully completed......................................
2023-02-28 02:12:02,527:INFO:SubProcess create_model() end ==================================
2023-02-28 02:12:02,527:INFO:choose_better activated
2023-02-28 02:12:02,535:INFO:SubProcess create_model() called ==================================
2023-02-28 02:12:02,535:INFO:Initializing create_model()
2023-02-28 02:12:02,535:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:12:02,535:INFO:Checking exceptions
2023-02-28 02:12:02,535:INFO:Importing libraries
2023-02-28 02:12:02,535:INFO:Copying training dataset
2023-02-28 02:12:02,543:INFO:Defining folds
2023-02-28 02:12:02,543:INFO:Declaring metric variables
2023-02-28 02:12:02,543:INFO:Importing untrained model
2023-02-28 02:12:02,543:INFO:Declaring custom model
2023-02-28 02:12:02,543:INFO:Gradient Boosting Regressor Imported successfully
2023-02-28 02:12:02,543:INFO:Starting cross validation
2023-02-28 02:12:02,543:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:12:02,900:INFO:Calculating mean and std
2023-02-28 02:12:02,900:INFO:Creating metrics dataframe
2023-02-28 02:12:02,900:INFO:Finalizing model
2023-02-28 02:12:03,054:INFO:Uploading results into container
2023-02-28 02:12:03,054:INFO:Uploading model into container now
2023-02-28 02:12:03,054:INFO:_master_model_container: 64
2023-02-28 02:12:03,054:INFO:_display_container: 29
2023-02-28 02:12:03,054:INFO:GradientBoostingRegressor(random_state=123)
2023-02-28 02:12:03,054:INFO:create_model() successfully completed......................................
2023-02-28 02:12:03,361:INFO:SubProcess create_model() end ==================================
2023-02-28 02:12:03,361:INFO:GradientBoostingRegressor(random_state=123) result for R2 is 0.832
2023-02-28 02:12:03,361:INFO:GradientBoostingRegressor(learning_rate=0.15, max_depth=7, max_features=1.0,
                          min_impurity_decrease=0.02, min_samples_leaf=5,
                          min_samples_split=5, n_estimators=230,
                          random_state=123, subsample=0.85) result for R2 is 0.7634
2023-02-28 02:12:03,361:INFO:GradientBoostingRegressor(random_state=123) is best model
2023-02-28 02:12:03,361:INFO:choose_better completed
2023-02-28 02:12:03,361:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-02-28 02:12:03,373:INFO:_master_model_container: 64
2023-02-28 02:12:03,373:INFO:_display_container: 28
2023-02-28 02:12:03,373:INFO:GradientBoostingRegressor(random_state=123)
2023-02-28 02:12:03,373:INFO:tune_model() successfully completed......................................
2023-02-28 02:12:03,667:INFO:Initializing tune_model()
2023-02-28 02:12:03,667:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>)
2023-02-28 02:12:03,667:INFO:Checking exceptions
2023-02-28 02:12:03,683:INFO:Copying training dataset
2023-02-28 02:12:03,691:INFO:Checking base model
2023-02-28 02:12:03,691:INFO:Base model : Random Forest Regressor
2023-02-28 02:12:03,691:INFO:Declaring metric variables
2023-02-28 02:12:03,699:INFO:Defining Hyperparameters
2023-02-28 02:12:03,999:INFO:Tuning with n_jobs=-1
2023-02-28 02:12:03,999:INFO:Initializing RandomizedSearchCV
2023-02-28 02:12:06,718:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-28 02:12:06,718:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-28 02:12:06,737:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-28 02:12:06,815:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-28 02:12:10,432:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-02-28 02:12:10,609:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-02-28 02:12:10,729:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-02-28 02:12:10,755:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-02-28 02:12:10,771:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-02-28 02:12:10,795:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-02-28 02:12:10,804:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-02-28 02:12:10,983:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-02-28 02:12:13,874:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-28 02:12:13,942:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-28 02:12:13,979:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-28 02:12:15,678:INFO:best_params: {'actual_estimator__n_estimators': 100, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.1, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': True}
2023-02-28 02:12:15,678:INFO:Hyperparameter search completed
2023-02-28 02:12:15,678:INFO:SubProcess create_model() called ==================================
2023-02-28 02:12:15,678:INFO:Initializing create_model()
2023-02-28 02:12:15,684:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB0585A490>, model_only=True, return_train_score=False, kwargs={'n_estimators': 100, 'min_samples_split': 7, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_features': 1.0, 'max_depth': 9, 'criterion': 'squared_error', 'bootstrap': True})
2023-02-28 02:12:15,684:INFO:Checking exceptions
2023-02-28 02:12:15,684:INFO:Importing libraries
2023-02-28 02:12:15,684:INFO:Copying training dataset
2023-02-28 02:12:15,684:INFO:Defining folds
2023-02-28 02:12:15,684:INFO:Declaring metric variables
2023-02-28 02:12:15,692:INFO:Importing untrained model
2023-02-28 02:12:15,692:INFO:Declaring custom model
2023-02-28 02:12:15,692:INFO:Random Forest Regressor Imported successfully
2023-02-28 02:12:15,700:INFO:Starting cross validation
2023-02-28 02:12:15,700:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:12:16,144:INFO:Calculating mean and std
2023-02-28 02:12:16,145:INFO:Creating metrics dataframe
2023-02-28 02:12:16,148:INFO:Finalizing model
2023-02-28 02:12:16,460:INFO:Uploading results into container
2023-02-28 02:12:16,461:INFO:Uploading model into container now
2023-02-28 02:12:16,461:INFO:_master_model_container: 65
2023-02-28 02:12:16,461:INFO:_display_container: 29
2023-02-28 02:12:16,461:INFO:RandomForestRegressor(max_depth=9, min_impurity_decrease=0.1,
                      min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                      random_state=123)
2023-02-28 02:12:16,461:INFO:create_model() successfully completed......................................
2023-02-28 02:12:16,733:INFO:SubProcess create_model() end ==================================
2023-02-28 02:12:16,733:INFO:choose_better activated
2023-02-28 02:12:16,741:INFO:SubProcess create_model() called ==================================
2023-02-28 02:12:16,741:INFO:Initializing create_model()
2023-02-28 02:12:16,741:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:12:16,741:INFO:Checking exceptions
2023-02-28 02:12:16,741:INFO:Importing libraries
2023-02-28 02:12:16,741:INFO:Copying training dataset
2023-02-28 02:12:16,749:INFO:Defining folds
2023-02-28 02:12:16,749:INFO:Declaring metric variables
2023-02-28 02:12:16,749:INFO:Importing untrained model
2023-02-28 02:12:16,749:INFO:Declaring custom model
2023-02-28 02:12:16,749:INFO:Random Forest Regressor Imported successfully
2023-02-28 02:12:16,749:INFO:Starting cross validation
2023-02-28 02:12:16,749:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:12:17,246:INFO:Calculating mean and std
2023-02-28 02:12:17,246:INFO:Creating metrics dataframe
2023-02-28 02:12:17,255:INFO:Finalizing model
2023-02-28 02:12:17,368:INFO:Uploading results into container
2023-02-28 02:12:17,368:INFO:Uploading model into container now
2023-02-28 02:12:17,368:INFO:_master_model_container: 66
2023-02-28 02:12:17,368:INFO:_display_container: 30
2023-02-28 02:12:17,368:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-02-28 02:12:17,368:INFO:create_model() successfully completed......................................
2023-02-28 02:12:17,675:INFO:SubProcess create_model() end ==================================
2023-02-28 02:12:17,675:INFO:RandomForestRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8172
2023-02-28 02:12:17,675:INFO:RandomForestRegressor(max_depth=9, min_impurity_decrease=0.1,
                      min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                      random_state=123) result for R2 is 0.8386
2023-02-28 02:12:17,675:INFO:RandomForestRegressor(max_depth=9, min_impurity_decrease=0.1,
                      min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                      random_state=123) is best model
2023-02-28 02:12:17,675:INFO:choose_better completed
2023-02-28 02:12:17,685:INFO:_master_model_container: 66
2023-02-28 02:12:17,685:INFO:_display_container: 29
2023-02-28 02:12:17,685:INFO:RandomForestRegressor(max_depth=9, min_impurity_decrease=0.1,
                      min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                      random_state=123)
2023-02-28 02:12:17,685:INFO:tune_model() successfully completed......................................
2023-02-28 02:12:17,981:INFO:Initializing tune_model()
2023-02-28 02:12:17,981:INFO:tune_model(estimator=LGBMRegressor(random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>)
2023-02-28 02:12:17,981:INFO:Checking exceptions
2023-02-28 02:12:17,998:INFO:Copying training dataset
2023-02-28 02:12:18,002:INFO:Checking base model
2023-02-28 02:12:18,002:INFO:Base model : Light Gradient Boosting Machine
2023-02-28 02:12:18,002:INFO:Declaring metric variables
2023-02-28 02:12:18,009:INFO:Defining Hyperparameters
2023-02-28 02:12:18,322:INFO:Tuning with n_jobs=-1
2023-02-28 02:12:18,322:INFO:Initializing RandomizedSearchCV
2023-02-28 02:12:21,015:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-02-28 02:12:21,015:INFO:Hyperparameter search completed
2023-02-28 02:12:21,015:INFO:SubProcess create_model() called ==================================
2023-02-28 02:12:21,015:INFO:Initializing create_model()
2023-02-28 02:12:21,015:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=LGBMRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB06450580>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-02-28 02:12:21,015:INFO:Checking exceptions
2023-02-28 02:12:21,018:INFO:Importing libraries
2023-02-28 02:12:21,018:INFO:Copying training dataset
2023-02-28 02:12:21,019:INFO:Defining folds
2023-02-28 02:12:21,019:INFO:Declaring metric variables
2023-02-28 02:12:21,026:INFO:Importing untrained model
2023-02-28 02:12:21,026:INFO:Declaring custom model
2023-02-28 02:12:21,027:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-28 02:12:21,034:INFO:Starting cross validation
2023-02-28 02:12:21,037:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:12:21,411:INFO:Calculating mean and std
2023-02-28 02:12:21,411:INFO:Creating metrics dataframe
2023-02-28 02:12:21,419:INFO:Finalizing model
2023-02-28 02:12:21,577:INFO:Uploading results into container
2023-02-28 02:12:21,578:INFO:Uploading model into container now
2023-02-28 02:12:21,579:INFO:_master_model_container: 67
2023-02-28 02:12:21,579:INFO:_display_container: 30
2023-02-28 02:12:21,580:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              num_leaves=70, random_state=123, reg_alpha=2, reg_lambda=3)
2023-02-28 02:12:21,581:INFO:create_model() successfully completed......................................
2023-02-28 02:12:21,899:INFO:SubProcess create_model() end ==================================
2023-02-28 02:12:21,899:INFO:choose_better activated
2023-02-28 02:12:21,899:INFO:SubProcess create_model() called ==================================
2023-02-28 02:12:21,899:INFO:Initializing create_model()
2023-02-28 02:12:21,899:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=LGBMRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:12:21,907:INFO:Checking exceptions
2023-02-28 02:12:21,907:INFO:Importing libraries
2023-02-28 02:12:21,907:INFO:Copying training dataset
2023-02-28 02:12:21,907:INFO:Defining folds
2023-02-28 02:12:21,907:INFO:Declaring metric variables
2023-02-28 02:12:21,907:INFO:Importing untrained model
2023-02-28 02:12:21,907:INFO:Declaring custom model
2023-02-28 02:12:21,907:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-28 02:12:21,907:INFO:Starting cross validation
2023-02-28 02:12:21,907:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:12:22,272:INFO:Calculating mean and std
2023-02-28 02:12:22,272:INFO:Creating metrics dataframe
2023-02-28 02:12:22,275:INFO:Finalizing model
2023-02-28 02:12:22,356:INFO:Uploading results into container
2023-02-28 02:12:22,356:INFO:Uploading model into container now
2023-02-28 02:12:22,356:INFO:_master_model_container: 68
2023-02-28 02:12:22,356:INFO:_display_container: 31
2023-02-28 02:12:22,356:INFO:LGBMRegressor(random_state=123)
2023-02-28 02:12:22,356:INFO:create_model() successfully completed......................................
2023-02-28 02:12:22,683:INFO:SubProcess create_model() end ==================================
2023-02-28 02:12:22,686:INFO:LGBMRegressor(random_state=123) result for R2 is 0.8149
2023-02-28 02:12:22,686:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              num_leaves=70, random_state=123, reg_alpha=2, reg_lambda=3) result for R2 is 0.7917
2023-02-28 02:12:22,686:INFO:LGBMRegressor(random_state=123) is best model
2023-02-28 02:12:22,686:INFO:choose_better completed
2023-02-28 02:12:22,686:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-02-28 02:12:22,694:INFO:_master_model_container: 68
2023-02-28 02:12:22,694:INFO:_display_container: 30
2023-02-28 02:12:22,694:INFO:LGBMRegressor(random_state=123)
2023-02-28 02:12:22,694:INFO:tune_model() successfully completed......................................
2023-02-28 02:12:22,992:INFO:Initializing tune_model()
2023-02-28 02:12:22,992:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>)
2023-02-28 02:12:22,992:INFO:Checking exceptions
2023-02-28 02:12:23,008:INFO:Copying training dataset
2023-02-28 02:12:23,010:INFO:Checking base model
2023-02-28 02:12:23,010:INFO:Base model : Extra Trees Regressor
2023-02-28 02:12:23,016:INFO:Declaring metric variables
2023-02-28 02:12:23,016:INFO:Defining Hyperparameters
2023-02-28 02:12:23,317:INFO:Tuning with n_jobs=-1
2023-02-28 02:12:23,317:INFO:Initializing RandomizedSearchCV
2023-02-28 02:12:26,042:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-28 02:12:26,051:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-28 02:12:26,066:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-28 02:12:26,294:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-28 02:12:29,135:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-28 02:12:29,216:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-28 02:12:30,190:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-02-28 02:12:30,338:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-02-28 02:12:32,706:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-02-28 02:12:32,830:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-02-28 02:12:33,062:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-28 02:12:33,070:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-28 02:12:33,086:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-02-28 02:12:33,094:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-28 02:12:34,757:INFO:best_params: {'actual_estimator__n_estimators': 100, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.1, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': True}
2023-02-28 02:12:34,757:INFO:Hyperparameter search completed
2023-02-28 02:12:34,757:INFO:SubProcess create_model() called ==================================
2023-02-28 02:12:34,757:INFO:Initializing create_model()
2023-02-28 02:12:34,757:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB073AE0A0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 100, 'min_samples_split': 7, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_features': 1.0, 'max_depth': 9, 'criterion': 'squared_error', 'bootstrap': True})
2023-02-28 02:12:34,757:INFO:Checking exceptions
2023-02-28 02:12:34,757:INFO:Importing libraries
2023-02-28 02:12:34,757:INFO:Copying training dataset
2023-02-28 02:12:34,766:INFO:Defining folds
2023-02-28 02:12:34,766:INFO:Declaring metric variables
2023-02-28 02:12:34,766:INFO:Importing untrained model
2023-02-28 02:12:34,766:INFO:Declaring custom model
2023-02-28 02:12:34,774:INFO:Extra Trees Regressor Imported successfully
2023-02-28 02:12:34,780:INFO:Starting cross validation
2023-02-28 02:12:34,782:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:12:35,158:INFO:Calculating mean and std
2023-02-28 02:12:35,158:INFO:Creating metrics dataframe
2023-02-28 02:12:35,161:INFO:Finalizing model
2023-02-28 02:12:35,468:INFO:Uploading results into container
2023-02-28 02:12:35,468:INFO:Uploading model into container now
2023-02-28 02:12:35,468:INFO:_master_model_container: 69
2023-02-28 02:12:35,468:INFO:_display_container: 31
2023-02-28 02:12:35,468:INFO:ExtraTreesRegressor(bootstrap=True, max_depth=9, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123)
2023-02-28 02:12:35,468:INFO:create_model() successfully completed......................................
2023-02-28 02:12:35,743:INFO:SubProcess create_model() end ==================================
2023-02-28 02:12:35,743:INFO:choose_better activated
2023-02-28 02:12:35,743:INFO:SubProcess create_model() called ==================================
2023-02-28 02:12:35,751:INFO:Initializing create_model()
2023-02-28 02:12:35,751:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:12:35,751:INFO:Checking exceptions
2023-02-28 02:12:35,751:INFO:Importing libraries
2023-02-28 02:12:35,751:INFO:Copying training dataset
2023-02-28 02:12:35,751:INFO:Defining folds
2023-02-28 02:12:35,751:INFO:Declaring metric variables
2023-02-28 02:12:35,751:INFO:Importing untrained model
2023-02-28 02:12:35,751:INFO:Declaring custom model
2023-02-28 02:12:35,751:INFO:Extra Trees Regressor Imported successfully
2023-02-28 02:12:35,751:INFO:Starting cross validation
2023-02-28 02:12:35,751:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:12:36,344:INFO:Calculating mean and std
2023-02-28 02:12:36,344:INFO:Creating metrics dataframe
2023-02-28 02:12:36,344:INFO:Finalizing model
2023-02-28 02:12:36,467:INFO:Uploading results into container
2023-02-28 02:12:36,467:INFO:Uploading model into container now
2023-02-28 02:12:36,467:INFO:_master_model_container: 70
2023-02-28 02:12:36,467:INFO:_display_container: 32
2023-02-28 02:12:36,467:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-02-28 02:12:36,467:INFO:create_model() successfully completed......................................
2023-02-28 02:12:36,762:INFO:SubProcess create_model() end ==================================
2023-02-28 02:12:36,762:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for R2 is 0.7991
2023-02-28 02:12:36,771:INFO:ExtraTreesRegressor(bootstrap=True, max_depth=9, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123) result for R2 is 0.8381
2023-02-28 02:12:36,771:INFO:ExtraTreesRegressor(bootstrap=True, max_depth=9, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123) is best model
2023-02-28 02:12:36,771:INFO:choose_better completed
2023-02-28 02:12:36,779:INFO:_master_model_container: 70
2023-02-28 02:12:36,779:INFO:_display_container: 31
2023-02-28 02:12:36,779:INFO:ExtraTreesRegressor(bootstrap=True, max_depth=9, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123)
2023-02-28 02:12:36,779:INFO:tune_model() successfully completed......................................
2023-02-28 02:12:37,091:INFO:Initializing tune_model()
2023-02-28 02:12:37,091:INFO:tune_model(estimator=AdaBoostRegressor(random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>)
2023-02-28 02:12:37,091:INFO:Checking exceptions
2023-02-28 02:12:37,106:INFO:Copying training dataset
2023-02-28 02:12:37,109:INFO:Checking base model
2023-02-28 02:12:37,109:INFO:Base model : AdaBoost Regressor
2023-02-28 02:12:37,115:INFO:Declaring metric variables
2023-02-28 02:12:37,115:INFO:Defining Hyperparameters
2023-02-28 02:12:37,433:INFO:Tuning with n_jobs=-1
2023-02-28 02:12:37,433:INFO:Initializing RandomizedSearchCV
2023-02-28 02:12:45,205:INFO:best_params: {'actual_estimator__n_estimators': 240, 'actual_estimator__loss': 'linear', 'actual_estimator__learning_rate': 1e-06}
2023-02-28 02:12:45,209:INFO:Hyperparameter search completed
2023-02-28 02:12:45,209:INFO:SubProcess create_model() called ==================================
2023-02-28 02:12:45,209:INFO:Initializing create_model()
2023-02-28 02:12:45,209:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=AdaBoostRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB066B4670>, model_only=True, return_train_score=False, kwargs={'n_estimators': 240, 'loss': 'linear', 'learning_rate': 1e-06})
2023-02-28 02:12:45,209:INFO:Checking exceptions
2023-02-28 02:12:45,209:INFO:Importing libraries
2023-02-28 02:12:45,209:INFO:Copying training dataset
2023-02-28 02:12:45,213:INFO:Defining folds
2023-02-28 02:12:45,213:INFO:Declaring metric variables
2023-02-28 02:12:45,213:INFO:Importing untrained model
2023-02-28 02:12:45,213:INFO:Declaring custom model
2023-02-28 02:12:45,221:INFO:str Imported successfully
2023-02-28 02:12:45,227:INFO:Starting cross validation
2023-02-28 02:12:45,229:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:12:45,822:INFO:Calculating mean and std
2023-02-28 02:12:45,822:INFO:Creating metrics dataframe
2023-02-28 02:12:45,829:INFO:Finalizing model
2023-02-28 02:12:46,443:INFO:Uploading results into container
2023-02-28 02:12:46,443:INFO:Uploading model into container now
2023-02-28 02:12:46,443:INFO:_master_model_container: 71
2023-02-28 02:12:46,443:INFO:_display_container: 32
2023-02-28 02:12:46,445:INFO:AdaBoostRegressor(learning_rate=1e-06, n_estimators=240, random_state=123)
2023-02-28 02:12:46,445:INFO:create_model() successfully completed......................................
2023-02-28 02:12:46,735:INFO:SubProcess create_model() end ==================================
2023-02-28 02:12:46,735:INFO:choose_better activated
2023-02-28 02:12:46,741:INFO:SubProcess create_model() called ==================================
2023-02-28 02:12:46,741:INFO:Initializing create_model()
2023-02-28 02:12:46,741:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=AdaBoostRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:12:46,741:INFO:Checking exceptions
2023-02-28 02:12:46,743:INFO:Importing libraries
2023-02-28 02:12:46,743:INFO:Copying training dataset
2023-02-28 02:12:46,743:INFO:Defining folds
2023-02-28 02:12:46,743:INFO:Declaring metric variables
2023-02-28 02:12:46,743:INFO:Importing untrained model
2023-02-28 02:12:46,743:INFO:Declaring custom model
2023-02-28 02:12:46,743:INFO:str Imported successfully
2023-02-28 02:12:46,743:INFO:Starting cross validation
2023-02-28 02:12:46,743:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:12:47,057:INFO:Calculating mean and std
2023-02-28 02:12:47,062:INFO:Creating metrics dataframe
2023-02-28 02:12:47,062:INFO:Finalizing model
2023-02-28 02:12:47,157:INFO:Uploading results into container
2023-02-28 02:12:47,157:INFO:Uploading model into container now
2023-02-28 02:12:47,157:INFO:_master_model_container: 72
2023-02-28 02:12:47,157:INFO:_display_container: 33
2023-02-28 02:12:47,157:INFO:AdaBoostRegressor(random_state=123)
2023-02-28 02:12:47,157:INFO:create_model() successfully completed......................................
2023-02-28 02:12:47,482:INFO:SubProcess create_model() end ==================================
2023-02-28 02:12:47,482:INFO:AdaBoostRegressor(random_state=123) result for R2 is 0.7903
2023-02-28 02:12:47,483:INFO:AdaBoostRegressor(learning_rate=1e-06, n_estimators=240, random_state=123) result for R2 is 0.8335
2023-02-28 02:12:47,483:INFO:AdaBoostRegressor(learning_rate=1e-06, n_estimators=240, random_state=123) is best model
2023-02-28 02:12:47,483:INFO:choose_better completed
2023-02-28 02:12:47,495:INFO:_master_model_container: 72
2023-02-28 02:12:47,495:INFO:_display_container: 32
2023-02-28 02:12:47,495:INFO:AdaBoostRegressor(learning_rate=1e-06, n_estimators=240, random_state=123)
2023-02-28 02:12:47,495:INFO:tune_model() successfully completed......................................
2023-02-28 02:12:47,777:INFO:Initializing tune_model()
2023-02-28 02:12:47,777:INFO:tune_model(estimator=HuberRegressor(), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>)
2023-02-28 02:12:47,777:INFO:Checking exceptions
2023-02-28 02:12:47,800:INFO:Copying training dataset
2023-02-28 02:12:47,804:INFO:Checking base model
2023-02-28 02:12:47,804:INFO:Base model : Huber Regressor
2023-02-28 02:12:47,804:INFO:Declaring metric variables
2023-02-28 02:12:47,810:INFO:Defining Hyperparameters
2023-02-28 02:12:48,128:INFO:Tuning with n_jobs=-1
2023-02-28 02:12:48,128:INFO:Initializing RandomizedSearchCV
2023-02-28 02:12:48,476:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:48,484:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:48,484:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:48,492:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:48,524:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:48,533:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:48,622:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:48,662:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:48,726:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:48,751:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:48,759:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:48,759:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:48,775:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:48,799:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:48,823:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:48,831:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:48,864:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:48,872:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:48,880:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:48,896:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:48,904:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:48,969:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:49,001:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:49,093:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:49,098:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:49,133:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:49,140:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:49,155:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:49,179:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:49,219:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:49,486:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:49,486:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:49,527:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:49,583:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:49,591:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:49,607:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:49,615:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:49,639:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:49,679:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:49,695:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:49,703:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:49,703:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:49,732:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:49,766:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:49,776:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:49,792:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:49,816:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:49,848:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:49,929:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:49,929:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:49,945:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:49,962:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:49,986:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:49,994:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:50,026:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:50,074:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:50,090:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:50,114:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:50,122:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:50,144:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:50,163:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:50,195:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:50,219:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:50,235:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:50,235:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:50,268:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:50,287:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:50,344:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:50,365:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:50,379:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:50,648:INFO:best_params: {'actual_estimator__fit_intercept': False, 'actual_estimator__epsilon': 1.4, 'actual_estimator__alpha': 0.001}
2023-02-28 02:12:50,648:INFO:Hyperparameter search completed
2023-02-28 02:12:50,648:INFO:SubProcess create_model() called ==================================
2023-02-28 02:12:50,656:INFO:Initializing create_model()
2023-02-28 02:12:50,656:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB0754A8E0>, model_only=True, return_train_score=False, kwargs={'fit_intercept': False, 'epsilon': 1.4, 'alpha': 0.001})
2023-02-28 02:12:50,656:INFO:Checking exceptions
2023-02-28 02:12:50,656:INFO:Importing libraries
2023-02-28 02:12:50,656:INFO:Copying training dataset
2023-02-28 02:12:50,656:INFO:Defining folds
2023-02-28 02:12:50,656:INFO:Declaring metric variables
2023-02-28 02:12:50,664:INFO:Importing untrained model
2023-02-28 02:12:50,664:INFO:Declaring custom model
2023-02-28 02:12:50,664:INFO:Huber Regressor Imported successfully
2023-02-28 02:12:50,672:INFO:Starting cross validation
2023-02-28 02:12:50,672:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:12:50,844:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:50,851:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:50,867:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:50,892:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:50,895:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:50,907:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:50,915:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:50,931:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:50,955:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:50,963:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:51,019:INFO:Calculating mean and std
2023-02-28 02:12:51,019:INFO:Creating metrics dataframe
2023-02-28 02:12:51,033:INFO:Finalizing model
2023-02-28 02:12:51,145:INFO:Uploading results into container
2023-02-28 02:12:51,145:INFO:Uploading model into container now
2023-02-28 02:12:51,145:INFO:_master_model_container: 73
2023-02-28 02:12:51,145:INFO:_display_container: 33
2023-02-28 02:12:51,145:INFO:HuberRegressor(alpha=0.001, epsilon=1.4, fit_intercept=False)
2023-02-28 02:12:51,145:INFO:create_model() successfully completed......................................
2023-02-28 02:12:51,454:INFO:SubProcess create_model() end ==================================
2023-02-28 02:12:51,454:INFO:choose_better activated
2023-02-28 02:12:51,462:INFO:SubProcess create_model() called ==================================
2023-02-28 02:12:51,462:INFO:Initializing create_model()
2023-02-28 02:12:51,462:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:12:51,462:INFO:Checking exceptions
2023-02-28 02:12:51,462:INFO:Importing libraries
2023-02-28 02:12:51,462:INFO:Copying training dataset
2023-02-28 02:12:51,462:INFO:Defining folds
2023-02-28 02:12:51,462:INFO:Declaring metric variables
2023-02-28 02:12:51,462:INFO:Importing untrained model
2023-02-28 02:12:51,462:INFO:Declaring custom model
2023-02-28 02:12:51,462:INFO:Huber Regressor Imported successfully
2023-02-28 02:12:51,462:INFO:Starting cross validation
2023-02-28 02:12:51,470:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:12:51,632:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:51,640:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:51,664:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:51,680:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:51,680:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:51,696:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:51,696:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:51,720:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:51,765:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:51,765:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:12:51,815:INFO:Calculating mean and std
2023-02-28 02:12:51,815:INFO:Creating metrics dataframe
2023-02-28 02:12:51,818:INFO:Finalizing model
2023-02-28 02:12:51,910:INFO:Uploading results into container
2023-02-28 02:12:51,910:INFO:Uploading model into container now
2023-02-28 02:12:51,910:INFO:_master_model_container: 74
2023-02-28 02:12:51,910:INFO:_display_container: 34
2023-02-28 02:12:51,910:INFO:HuberRegressor()
2023-02-28 02:12:51,910:INFO:create_model() successfully completed......................................
2023-02-28 02:12:52,217:INFO:SubProcess create_model() end ==================================
2023-02-28 02:12:52,217:INFO:HuberRegressor() result for R2 is 0.6544
2023-02-28 02:12:52,217:INFO:HuberRegressor(alpha=0.001, epsilon=1.4, fit_intercept=False) result for R2 is 0.6902
2023-02-28 02:12:52,217:INFO:HuberRegressor(alpha=0.001, epsilon=1.4, fit_intercept=False) is best model
2023-02-28 02:12:52,217:INFO:choose_better completed
2023-02-28 02:12:52,225:INFO:_master_model_container: 74
2023-02-28 02:12:52,225:INFO:_display_container: 33
2023-02-28 02:12:52,225:INFO:HuberRegressor(alpha=0.001, epsilon=1.4, fit_intercept=False)
2023-02-28 02:12:52,225:INFO:tune_model() successfully completed......................................
2023-02-28 02:12:52,524:INFO:Initializing tune_model()
2023-02-28 02:12:52,524:INFO:tune_model(estimator=BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                 random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>)
2023-02-28 02:12:52,524:INFO:Checking exceptions
2023-02-28 02:12:52,549:INFO:Copying training dataset
2023-02-28 02:12:52,550:INFO:Checking base model
2023-02-28 02:12:52,550:INFO:Base model : Bagging Regressor
2023-02-28 02:12:52,556:INFO:Declaring metric variables
2023-02-28 02:12:52,559:INFO:Defining Hyperparameters
2023-02-28 02:12:52,872:INFO:Tuning with n_jobs=-1
2023-02-28 02:12:52,872:INFO:Initializing RandomizedSearchCV
2023-02-28 02:13:52,250:INFO:Initializing tune_model()
2023-02-28 02:13:52,250:INFO:tune_model(estimator=GradientBoostingRegressor(random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>)
2023-02-28 02:13:52,250:INFO:Checking exceptions
2023-02-28 02:13:52,274:INFO:Copying training dataset
2023-02-28 02:13:52,279:INFO:Checking base model
2023-02-28 02:13:52,279:INFO:Base model : Gradient Boosting Regressor
2023-02-28 02:13:52,284:INFO:Declaring metric variables
2023-02-28 02:13:52,288:INFO:Defining Hyperparameters
2023-02-28 02:13:53,011:INFO:Tuning with n_jobs=-1
2023-02-28 02:13:53,011:INFO:Initializing RandomizedSearchCV
2023-02-28 02:13:56,560:INFO:best_params: {'actual_estimator__subsample': 0.85, 'actual_estimator__n_estimators': 230, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.02, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.15}
2023-02-28 02:13:56,560:INFO:Hyperparameter search completed
2023-02-28 02:13:56,560:INFO:SubProcess create_model() called ==================================
2023-02-28 02:13:56,560:INFO:Initializing create_model()
2023-02-28 02:13:56,560:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB03839EB0>, model_only=True, return_train_score=False, kwargs={'subsample': 0.85, 'n_estimators': 230, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.02, 'max_features': 1.0, 'max_depth': 7, 'learning_rate': 0.15})
2023-02-28 02:13:56,560:INFO:Checking exceptions
2023-02-28 02:13:56,560:INFO:Importing libraries
2023-02-28 02:13:56,560:INFO:Copying training dataset
2023-02-28 02:13:56,568:INFO:Defining folds
2023-02-28 02:13:56,568:INFO:Declaring metric variables
2023-02-28 02:13:56,576:INFO:Importing untrained model
2023-02-28 02:13:56,576:INFO:Declaring custom model
2023-02-28 02:13:56,577:INFO:Gradient Boosting Regressor Imported successfully
2023-02-28 02:13:56,585:INFO:Starting cross validation
2023-02-28 02:13:56,585:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:13:57,001:INFO:Calculating mean and std
2023-02-28 02:13:57,001:INFO:Creating metrics dataframe
2023-02-28 02:13:57,007:INFO:Finalizing model
2023-02-28 02:13:57,099:INFO:Uploading results into container
2023-02-28 02:13:57,103:INFO:Uploading model into container now
2023-02-28 02:13:57,103:INFO:_master_model_container: 75
2023-02-28 02:13:57,103:INFO:_display_container: 34
2023-02-28 02:13:57,103:INFO:GradientBoostingRegressor(learning_rate=0.15, max_depth=7, max_features=1.0,
                          min_impurity_decrease=0.02, min_samples_leaf=5,
                          min_samples_split=5, n_estimators=230,
                          random_state=123, subsample=0.85)
2023-02-28 02:13:57,103:INFO:create_model() successfully completed......................................
2023-02-28 02:13:57,434:INFO:SubProcess create_model() end ==================================
2023-02-28 02:13:57,434:INFO:choose_better activated
2023-02-28 02:13:57,436:INFO:SubProcess create_model() called ==================================
2023-02-28 02:13:57,436:INFO:Initializing create_model()
2023-02-28 02:13:57,436:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:13:57,436:INFO:Checking exceptions
2023-02-28 02:13:57,436:INFO:Importing libraries
2023-02-28 02:13:57,442:INFO:Copying training dataset
2023-02-28 02:13:57,442:INFO:Defining folds
2023-02-28 02:13:57,442:INFO:Declaring metric variables
2023-02-28 02:13:57,442:INFO:Importing untrained model
2023-02-28 02:13:57,442:INFO:Declaring custom model
2023-02-28 02:13:57,442:INFO:Gradient Boosting Regressor Imported successfully
2023-02-28 02:13:57,442:INFO:Starting cross validation
2023-02-28 02:13:57,442:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:13:57,785:INFO:Calculating mean and std
2023-02-28 02:13:57,785:INFO:Creating metrics dataframe
2023-02-28 02:13:57,785:INFO:Finalizing model
2023-02-28 02:13:57,931:INFO:Uploading results into container
2023-02-28 02:13:57,939:INFO:Uploading model into container now
2023-02-28 02:13:57,939:INFO:_master_model_container: 76
2023-02-28 02:13:57,939:INFO:_display_container: 35
2023-02-28 02:13:57,940:INFO:GradientBoostingRegressor(random_state=123)
2023-02-28 02:13:57,940:INFO:create_model() successfully completed......................................
2023-02-28 02:13:58,253:INFO:SubProcess create_model() end ==================================
2023-02-28 02:13:58,253:INFO:GradientBoostingRegressor(random_state=123) result for R2 is 0.832
2023-02-28 02:13:58,258:INFO:GradientBoostingRegressor(learning_rate=0.15, max_depth=7, max_features=1.0,
                          min_impurity_decrease=0.02, min_samples_leaf=5,
                          min_samples_split=5, n_estimators=230,
                          random_state=123, subsample=0.85) result for R2 is 0.7634
2023-02-28 02:13:58,258:INFO:GradientBoostingRegressor(random_state=123) is best model
2023-02-28 02:13:58,258:INFO:choose_better completed
2023-02-28 02:13:58,258:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-02-28 02:13:58,263:INFO:_master_model_container: 76
2023-02-28 02:13:58,263:INFO:_display_container: 34
2023-02-28 02:13:58,269:INFO:GradientBoostingRegressor(random_state=123)
2023-02-28 02:13:58,269:INFO:tune_model() successfully completed......................................
2023-02-28 02:13:58,587:INFO:Initializing tune_model()
2023-02-28 02:13:58,587:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>)
2023-02-28 02:13:58,587:INFO:Checking exceptions
2023-02-28 02:13:58,606:INFO:Copying training dataset
2023-02-28 02:13:58,613:INFO:Checking base model
2023-02-28 02:13:58,613:INFO:Base model : Random Forest Regressor
2023-02-28 02:13:58,613:INFO:Declaring metric variables
2023-02-28 02:13:58,619:INFO:Defining Hyperparameters
2023-02-28 02:13:58,940:INFO:Tuning with n_jobs=-1
2023-02-28 02:13:58,940:INFO:Initializing RandomizedSearchCV
2023-02-28 02:14:03,339:INFO:best_params: {'actual_estimator__n_estimators': 100, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.1, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': True}
2023-02-28 02:14:03,339:INFO:Hyperparameter search completed
2023-02-28 02:14:03,339:INFO:SubProcess create_model() called ==================================
2023-02-28 02:14:03,339:INFO:Initializing create_model()
2023-02-28 02:14:03,339:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB075D0B20>, model_only=True, return_train_score=False, kwargs={'n_estimators': 100, 'min_samples_split': 7, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_features': 1.0, 'max_depth': 9, 'criterion': 'squared_error', 'bootstrap': True})
2023-02-28 02:14:03,339:INFO:Checking exceptions
2023-02-28 02:14:03,339:INFO:Importing libraries
2023-02-28 02:14:03,339:INFO:Copying training dataset
2023-02-28 02:14:03,347:INFO:Defining folds
2023-02-28 02:14:03,347:INFO:Declaring metric variables
2023-02-28 02:14:03,347:INFO:Importing untrained model
2023-02-28 02:14:03,347:INFO:Declaring custom model
2023-02-28 02:14:03,355:INFO:Random Forest Regressor Imported successfully
2023-02-28 02:14:03,363:INFO:Starting cross validation
2023-02-28 02:14:03,366:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:14:03,795:INFO:Calculating mean and std
2023-02-28 02:14:03,796:INFO:Creating metrics dataframe
2023-02-28 02:14:03,803:INFO:Finalizing model
2023-02-28 02:14:03,936:INFO:Uploading results into container
2023-02-28 02:14:03,937:INFO:Uploading model into container now
2023-02-28 02:14:03,937:INFO:_master_model_container: 77
2023-02-28 02:14:03,937:INFO:_display_container: 35
2023-02-28 02:14:03,939:INFO:RandomForestRegressor(max_depth=9, min_impurity_decrease=0.1,
                      min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                      random_state=123)
2023-02-28 02:14:03,939:INFO:create_model() successfully completed......................................
2023-02-28 02:14:04,224:INFO:SubProcess create_model() end ==================================
2023-02-28 02:14:04,224:INFO:choose_better activated
2023-02-28 02:14:04,232:INFO:SubProcess create_model() called ==================================
2023-02-28 02:14:04,232:INFO:Initializing create_model()
2023-02-28 02:14:04,232:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:14:04,232:INFO:Checking exceptions
2023-02-28 02:14:04,232:INFO:Importing libraries
2023-02-28 02:14:04,232:INFO:Copying training dataset
2023-02-28 02:14:04,232:INFO:Defining folds
2023-02-28 02:14:04,232:INFO:Declaring metric variables
2023-02-28 02:14:04,232:INFO:Importing untrained model
2023-02-28 02:14:04,232:INFO:Declaring custom model
2023-02-28 02:14:04,232:INFO:Random Forest Regressor Imported successfully
2023-02-28 02:14:04,232:INFO:Starting cross validation
2023-02-28 02:14:04,240:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:14:04,687:INFO:Calculating mean and std
2023-02-28 02:14:04,687:INFO:Creating metrics dataframe
2023-02-28 02:14:04,687:INFO:Finalizing model
2023-02-28 02:14:04,801:INFO:Uploading results into container
2023-02-28 02:14:04,801:INFO:Uploading model into container now
2023-02-28 02:14:04,801:INFO:_master_model_container: 78
2023-02-28 02:14:04,801:INFO:_display_container: 36
2023-02-28 02:14:04,801:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-02-28 02:14:04,801:INFO:create_model() successfully completed......................................
2023-02-28 02:14:05,101:INFO:SubProcess create_model() end ==================================
2023-02-28 02:14:05,102:INFO:RandomForestRegressor(n_jobs=-1, random_state=123) result for R2 is 0.8172
2023-02-28 02:14:05,102:INFO:RandomForestRegressor(max_depth=9, min_impurity_decrease=0.1,
                      min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                      random_state=123) result for R2 is 0.8386
2023-02-28 02:14:05,102:INFO:RandomForestRegressor(max_depth=9, min_impurity_decrease=0.1,
                      min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                      random_state=123) is best model
2023-02-28 02:14:05,102:INFO:choose_better completed
2023-02-28 02:14:05,110:INFO:_master_model_container: 78
2023-02-28 02:14:05,110:INFO:_display_container: 35
2023-02-28 02:14:05,110:INFO:RandomForestRegressor(max_depth=9, min_impurity_decrease=0.1,
                      min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                      random_state=123)
2023-02-28 02:14:05,110:INFO:tune_model() successfully completed......................................
2023-02-28 02:14:05,422:INFO:Initializing tune_model()
2023-02-28 02:14:05,422:INFO:tune_model(estimator=LGBMRegressor(random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>)
2023-02-28 02:14:05,422:INFO:Checking exceptions
2023-02-28 02:14:05,436:INFO:Copying training dataset
2023-02-28 02:14:05,440:INFO:Checking base model
2023-02-28 02:14:05,440:INFO:Base model : Light Gradient Boosting Machine
2023-02-28 02:14:05,445:INFO:Declaring metric variables
2023-02-28 02:14:05,445:INFO:Defining Hyperparameters
2023-02-28 02:14:05,769:INFO:Tuning with n_jobs=-1
2023-02-28 02:14:05,769:INFO:Initializing RandomizedSearchCV
2023-02-28 02:14:08,221:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-02-28 02:14:08,223:INFO:Hyperparameter search completed
2023-02-28 02:14:08,223:INFO:SubProcess create_model() called ==================================
2023-02-28 02:14:08,223:INFO:Initializing create_model()
2023-02-28 02:14:08,223:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=LGBMRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB07308670>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-02-28 02:14:08,223:INFO:Checking exceptions
2023-02-28 02:14:08,223:INFO:Importing libraries
2023-02-28 02:14:08,223:INFO:Copying training dataset
2023-02-28 02:14:08,227:INFO:Defining folds
2023-02-28 02:14:08,227:INFO:Declaring metric variables
2023-02-28 02:14:08,231:INFO:Importing untrained model
2023-02-28 02:14:08,231:INFO:Declaring custom model
2023-02-28 02:14:08,231:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-28 02:14:08,240:INFO:Starting cross validation
2023-02-28 02:14:08,240:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:14:08,570:INFO:Calculating mean and std
2023-02-28 02:14:08,578:INFO:Creating metrics dataframe
2023-02-28 02:14:08,586:INFO:Finalizing model
2023-02-28 02:14:08,723:INFO:Uploading results into container
2023-02-28 02:14:08,723:INFO:Uploading model into container now
2023-02-28 02:14:08,723:INFO:_master_model_container: 79
2023-02-28 02:14:08,723:INFO:_display_container: 36
2023-02-28 02:14:08,723:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              num_leaves=70, random_state=123, reg_alpha=2, reg_lambda=3)
2023-02-28 02:14:08,723:INFO:create_model() successfully completed......................................
2023-02-28 02:14:09,065:INFO:SubProcess create_model() end ==================================
2023-02-28 02:14:09,073:INFO:choose_better activated
2023-02-28 02:14:09,073:INFO:SubProcess create_model() called ==================================
2023-02-28 02:14:09,073:INFO:Initializing create_model()
2023-02-28 02:14:09,073:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=LGBMRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:14:09,073:INFO:Checking exceptions
2023-02-28 02:14:09,073:INFO:Importing libraries
2023-02-28 02:14:09,081:INFO:Copying training dataset
2023-02-28 02:14:09,081:INFO:Defining folds
2023-02-28 02:14:09,084:INFO:Declaring metric variables
2023-02-28 02:14:09,084:INFO:Importing untrained model
2023-02-28 02:14:09,084:INFO:Declaring custom model
2023-02-28 02:14:09,084:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-28 02:14:09,084:INFO:Starting cross validation
2023-02-28 02:14:09,084:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:14:09,457:INFO:Calculating mean and std
2023-02-28 02:14:09,464:INFO:Creating metrics dataframe
2023-02-28 02:14:09,464:INFO:Finalizing model
2023-02-28 02:14:09,548:INFO:Uploading results into container
2023-02-28 02:14:09,548:INFO:Uploading model into container now
2023-02-28 02:14:09,548:INFO:_master_model_container: 80
2023-02-28 02:14:09,548:INFO:_display_container: 37
2023-02-28 02:14:09,548:INFO:LGBMRegressor(random_state=123)
2023-02-28 02:14:09,548:INFO:create_model() successfully completed......................................
2023-02-28 02:14:09,885:INFO:SubProcess create_model() end ==================================
2023-02-28 02:14:09,893:INFO:LGBMRegressor(random_state=123) result for R2 is 0.8149
2023-02-28 02:14:09,893:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              num_leaves=70, random_state=123, reg_alpha=2, reg_lambda=3) result for R2 is 0.7917
2023-02-28 02:14:09,893:INFO:LGBMRegressor(random_state=123) is best model
2023-02-28 02:14:09,893:INFO:choose_better completed
2023-02-28 02:14:09,893:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-02-28 02:14:09,904:INFO:_master_model_container: 80
2023-02-28 02:14:09,904:INFO:_display_container: 36
2023-02-28 02:14:09,906:INFO:LGBMRegressor(random_state=123)
2023-02-28 02:14:09,906:INFO:tune_model() successfully completed......................................
2023-02-28 02:14:10,242:INFO:Initializing tune_model()
2023-02-28 02:14:10,242:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>)
2023-02-28 02:14:10,242:INFO:Checking exceptions
2023-02-28 02:14:10,267:INFO:Copying training dataset
2023-02-28 02:14:10,267:INFO:Checking base model
2023-02-28 02:14:10,267:INFO:Base model : Extra Trees Regressor
2023-02-28 02:14:10,274:INFO:Declaring metric variables
2023-02-28 02:14:10,278:INFO:Defining Hyperparameters
2023-02-28 02:14:10,648:INFO:Tuning with n_jobs=-1
2023-02-28 02:14:10,648:INFO:Initializing RandomizedSearchCV
2023-02-28 02:14:15,032:INFO:best_params: {'actual_estimator__n_estimators': 100, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.1, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': True}
2023-02-28 02:14:15,032:INFO:Hyperparameter search completed
2023-02-28 02:14:15,032:INFO:SubProcess create_model() called ==================================
2023-02-28 02:14:15,032:INFO:Initializing create_model()
2023-02-28 02:14:15,032:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB05D6B6D0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 100, 'min_samples_split': 7, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_features': 1.0, 'max_depth': 9, 'criterion': 'squared_error', 'bootstrap': True})
2023-02-28 02:14:15,032:INFO:Checking exceptions
2023-02-28 02:14:15,032:INFO:Importing libraries
2023-02-28 02:14:15,032:INFO:Copying training dataset
2023-02-28 02:14:15,048:INFO:Defining folds
2023-02-28 02:14:15,048:INFO:Declaring metric variables
2023-02-28 02:14:15,048:INFO:Importing untrained model
2023-02-28 02:14:15,048:INFO:Declaring custom model
2023-02-28 02:14:15,048:INFO:Extra Trees Regressor Imported successfully
2023-02-28 02:14:15,064:INFO:Starting cross validation
2023-02-28 02:14:15,064:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:14:15,708:INFO:Calculating mean and std
2023-02-28 02:14:15,724:INFO:Creating metrics dataframe
2023-02-28 02:14:15,729:INFO:Finalizing model
2023-02-28 02:14:15,994:INFO:Uploading results into container
2023-02-28 02:14:15,994:INFO:Uploading model into container now
2023-02-28 02:14:15,994:INFO:_master_model_container: 81
2023-02-28 02:14:15,994:INFO:_display_container: 37
2023-02-28 02:14:15,994:INFO:ExtraTreesRegressor(bootstrap=True, max_depth=9, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123)
2023-02-28 02:14:15,994:INFO:create_model() successfully completed......................................
2023-02-28 02:14:16,407:INFO:SubProcess create_model() end ==================================
2023-02-28 02:14:16,407:INFO:choose_better activated
2023-02-28 02:14:16,407:INFO:SubProcess create_model() called ==================================
2023-02-28 02:14:16,407:INFO:Initializing create_model()
2023-02-28 02:14:16,407:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:14:16,407:INFO:Checking exceptions
2023-02-28 02:14:16,407:INFO:Importing libraries
2023-02-28 02:14:16,407:INFO:Copying training dataset
2023-02-28 02:14:16,423:INFO:Defining folds
2023-02-28 02:14:16,423:INFO:Declaring metric variables
2023-02-28 02:14:16,423:INFO:Importing untrained model
2023-02-28 02:14:16,423:INFO:Declaring custom model
2023-02-28 02:14:16,423:INFO:Extra Trees Regressor Imported successfully
2023-02-28 02:14:16,423:INFO:Starting cross validation
2023-02-28 02:14:16,423:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:14:17,252:INFO:Calculating mean and std
2023-02-28 02:14:17,252:INFO:Creating metrics dataframe
2023-02-28 02:14:17,252:INFO:Finalizing model
2023-02-28 02:14:17,492:INFO:Uploading results into container
2023-02-28 02:14:17,492:INFO:Uploading model into container now
2023-02-28 02:14:17,496:INFO:_master_model_container: 82
2023-02-28 02:14:17,496:INFO:_display_container: 38
2023-02-28 02:14:17,496:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-02-28 02:14:17,496:INFO:create_model() successfully completed......................................
2023-02-28 02:14:17,892:INFO:SubProcess create_model() end ==================================
2023-02-28 02:14:17,892:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for R2 is 0.7991
2023-02-28 02:14:17,892:INFO:ExtraTreesRegressor(bootstrap=True, max_depth=9, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123) result for R2 is 0.8381
2023-02-28 02:14:17,892:INFO:ExtraTreesRegressor(bootstrap=True, max_depth=9, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123) is best model
2023-02-28 02:14:17,892:INFO:choose_better completed
2023-02-28 02:14:17,923:INFO:_master_model_container: 82
2023-02-28 02:14:17,923:INFO:_display_container: 37
2023-02-28 02:14:17,923:INFO:ExtraTreesRegressor(bootstrap=True, max_depth=9, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123)
2023-02-28 02:14:17,923:INFO:tune_model() successfully completed......................................
2023-02-28 02:14:18,335:INFO:Initializing tune_model()
2023-02-28 02:14:18,347:INFO:tune_model(estimator=AdaBoostRegressor(random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>)
2023-02-28 02:14:18,347:INFO:Checking exceptions
2023-02-28 02:14:18,378:INFO:Copying training dataset
2023-02-28 02:14:18,378:INFO:Checking base model
2023-02-28 02:14:18,378:INFO:Base model : AdaBoost Regressor
2023-02-28 02:14:18,378:INFO:Declaring metric variables
2023-02-28 02:14:18,394:INFO:Defining Hyperparameters
2023-02-28 02:14:18,804:INFO:Tuning with n_jobs=-1
2023-02-28 02:14:18,804:INFO:Initializing RandomizedSearchCV
2023-02-28 02:14:23,053:INFO:best_params: {'actual_estimator__n_estimators': 240, 'actual_estimator__loss': 'linear', 'actual_estimator__learning_rate': 1e-06}
2023-02-28 02:14:23,053:INFO:Hyperparameter search completed
2023-02-28 02:14:23,053:INFO:SubProcess create_model() called ==================================
2023-02-28 02:14:23,053:INFO:Initializing create_model()
2023-02-28 02:14:23,053:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=AdaBoostRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB072E9F10>, model_only=True, return_train_score=False, kwargs={'n_estimators': 240, 'loss': 'linear', 'learning_rate': 1e-06})
2023-02-28 02:14:23,053:INFO:Checking exceptions
2023-02-28 02:14:23,053:INFO:Importing libraries
2023-02-28 02:14:23,053:INFO:Copying training dataset
2023-02-28 02:14:23,069:INFO:Defining folds
2023-02-28 02:14:23,069:INFO:Declaring metric variables
2023-02-28 02:14:23,069:INFO:Importing untrained model
2023-02-28 02:14:23,069:INFO:Declaring custom model
2023-02-28 02:14:23,084:INFO:str Imported successfully
2023-02-28 02:14:23,084:INFO:Starting cross validation
2023-02-28 02:14:23,100:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:14:23,870:INFO:Calculating mean and std
2023-02-28 02:14:23,870:INFO:Creating metrics dataframe
2023-02-28 02:14:23,886:INFO:Finalizing model
2023-02-28 02:14:24,142:INFO:Uploading results into container
2023-02-28 02:14:24,142:INFO:Uploading model into container now
2023-02-28 02:14:24,142:INFO:_master_model_container: 83
2023-02-28 02:14:24,142:INFO:_display_container: 38
2023-02-28 02:14:24,142:INFO:AdaBoostRegressor(learning_rate=1e-06, n_estimators=240, random_state=123)
2023-02-28 02:14:24,142:INFO:create_model() successfully completed......................................
2023-02-28 02:14:24,500:INFO:SubProcess create_model() end ==================================
2023-02-28 02:14:24,500:INFO:choose_better activated
2023-02-28 02:14:24,508:INFO:SubProcess create_model() called ==================================
2023-02-28 02:14:24,508:INFO:Initializing create_model()
2023-02-28 02:14:24,508:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=AdaBoostRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:14:24,508:INFO:Checking exceptions
2023-02-28 02:14:24,516:INFO:Importing libraries
2023-02-28 02:14:24,516:INFO:Copying training dataset
2023-02-28 02:14:24,521:INFO:Defining folds
2023-02-28 02:14:24,521:INFO:Declaring metric variables
2023-02-28 02:14:24,521:INFO:Importing untrained model
2023-02-28 02:14:24,522:INFO:Declaring custom model
2023-02-28 02:14:24,523:INFO:str Imported successfully
2023-02-28 02:14:24,523:INFO:Starting cross validation
2023-02-28 02:14:24,524:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:14:25,070:INFO:Calculating mean and std
2023-02-28 02:14:25,070:INFO:Creating metrics dataframe
2023-02-28 02:14:25,078:INFO:Finalizing model
2023-02-28 02:14:25,257:INFO:Uploading results into container
2023-02-28 02:14:25,257:INFO:Uploading model into container now
2023-02-28 02:14:25,257:INFO:_master_model_container: 84
2023-02-28 02:14:25,257:INFO:_display_container: 39
2023-02-28 02:14:25,257:INFO:AdaBoostRegressor(random_state=123)
2023-02-28 02:14:25,257:INFO:create_model() successfully completed......................................
2023-02-28 02:14:25,624:INFO:SubProcess create_model() end ==================================
2023-02-28 02:14:25,624:INFO:AdaBoostRegressor(random_state=123) result for R2 is 0.7903
2023-02-28 02:14:25,624:INFO:AdaBoostRegressor(learning_rate=1e-06, n_estimators=240, random_state=123) result for R2 is 0.8335
2023-02-28 02:14:25,624:INFO:AdaBoostRegressor(learning_rate=1e-06, n_estimators=240, random_state=123) is best model
2023-02-28 02:14:25,624:INFO:choose_better completed
2023-02-28 02:14:25,653:INFO:_master_model_container: 84
2023-02-28 02:14:25,656:INFO:_display_container: 38
2023-02-28 02:14:25,657:INFO:AdaBoostRegressor(learning_rate=1e-06, n_estimators=240, random_state=123)
2023-02-28 02:14:25,657:INFO:tune_model() successfully completed......................................
2023-02-28 02:14:26,020:INFO:Initializing tune_model()
2023-02-28 02:14:26,020:INFO:tune_model(estimator=HuberRegressor(), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>)
2023-02-28 02:14:26,020:INFO:Checking exceptions
2023-02-28 02:14:26,054:INFO:Copying training dataset
2023-02-28 02:14:26,058:INFO:Checking base model
2023-02-28 02:14:26,058:INFO:Base model : Huber Regressor
2023-02-28 02:14:26,058:INFO:Declaring metric variables
2023-02-28 02:14:26,073:INFO:Defining Hyperparameters
2023-02-28 02:14:26,431:INFO:Tuning with n_jobs=-1
2023-02-28 02:14:26,431:INFO:Initializing RandomizedSearchCV
2023-02-28 02:14:26,860:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:26,957:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:27,007:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:27,056:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:27,079:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:27,125:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:27,125:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:27,187:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:27,187:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:27,255:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:27,282:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:27,298:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:27,377:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:27,378:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:27,459:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:27,491:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:27,503:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:27,534:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:27,534:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:27,571:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:27,586:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:27,586:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:27,614:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:27,662:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:27,662:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:27,740:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:27,776:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:27,820:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:27,883:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:27,931:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:28,083:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:28,159:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:28,161:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:28,238:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:28,280:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:28,313:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:28,329:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:28,379:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:28,449:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:28,449:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:28,476:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:28,486:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:28,507:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:28,519:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:28,535:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:28,539:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:28,541:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:28,591:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:28,710:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:28,726:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:28,726:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:28,776:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:28,802:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:28,859:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:28,880:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:28,880:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:28,903:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:28,930:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:28,948:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:29,007:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:29,029:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:29,038:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:29,072:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:29,117:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:29,133:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:29,180:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:29,227:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:29,270:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:29,301:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:29,314:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:29,549:INFO:best_params: {'actual_estimator__fit_intercept': False, 'actual_estimator__epsilon': 1.4, 'actual_estimator__alpha': 0.001}
2023-02-28 02:14:29,550:INFO:Hyperparameter search completed
2023-02-28 02:14:29,550:INFO:SubProcess create_model() called ==================================
2023-02-28 02:14:29,552:INFO:Initializing create_model()
2023-02-28 02:14:29,552:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB08A01AF0>, model_only=True, return_train_score=False, kwargs={'fit_intercept': False, 'epsilon': 1.4, 'alpha': 0.001})
2023-02-28 02:14:29,553:INFO:Checking exceptions
2023-02-28 02:14:29,553:INFO:Importing libraries
2023-02-28 02:14:29,554:INFO:Copying training dataset
2023-02-28 02:14:29,562:INFO:Defining folds
2023-02-28 02:14:29,562:INFO:Declaring metric variables
2023-02-28 02:14:29,562:INFO:Importing untrained model
2023-02-28 02:14:29,562:INFO:Declaring custom model
2023-02-28 02:14:29,575:INFO:Huber Regressor Imported successfully
2023-02-28 02:14:29,591:INFO:Starting cross validation
2023-02-28 02:14:29,591:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:14:29,850:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:29,877:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:29,908:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:29,924:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:29,926:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:29,940:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:29,956:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:30,008:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:30,019:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:30,113:INFO:Calculating mean and std
2023-02-28 02:14:30,113:INFO:Creating metrics dataframe
2023-02-28 02:14:30,113:INFO:Finalizing model
2023-02-28 02:14:30,333:INFO:Uploading results into container
2023-02-28 02:14:30,333:INFO:Uploading model into container now
2023-02-28 02:14:30,333:INFO:_master_model_container: 85
2023-02-28 02:14:30,333:INFO:_display_container: 39
2023-02-28 02:14:30,333:INFO:HuberRegressor(alpha=0.001, epsilon=1.4, fit_intercept=False)
2023-02-28 02:14:30,333:INFO:create_model() successfully completed......................................
2023-02-28 02:14:30,697:INFO:SubProcess create_model() end ==================================
2023-02-28 02:14:30,697:INFO:choose_better activated
2023-02-28 02:14:30,697:INFO:SubProcess create_model() called ==================================
2023-02-28 02:14:30,712:INFO:Initializing create_model()
2023-02-28 02:14:30,712:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:14:30,712:INFO:Checking exceptions
2023-02-28 02:14:30,715:INFO:Importing libraries
2023-02-28 02:14:30,715:INFO:Copying training dataset
2023-02-28 02:14:30,715:INFO:Defining folds
2023-02-28 02:14:30,715:INFO:Declaring metric variables
2023-02-28 02:14:30,715:INFO:Importing untrained model
2023-02-28 02:14:30,715:INFO:Declaring custom model
2023-02-28 02:14:30,715:INFO:Huber Regressor Imported successfully
2023-02-28 02:14:30,715:INFO:Starting cross validation
2023-02-28 02:14:30,715:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:14:30,995:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:31,031:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:31,031:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:31,059:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:31,076:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:31,076:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:31,107:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:31,132:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:31,153:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:31,156:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:14:31,263:INFO:Calculating mean and std
2023-02-28 02:14:31,263:INFO:Creating metrics dataframe
2023-02-28 02:14:31,263:INFO:Finalizing model
2023-02-28 02:14:31,502:INFO:Uploading results into container
2023-02-28 02:14:31,502:INFO:Uploading model into container now
2023-02-28 02:14:31,502:INFO:_master_model_container: 86
2023-02-28 02:14:31,502:INFO:_display_container: 40
2023-02-28 02:14:31,502:INFO:HuberRegressor()
2023-02-28 02:14:31,502:INFO:create_model() successfully completed......................................
2023-02-28 02:14:31,883:INFO:SubProcess create_model() end ==================================
2023-02-28 02:14:31,883:INFO:HuberRegressor() result for R2 is 0.6544
2023-02-28 02:14:31,883:INFO:HuberRegressor(alpha=0.001, epsilon=1.4, fit_intercept=False) result for R2 is 0.6902
2023-02-28 02:14:31,883:INFO:HuberRegressor(alpha=0.001, epsilon=1.4, fit_intercept=False) is best model
2023-02-28 02:14:31,883:INFO:choose_better completed
2023-02-28 02:14:31,899:INFO:_master_model_container: 86
2023-02-28 02:14:31,899:INFO:_display_container: 39
2023-02-28 02:14:31,899:INFO:HuberRegressor(alpha=0.001, epsilon=1.4, fit_intercept=False)
2023-02-28 02:14:31,899:INFO:tune_model() successfully completed......................................
2023-02-28 02:15:53,029:INFO:Initializing blend_models()
2023-02-28 02:15:53,029:INFO:blend_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator_list=[GradientBoostingRegressor(random_state=123), RandomForestRegressor(max_depth=9, min_impurity_decrease=0.1,
                      min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                      random_state=123), LGBMRegressor(random_state=123), ExtraTreesRegressor(bootstrap=True, max_depth=9, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123), AdaBoostRegressor(learning_rate=1e-06, n_estimators=240, random_state=123), HuberRegressor(alpha=0.001, epsilon=1.4, fit_intercept=False), BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                 random_state=123)], fold=None, round=4, choose_better=False, optimize=R2, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-02-28 02:15:53,029:INFO:Checking exceptions
2023-02-28 02:15:53,056:INFO:Importing libraries
2023-02-28 02:15:53,056:INFO:Copying training dataset
2023-02-28 02:15:53,062:INFO:Getting model names
2023-02-28 02:15:53,066:INFO:SubProcess create_model() called ==================================
2023-02-28 02:15:53,079:INFO:Initializing create_model()
2023-02-28 02:15:53,079:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(random_state=123)),
                            ('Random Forest Regressor',
                             RandomForestRegressor(max_depth=9,
                                                   min_impurity_decrease=0.1,
                                                   min_samples_leaf=4,
                                                   min_samples_split=7,
                                                   n_jobs=-1,
                                                   random_state=123)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(random_state=123)),
                            ('Extra Trees Regressor',
                             ExtraTr...
                                                 min_impurity_decrease=0.1,
                                                 min_samples_leaf=4,
                                                 min_samples_split=7, n_jobs=-1,
                                                 random_state=123)),
                            ('str',
                             AdaBoostRegressor(learning_rate=1e-06,
                                               n_estimators=240,
                                               random_state=123)),
                            ('Huber Regressor',
                             HuberRegressor(alpha=0.001, epsilon=1.4,
                                            fit_intercept=False)),
                            ('str_1',
                             BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                                              random_state=123))],
                n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB038C42B0>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:15:53,079:INFO:Checking exceptions
2023-02-28 02:15:53,079:INFO:Importing libraries
2023-02-28 02:15:53,079:INFO:Copying training dataset
2023-02-28 02:15:53,084:INFO:Defining folds
2023-02-28 02:15:53,084:INFO:Declaring metric variables
2023-02-28 02:15:53,087:INFO:Importing untrained model
2023-02-28 02:15:53,087:INFO:Declaring custom model
2023-02-28 02:15:53,097:INFO:Voting Regressor Imported successfully
2023-02-28 02:15:53,103:INFO:Starting cross validation
2023-02-28 02:15:53,107:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:15:53,679:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:15:53,739:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:15:53,821:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:15:53,845:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:15:53,910:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:15:53,921:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:15:53,951:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:15:53,951:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:15:53,973:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:15:54,098:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:15:56,531:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-28 02:15:56,536:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-28 02:15:56,570:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-28 02:15:56,570:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-28 02:15:56,576:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-28 02:15:56,600:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-28 02:15:56,608:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-28 02:15:56,641:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-28 02:15:56,680:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-28 02:15:56,706:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-28 02:15:57,738:INFO:Calculating mean and std
2023-02-28 02:15:57,738:INFO:Creating metrics dataframe
2023-02-28 02:15:57,746:INFO:Finalizing model
2023-02-28 02:15:57,851:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:15:59,273:INFO:Uploading results into container
2023-02-28 02:15:59,274:INFO:Uploading model into container now
2023-02-28 02:15:59,274:INFO:_master_model_container: 87
2023-02-28 02:15:59,275:INFO:_display_container: 40
2023-02-28 02:15:59,277:INFO:VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(random_state=123)),
                            ('Random Forest Regressor',
                             RandomForestRegressor(max_depth=9,
                                                   min_impurity_decrease=0.1,
                                                   min_samples_leaf=4,
                                                   min_samples_split=7,
                                                   n_jobs=-1,
                                                   random_state=123)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(random_state=123)),
                            ('Extra Trees Regressor',
                             ExtraTr...
                                                 min_impurity_decrease=0.1,
                                                 min_samples_leaf=4,
                                                 min_samples_split=7, n_jobs=-1,
                                                 random_state=123)),
                            ('str',
                             AdaBoostRegressor(learning_rate=1e-06,
                                               n_estimators=240,
                                               random_state=123)),
                            ('Huber Regressor',
                             HuberRegressor(alpha=0.001, epsilon=1.4,
                                            fit_intercept=False)),
                            ('str_1',
                             BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                                              random_state=123))],
                n_jobs=-1)
2023-02-28 02:15:59,277:INFO:create_model() successfully completed......................................
2023-02-28 02:15:59,577:INFO:SubProcess create_model() end ==================================
2023-02-28 02:15:59,594:INFO:_master_model_container: 87
2023-02-28 02:15:59,595:INFO:_display_container: 40
2023-02-28 02:15:59,602:INFO:VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(random_state=123)),
                            ('Random Forest Regressor',
                             RandomForestRegressor(max_depth=9,
                                                   min_impurity_decrease=0.1,
                                                   min_samples_leaf=4,
                                                   min_samples_split=7,
                                                   n_jobs=-1,
                                                   random_state=123)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(random_state=123)),
                            ('Extra Trees Regressor',
                             ExtraTr...
                                                 min_impurity_decrease=0.1,
                                                 min_samples_leaf=4,
                                                 min_samples_split=7, n_jobs=-1,
                                                 random_state=123)),
                            ('str',
                             AdaBoostRegressor(learning_rate=1e-06,
                                               n_estimators=240,
                                               random_state=123)),
                            ('Huber Regressor',
                             HuberRegressor(alpha=0.001, epsilon=1.4,
                                            fit_intercept=False)),
                            ('str_1',
                             BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                                              random_state=123))],
                n_jobs=-1)
2023-02-28 02:15:59,602:INFO:blend_models() successfully completed......................................
2023-02-28 02:16:27,313:INFO:Initializing blend_models()
2023-02-28 02:16:27,313:INFO:blend_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator_list=[GradientBoostingRegressor(random_state=123), RandomForestRegressor(max_depth=9, min_impurity_decrease=0.1,
                      min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                      random_state=123), LGBMRegressor(random_state=123), ExtraTreesRegressor(bootstrap=True, max_depth=9, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123), AdaBoostRegressor(learning_rate=1e-06, n_estimators=240, random_state=123), HuberRegressor(alpha=0.001, epsilon=1.4, fit_intercept=False), BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                 random_state=123)], fold=None, round=4, choose_better=True, optimize=R2, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-02-28 02:16:27,313:INFO:Checking exceptions
2023-02-28 02:16:27,334:INFO:Importing libraries
2023-02-28 02:16:27,334:INFO:Copying training dataset
2023-02-28 02:16:27,339:INFO:Getting model names
2023-02-28 02:16:27,343:INFO:SubProcess create_model() called ==================================
2023-02-28 02:16:27,351:INFO:Initializing create_model()
2023-02-28 02:16:27,351:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(random_state=123)),
                            ('Random Forest Regressor',
                             RandomForestRegressor(max_depth=9,
                                                   min_impurity_decrease=0.1,
                                                   min_samples_leaf=4,
                                                   min_samples_split=7,
                                                   n_jobs=-1,
                                                   random_state=123)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(random_state=123)),
                            ('Extra Trees Regressor',
                             ExtraTr...
                                                 min_impurity_decrease=0.1,
                                                 min_samples_leaf=4,
                                                 min_samples_split=7, n_jobs=-1,
                                                 random_state=123)),
                            ('str',
                             AdaBoostRegressor(learning_rate=1e-06,
                                               n_estimators=240,
                                               random_state=123)),
                            ('Huber Regressor',
                             HuberRegressor(alpha=0.001, epsilon=1.4,
                                            fit_intercept=False)),
                            ('str_1',
                             BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                                              random_state=123))],
                n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB070CBD60>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:16:27,351:INFO:Checking exceptions
2023-02-28 02:16:27,351:INFO:Importing libraries
2023-02-28 02:16:27,351:INFO:Copying training dataset
2023-02-28 02:16:27,360:INFO:Defining folds
2023-02-28 02:16:27,360:INFO:Declaring metric variables
2023-02-28 02:16:27,360:INFO:Importing untrained model
2023-02-28 02:16:27,360:INFO:Declaring custom model
2023-02-28 02:16:27,370:INFO:Voting Regressor Imported successfully
2023-02-28 02:16:27,378:INFO:Starting cross validation
2023-02-28 02:16:27,378:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:16:29,004:INFO:Calculating mean and std
2023-02-28 02:16:29,004:INFO:Creating metrics dataframe
2023-02-28 02:16:29,012:INFO:Finalizing model
2023-02-28 02:16:29,264:INFO:Uploading results into container
2023-02-28 02:16:29,273:INFO:Uploading model into container now
2023-02-28 02:16:29,273:INFO:_master_model_container: 88
2023-02-28 02:16:29,273:INFO:_display_container: 41
2023-02-28 02:16:29,280:INFO:VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(random_state=123)),
                            ('Random Forest Regressor',
                             RandomForestRegressor(max_depth=9,
                                                   min_impurity_decrease=0.1,
                                                   min_samples_leaf=4,
                                                   min_samples_split=7,
                                                   n_jobs=-1,
                                                   random_state=123)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(random_state=123)),
                            ('Extra Trees Regressor',
                             ExtraTr...
                                                 min_impurity_decrease=0.1,
                                                 min_samples_leaf=4,
                                                 min_samples_split=7, n_jobs=-1,
                                                 random_state=123)),
                            ('str',
                             AdaBoostRegressor(learning_rate=1e-06,
                                               n_estimators=240,
                                               random_state=123)),
                            ('Huber Regressor',
                             HuberRegressor(alpha=0.001, epsilon=1.4,
                                            fit_intercept=False)),
                            ('str_1',
                             BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                                              random_state=123))],
                n_jobs=-1)
2023-02-28 02:16:29,280:INFO:create_model() successfully completed......................................
2023-02-28 02:16:29,608:INFO:SubProcess create_model() end ==================================
2023-02-28 02:16:29,608:INFO:choose_better activated
2023-02-28 02:16:29,623:INFO:VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(random_state=123)),
                            ('Random Forest Regressor',
                             RandomForestRegressor(max_depth=9,
                                                   min_impurity_decrease=0.1,
                                                   min_samples_leaf=4,
                                                   min_samples_split=7,
                                                   n_jobs=-1,
                                                   random_state=123)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(random_state=123)),
                            ('Extra Trees Regressor',
                             ExtraTr...
                                                 min_impurity_decrease=0.1,
                                                 min_samples_leaf=4,
                                                 min_samples_split=7, n_jobs=-1,
                                                 random_state=123)),
                            ('str',
                             AdaBoostRegressor(learning_rate=1e-06,
                                               n_estimators=240,
                                               random_state=123)),
                            ('Huber Regressor',
                             HuberRegressor(alpha=0.001, epsilon=1.4,
                                            fit_intercept=False)),
                            ('str_1',
                             BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                                              random_state=123))],
                n_jobs=-1) result for R2 is 0.8398
2023-02-28 02:16:29,623:INFO:SubProcess create_model() called ==================================
2023-02-28 02:16:29,623:INFO:Initializing create_model()
2023-02-28 02:16:29,623:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:16:29,623:INFO:Checking exceptions
2023-02-28 02:16:29,623:INFO:Importing libraries
2023-02-28 02:16:29,623:INFO:Copying training dataset
2023-02-28 02:16:29,623:INFO:Defining folds
2023-02-28 02:16:29,623:INFO:Declaring metric variables
2023-02-28 02:16:29,623:INFO:Importing untrained model
2023-02-28 02:16:29,623:INFO:Declaring custom model
2023-02-28 02:16:29,623:INFO:Gradient Boosting Regressor Imported successfully
2023-02-28 02:16:29,631:INFO:Starting cross validation
2023-02-28 02:16:29,631:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:16:29,978:INFO:Calculating mean and std
2023-02-28 02:16:29,978:INFO:Creating metrics dataframe
2023-02-28 02:16:29,978:INFO:Finalizing model
2023-02-28 02:16:30,137:INFO:Uploading results into container
2023-02-28 02:16:30,137:INFO:Uploading model into container now
2023-02-28 02:16:30,137:INFO:_master_model_container: 89
2023-02-28 02:16:30,137:INFO:_display_container: 42
2023-02-28 02:16:30,141:INFO:GradientBoostingRegressor(random_state=123)
2023-02-28 02:16:30,141:INFO:create_model() successfully completed......................................
2023-02-28 02:16:30,468:INFO:SubProcess create_model() end ==================================
2023-02-28 02:16:30,468:INFO:GradientBoostingRegressor(random_state=123) result for R2 is 0.832
2023-02-28 02:16:30,468:INFO:SubProcess create_model() called ==================================
2023-02-28 02:16:30,468:INFO:Initializing create_model()
2023-02-28 02:16:30,468:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=RandomForestRegressor(max_depth=9, min_impurity_decrease=0.1,
                      min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                      random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:16:30,468:INFO:Checking exceptions
2023-02-28 02:16:30,468:INFO:Importing libraries
2023-02-28 02:16:30,471:INFO:Copying training dataset
2023-02-28 02:16:30,472:INFO:Defining folds
2023-02-28 02:16:30,472:INFO:Declaring metric variables
2023-02-28 02:16:30,472:INFO:Importing untrained model
2023-02-28 02:16:30,472:INFO:Declaring custom model
2023-02-28 02:16:30,472:INFO:Random Forest Regressor Imported successfully
2023-02-28 02:16:30,472:INFO:Starting cross validation
2023-02-28 02:16:30,472:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:16:30,802:INFO:Calculating mean and std
2023-02-28 02:16:30,802:INFO:Creating metrics dataframe
2023-02-28 02:16:30,802:INFO:Finalizing model
2023-02-28 02:16:30,891:INFO:Uploading results into container
2023-02-28 02:16:30,891:INFO:Uploading model into container now
2023-02-28 02:16:30,891:INFO:_master_model_container: 90
2023-02-28 02:16:30,891:INFO:_display_container: 42
2023-02-28 02:16:30,891:INFO:RandomForestRegressor(max_depth=9, min_impurity_decrease=0.1,
                      min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                      random_state=123)
2023-02-28 02:16:30,891:INFO:create_model() successfully completed......................................
2023-02-28 02:16:31,182:INFO:SubProcess create_model() end ==================================
2023-02-28 02:16:31,182:INFO:RandomForestRegressor(max_depth=9, min_impurity_decrease=0.1,
                      min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                      random_state=123) result for R2 is 0.8386
2023-02-28 02:16:31,182:INFO:SubProcess create_model() called ==================================
2023-02-28 02:16:31,182:INFO:Initializing create_model()
2023-02-28 02:16:31,190:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=LGBMRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:16:31,190:INFO:Checking exceptions
2023-02-28 02:16:31,190:INFO:Importing libraries
2023-02-28 02:16:31,190:INFO:Copying training dataset
2023-02-28 02:16:31,190:INFO:Defining folds
2023-02-28 02:16:31,190:INFO:Declaring metric variables
2023-02-28 02:16:31,190:INFO:Importing untrained model
2023-02-28 02:16:31,190:INFO:Declaring custom model
2023-02-28 02:16:31,190:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-28 02:16:31,190:INFO:Starting cross validation
2023-02-28 02:16:31,190:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:16:31,481:INFO:Calculating mean and std
2023-02-28 02:16:31,481:INFO:Creating metrics dataframe
2023-02-28 02:16:31,481:INFO:Finalizing model
2023-02-28 02:16:31,554:INFO:Uploading results into container
2023-02-28 02:16:31,554:INFO:Uploading model into container now
2023-02-28 02:16:31,554:INFO:_master_model_container: 91
2023-02-28 02:16:31,554:INFO:_display_container: 42
2023-02-28 02:16:31,554:INFO:LGBMRegressor(random_state=123)
2023-02-28 02:16:31,554:INFO:create_model() successfully completed......................................
2023-02-28 02:16:31,877:INFO:SubProcess create_model() end ==================================
2023-02-28 02:16:31,877:INFO:LGBMRegressor(random_state=123) result for R2 is 0.8149
2023-02-28 02:16:31,877:INFO:SubProcess create_model() called ==================================
2023-02-28 02:16:31,877:INFO:Initializing create_model()
2023-02-28 02:16:31,877:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=ExtraTreesRegressor(bootstrap=True, max_depth=9, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:16:31,877:INFO:Checking exceptions
2023-02-28 02:16:31,877:INFO:Importing libraries
2023-02-28 02:16:31,877:INFO:Copying training dataset
2023-02-28 02:16:31,885:INFO:Defining folds
2023-02-28 02:16:31,885:INFO:Declaring metric variables
2023-02-28 02:16:31,885:INFO:Importing untrained model
2023-02-28 02:16:31,885:INFO:Declaring custom model
2023-02-28 02:16:31,886:INFO:Extra Trees Regressor Imported successfully
2023-02-28 02:16:31,886:INFO:Starting cross validation
2023-02-28 02:16:31,887:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:16:32,238:INFO:Calculating mean and std
2023-02-28 02:16:32,238:INFO:Creating metrics dataframe
2023-02-28 02:16:32,238:INFO:Finalizing model
2023-02-28 02:16:32,331:INFO:Uploading results into container
2023-02-28 02:16:32,331:INFO:Uploading model into container now
2023-02-28 02:16:32,331:INFO:_master_model_container: 92
2023-02-28 02:16:32,335:INFO:_display_container: 42
2023-02-28 02:16:32,335:INFO:ExtraTreesRegressor(bootstrap=True, max_depth=9, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123)
2023-02-28 02:16:32,335:INFO:create_model() successfully completed......................................
2023-02-28 02:16:32,618:INFO:SubProcess create_model() end ==================================
2023-02-28 02:16:32,619:INFO:ExtraTreesRegressor(bootstrap=True, max_depth=9, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123) result for R2 is 0.8381
2023-02-28 02:16:32,619:INFO:SubProcess create_model() called ==================================
2023-02-28 02:16:32,619:INFO:Initializing create_model()
2023-02-28 02:16:32,619:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=AdaBoostRegressor(learning_rate=1e-06, n_estimators=240, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:16:32,619:INFO:Checking exceptions
2023-02-28 02:16:32,621:INFO:Importing libraries
2023-02-28 02:16:32,621:INFO:Copying training dataset
2023-02-28 02:16:32,621:INFO:Defining folds
2023-02-28 02:16:32,621:INFO:Declaring metric variables
2023-02-28 02:16:32,621:INFO:Importing untrained model
2023-02-28 02:16:32,621:INFO:Declaring custom model
2023-02-28 02:16:32,624:INFO:str Imported successfully
2023-02-28 02:16:32,624:INFO:Starting cross validation
2023-02-28 02:16:32,624:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:16:33,060:INFO:Calculating mean and std
2023-02-28 02:16:33,068:INFO:Creating metrics dataframe
2023-02-28 02:16:33,068:INFO:Finalizing model
2023-02-28 02:16:33,182:INFO:Uploading results into container
2023-02-28 02:16:33,182:INFO:Uploading model into container now
2023-02-28 02:16:33,182:INFO:_master_model_container: 93
2023-02-28 02:16:33,182:INFO:_display_container: 42
2023-02-28 02:16:33,182:INFO:AdaBoostRegressor(learning_rate=1e-06, n_estimators=240, random_state=123)
2023-02-28 02:16:33,182:INFO:create_model() successfully completed......................................
2023-02-28 02:16:33,486:INFO:SubProcess create_model() end ==================================
2023-02-28 02:16:33,486:INFO:AdaBoostRegressor(learning_rate=1e-06, n_estimators=240, random_state=123) result for R2 is 0.8335
2023-02-28 02:16:33,486:INFO:SubProcess create_model() called ==================================
2023-02-28 02:16:33,486:INFO:Initializing create_model()
2023-02-28 02:16:33,486:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=HuberRegressor(alpha=0.001, epsilon=1.4, fit_intercept=False), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:16:33,486:INFO:Checking exceptions
2023-02-28 02:16:33,486:INFO:Importing libraries
2023-02-28 02:16:33,486:INFO:Copying training dataset
2023-02-28 02:16:33,486:INFO:Defining folds
2023-02-28 02:16:33,486:INFO:Declaring metric variables
2023-02-28 02:16:33,493:INFO:Importing untrained model
2023-02-28 02:16:33,493:INFO:Declaring custom model
2023-02-28 02:16:33,493:INFO:Huber Regressor Imported successfully
2023-02-28 02:16:33,493:INFO:Starting cross validation
2023-02-28 02:16:33,493:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:16:33,623:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:16:33,654:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:16:33,656:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:16:33,664:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:16:33,672:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:16:33,689:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:16:33,704:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:16:33,712:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:16:33,729:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:16:33,769:INFO:Calculating mean and std
2023-02-28 02:16:33,778:INFO:Creating metrics dataframe
2023-02-28 02:16:33,778:INFO:Finalizing model
2023-02-28 02:16:33,868:INFO:Uploading results into container
2023-02-28 02:16:33,868:INFO:Uploading model into container now
2023-02-28 02:16:33,868:INFO:_master_model_container: 94
2023-02-28 02:16:33,868:INFO:_display_container: 42
2023-02-28 02:16:33,868:INFO:HuberRegressor(alpha=0.001, epsilon=1.4, fit_intercept=False)
2023-02-28 02:16:33,868:INFO:create_model() successfully completed......................................
2023-02-28 02:16:34,178:INFO:SubProcess create_model() end ==================================
2023-02-28 02:16:34,178:INFO:HuberRegressor(alpha=0.001, epsilon=1.4, fit_intercept=False) result for R2 is 0.6902
2023-02-28 02:16:34,178:INFO:SubProcess create_model() called ==================================
2023-02-28 02:16:34,178:INFO:Initializing create_model()
2023-02-28 02:16:34,178:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:16:34,178:INFO:Checking exceptions
2023-02-28 02:16:34,178:INFO:Importing libraries
2023-02-28 02:16:34,178:INFO:Copying training dataset
2023-02-28 02:16:34,186:INFO:Defining folds
2023-02-28 02:16:34,186:INFO:Declaring metric variables
2023-02-28 02:16:34,186:INFO:Importing untrained model
2023-02-28 02:16:34,186:INFO:Declaring custom model
2023-02-28 02:16:34,186:INFO:str Imported successfully
2023-02-28 02:16:34,186:INFO:Starting cross validation
2023-02-28 02:16:34,186:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:16:35,176:INFO:Calculating mean and std
2023-02-28 02:16:35,176:INFO:Creating metrics dataframe
2023-02-28 02:16:35,181:INFO:Finalizing model
2023-02-28 02:16:35,298:INFO:Uploading results into container
2023-02-28 02:16:35,298:INFO:Uploading model into container now
2023-02-28 02:16:35,298:INFO:_master_model_container: 95
2023-02-28 02:16:35,298:INFO:_display_container: 42
2023-02-28 02:16:35,298:INFO:BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                 random_state=123)
2023-02-28 02:16:35,298:INFO:create_model() successfully completed......................................
2023-02-28 02:16:35,590:INFO:SubProcess create_model() end ==================================
2023-02-28 02:16:35,590:INFO:BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                 random_state=123) result for R2 is 0.8395
2023-02-28 02:16:35,603:INFO:VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(random_state=123)),
                            ('Random Forest Regressor',
                             RandomForestRegressor(max_depth=9,
                                                   min_impurity_decrease=0.1,
                                                   min_samples_leaf=4,
                                                   min_samples_split=7,
                                                   n_jobs=-1,
                                                   random_state=123)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(random_state=123)),
                            ('Extra Trees Regressor',
                             ExtraTr...
                                                 min_impurity_decrease=0.1,
                                                 min_samples_leaf=4,
                                                 min_samples_split=7, n_jobs=-1,
                                                 random_state=123)),
                            ('str',
                             AdaBoostRegressor(learning_rate=1e-06,
                                               n_estimators=240,
                                               random_state=123)),
                            ('Huber Regressor',
                             HuberRegressor(alpha=0.001, epsilon=1.4,
                                            fit_intercept=False)),
                            ('str_1',
                             BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                                              random_state=123))],
                n_jobs=-1) is best model
2023-02-28 02:16:35,603:INFO:choose_better completed
2023-02-28 02:16:35,606:INFO:_master_model_container: 95
2023-02-28 02:16:35,606:INFO:_display_container: 41
2023-02-28 02:16:35,622:INFO:VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(random_state=123)),
                            ('Random Forest Regressor',
                             RandomForestRegressor(max_depth=9,
                                                   min_impurity_decrease=0.1,
                                                   min_samples_leaf=4,
                                                   min_samples_split=7,
                                                   n_jobs=-1,
                                                   random_state=123)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(random_state=123)),
                            ('Extra Trees Regressor',
                             ExtraTr...
                                                 min_impurity_decrease=0.1,
                                                 min_samples_leaf=4,
                                                 min_samples_split=7, n_jobs=-1,
                                                 random_state=123)),
                            ('str',
                             AdaBoostRegressor(learning_rate=1e-06,
                                               n_estimators=240,
                                               random_state=123)),
                            ('Huber Regressor',
                             HuberRegressor(alpha=0.001, epsilon=1.4,
                                            fit_intercept=False)),
                            ('str_1',
                             BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                                              random_state=123))],
                n_jobs=-1)
2023-02-28 02:16:35,622:INFO:blend_models() successfully completed......................................
2023-02-28 02:17:04,478:INFO:Initializing stack_models()
2023-02-28 02:17:04,478:INFO:stack_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator_list=[GradientBoostingRegressor(random_state=123), RandomForestRegressor(max_depth=9, min_impurity_decrease=0.1,
                      min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                      random_state=123), LGBMRegressor(random_state=123), ExtraTreesRegressor(bootstrap=True, max_depth=9, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123), AdaBoostRegressor(learning_rate=1e-06, n_estimators=240, random_state=123), HuberRegressor(alpha=0.001, epsilon=1.4, fit_intercept=False), BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                 random_state=123)], meta_model=None, meta_model_fold=5, fold=None, round=4, method=auto, restack=False, choose_better=True, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-02-28 02:17:04,478:INFO:Checking exceptions
2023-02-28 02:17:04,479:INFO:Defining meta model
2023-02-28 02:17:04,501:INFO:Getting model names
2023-02-28 02:17:04,502:INFO:[('Gradient Boosting Regressor', GradientBoostingRegressor(random_state=123)), ('Random Forest Regressor', RandomForestRegressor(max_depth=9, min_impurity_decrease=0.1,
                      min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                      random_state=123)), ('Light Gradient Boosting Machine', LGBMRegressor(random_state=123)), ('Extra Trees Regressor', ExtraTreesRegressor(bootstrap=True, max_depth=9, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123)), ('str', AdaBoostRegressor(learning_rate=1e-06, n_estimators=240, random_state=123)), ('Huber Regressor', HuberRegressor(alpha=0.001, epsilon=1.4, fit_intercept=False)), ('str_1', BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                 random_state=123))]
2023-02-28 02:17:04,509:INFO:SubProcess create_model() called ==================================
2023-02-28 02:17:04,518:INFO:Initializing create_model()
2023-02-28 02:17:04,518:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=StackingRegressor(cv=5,
                  estimators=[('Gradient Boosting Regressor',
                               GradientBoostingRegressor(random_state=123)),
                              ('Random Forest Regressor',
                               RandomForestRegressor(max_depth=9,
                                                     min_impurity_decrease=0.1,
                                                     min_samples_leaf=4,
                                                     min_samples_split=7,
                                                     n_jobs=-1,
                                                     random_state=123)),
                              ('Light Gradient Boosting Machine',
                               LGBMRegressor(random_state=123)),
                              ('Extra Trees Regressor',...
                                                   min_samples_split=7,
                                                   n_jobs=-1,
                                                   random_state=123)),
                              ('str',
                               AdaBoostRegressor(learning_rate=1e-06,
                                                 n_estimators=240,
                                                 random_state=123)),
                              ('Huber Regressor',
                               HuberRegressor(alpha=0.001, epsilon=1.4,
                                              fit_intercept=False)),
                              ('str_1',
                               BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                                                random_state=123))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AB08CC3A00>, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:17:04,518:INFO:Checking exceptions
2023-02-28 02:17:04,518:INFO:Importing libraries
2023-02-28 02:17:04,518:INFO:Copying training dataset
2023-02-28 02:17:04,523:INFO:Defining folds
2023-02-28 02:17:04,523:INFO:Declaring metric variables
2023-02-28 02:17:04,523:INFO:Importing untrained model
2023-02-28 02:17:04,523:INFO:Declaring custom model
2023-02-28 02:17:04,535:INFO:Stacking Regressor Imported successfully
2023-02-28 02:17:04,543:INFO:Starting cross validation
2023-02-28 02:17:04,543:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:17:05,127:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:05,167:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:05,175:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:05,200:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:05,224:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:05,239:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:05,247:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:05,264:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:05,264:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:05,507:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:07,422:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:07,426:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:07,457:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:07,509:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:07,560:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:07,570:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:07,586:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:07,602:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:07,639:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:07,651:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:07,788:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:07,875:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:07,875:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:07,922:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:08,026:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:08,056:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:08,067:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:08,100:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:08,179:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:08,186:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:08,235:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:08,334:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:08,383:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:08,509:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:08,509:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:08,582:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:08,613:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:08,641:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:08,684:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:08,707:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:08,712:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:08,840:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:08,903:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:08,998:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:09,019:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:09,046:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:09,052:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:09,110:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:09,128:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:09,167:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:09,197:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:09,315:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:09,448:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:09,547:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:09,555:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:09,572:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:09,583:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:09,596:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:09,605:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:09,676:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:19,154:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-28 02:17:19,154:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-28 02:17:19,170:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-28 02:17:19,225:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-28 02:17:19,272:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-28 02:17:19,358:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-28 02:17:19,399:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-28 02:17:19,572:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-28 02:17:19,572:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-02-28 02:17:21,038:INFO:Calculating mean and std
2023-02-28 02:17:21,038:INFO:Creating metrics dataframe
2023-02-28 02:17:21,038:INFO:Finalizing model
2023-02-28 02:17:21,257:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:23,037:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:23,042:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:23,053:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:23,053:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:23,069:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:29,722:INFO:Uploading results into container
2023-02-28 02:17:29,723:INFO:Uploading model into container now
2023-02-28 02:17:29,724:INFO:_master_model_container: 96
2023-02-28 02:17:29,724:INFO:_display_container: 42
2023-02-28 02:17:29,732:INFO:StackingRegressor(cv=5,
                  estimators=[('Gradient Boosting Regressor',
                               GradientBoostingRegressor(random_state=123)),
                              ('Random Forest Regressor',
                               RandomForestRegressor(max_depth=9,
                                                     min_impurity_decrease=0.1,
                                                     min_samples_leaf=4,
                                                     min_samples_split=7,
                                                     n_jobs=-1,
                                                     random_state=123)),
                              ('Light Gradient Boosting Machine',
                               LGBMRegressor(random_state=123)),
                              ('Extra Trees Regressor',...
                                                   min_samples_split=7,
                                                   n_jobs=-1,
                                                   random_state=123)),
                              ('str',
                               AdaBoostRegressor(learning_rate=1e-06,
                                                 n_estimators=240,
                                                 random_state=123)),
                              ('Huber Regressor',
                               HuberRegressor(alpha=0.001, epsilon=1.4,
                                              fit_intercept=False)),
                              ('str_1',
                               BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                                                random_state=123))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1)
2023-02-28 02:17:29,732:INFO:create_model() successfully completed......................................
2023-02-28 02:17:30,145:INFO:SubProcess create_model() end ==================================
2023-02-28 02:17:30,145:INFO:choose_better activated
2023-02-28 02:17:30,172:INFO:StackingRegressor(cv=5,
                  estimators=[('Gradient Boosting Regressor',
                               GradientBoostingRegressor(random_state=123)),
                              ('Random Forest Regressor',
                               RandomForestRegressor(max_depth=9,
                                                     min_impurity_decrease=0.1,
                                                     min_samples_leaf=4,
                                                     min_samples_split=7,
                                                     n_jobs=-1,
                                                     random_state=123)),
                              ('Light Gradient Boosting Machine',
                               LGBMRegressor(random_state=123)),
                              ('Extra Trees Regressor',...
                                                   min_samples_split=7,
                                                   n_jobs=-1,
                                                   random_state=123)),
                              ('str',
                               AdaBoostRegressor(learning_rate=1e-06,
                                                 n_estimators=240,
                                                 random_state=123)),
                              ('Huber Regressor',
                               HuberRegressor(alpha=0.001, epsilon=1.4,
                                              fit_intercept=False)),
                              ('str_1',
                               BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                                                random_state=123))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1) result for R2 is 0.846
2023-02-28 02:17:30,177:INFO:SubProcess create_model() called ==================================
2023-02-28 02:17:30,177:INFO:Initializing create_model()
2023-02-28 02:17:30,177:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:17:30,177:INFO:Checking exceptions
2023-02-28 02:17:30,177:INFO:Importing libraries
2023-02-28 02:17:30,177:INFO:Copying training dataset
2023-02-28 02:17:30,187:INFO:Defining folds
2023-02-28 02:17:30,187:INFO:Declaring metric variables
2023-02-28 02:17:30,187:INFO:Importing untrained model
2023-02-28 02:17:30,187:INFO:Declaring custom model
2023-02-28 02:17:30,187:INFO:Gradient Boosting Regressor Imported successfully
2023-02-28 02:17:30,187:INFO:Starting cross validation
2023-02-28 02:17:30,187:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:17:30,762:INFO:Calculating mean and std
2023-02-28 02:17:30,762:INFO:Creating metrics dataframe
2023-02-28 02:17:30,778:INFO:Finalizing model
2023-02-28 02:17:31,284:INFO:Uploading results into container
2023-02-28 02:17:31,284:INFO:Uploading model into container now
2023-02-28 02:17:31,284:INFO:_master_model_container: 97
2023-02-28 02:17:31,284:INFO:_display_container: 43
2023-02-28 02:17:31,284:INFO:GradientBoostingRegressor(random_state=123)
2023-02-28 02:17:31,284:INFO:create_model() successfully completed......................................
2023-02-28 02:17:31,679:INFO:SubProcess create_model() end ==================================
2023-02-28 02:17:31,679:INFO:GradientBoostingRegressor(random_state=123) result for R2 is 0.832
2023-02-28 02:17:31,679:INFO:SubProcess create_model() called ==================================
2023-02-28 02:17:31,679:INFO:Initializing create_model()
2023-02-28 02:17:31,679:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=RandomForestRegressor(max_depth=9, min_impurity_decrease=0.1,
                      min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                      random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:17:31,679:INFO:Checking exceptions
2023-02-28 02:17:31,679:INFO:Importing libraries
2023-02-28 02:17:31,679:INFO:Copying training dataset
2023-02-28 02:17:31,679:INFO:Defining folds
2023-02-28 02:17:31,679:INFO:Declaring metric variables
2023-02-28 02:17:31,679:INFO:Importing untrained model
2023-02-28 02:17:31,679:INFO:Declaring custom model
2023-02-28 02:17:31,679:INFO:Random Forest Regressor Imported successfully
2023-02-28 02:17:31,679:INFO:Starting cross validation
2023-02-28 02:17:31,679:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:17:32,311:INFO:Calculating mean and std
2023-02-28 02:17:32,311:INFO:Creating metrics dataframe
2023-02-28 02:17:32,311:INFO:Finalizing model
2023-02-28 02:17:32,484:INFO:Uploading results into container
2023-02-28 02:17:32,484:INFO:Uploading model into container now
2023-02-28 02:17:32,484:INFO:_master_model_container: 98
2023-02-28 02:17:32,484:INFO:_display_container: 43
2023-02-28 02:17:32,484:INFO:RandomForestRegressor(max_depth=9, min_impurity_decrease=0.1,
                      min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                      random_state=123)
2023-02-28 02:17:32,484:INFO:create_model() successfully completed......................................
2023-02-28 02:17:32,831:INFO:SubProcess create_model() end ==================================
2023-02-28 02:17:32,831:INFO:RandomForestRegressor(max_depth=9, min_impurity_decrease=0.1,
                      min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                      random_state=123) result for R2 is 0.8386
2023-02-28 02:17:32,831:INFO:SubProcess create_model() called ==================================
2023-02-28 02:17:32,831:INFO:Initializing create_model()
2023-02-28 02:17:32,831:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=LGBMRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:17:32,831:INFO:Checking exceptions
2023-02-28 02:17:32,831:INFO:Importing libraries
2023-02-28 02:17:32,831:INFO:Copying training dataset
2023-02-28 02:17:32,831:INFO:Defining folds
2023-02-28 02:17:32,831:INFO:Declaring metric variables
2023-02-28 02:17:32,831:INFO:Importing untrained model
2023-02-28 02:17:32,831:INFO:Declaring custom model
2023-02-28 02:17:32,831:INFO:Light Gradient Boosting Machine Imported successfully
2023-02-28 02:17:32,831:INFO:Starting cross validation
2023-02-28 02:17:32,831:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:17:33,387:INFO:Calculating mean and std
2023-02-28 02:17:33,387:INFO:Creating metrics dataframe
2023-02-28 02:17:33,387:INFO:Finalizing model
2023-02-28 02:17:33,533:INFO:Uploading results into container
2023-02-28 02:17:33,534:INFO:Uploading model into container now
2023-02-28 02:17:33,534:INFO:_master_model_container: 99
2023-02-28 02:17:33,534:INFO:_display_container: 43
2023-02-28 02:17:33,534:INFO:LGBMRegressor(random_state=123)
2023-02-28 02:17:33,534:INFO:create_model() successfully completed......................................
2023-02-28 02:17:33,877:INFO:SubProcess create_model() end ==================================
2023-02-28 02:17:33,877:INFO:LGBMRegressor(random_state=123) result for R2 is 0.8149
2023-02-28 02:17:33,877:INFO:SubProcess create_model() called ==================================
2023-02-28 02:17:33,877:INFO:Initializing create_model()
2023-02-28 02:17:33,877:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=ExtraTreesRegressor(bootstrap=True, max_depth=9, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:17:33,877:INFO:Checking exceptions
2023-02-28 02:17:33,877:INFO:Importing libraries
2023-02-28 02:17:33,877:INFO:Copying training dataset
2023-02-28 02:17:33,892:INFO:Defining folds
2023-02-28 02:17:33,892:INFO:Declaring metric variables
2023-02-28 02:17:33,892:INFO:Importing untrained model
2023-02-28 02:17:33,892:INFO:Declaring custom model
2023-02-28 02:17:33,892:INFO:Extra Trees Regressor Imported successfully
2023-02-28 02:17:33,892:INFO:Starting cross validation
2023-02-28 02:17:33,892:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:17:34,469:INFO:Calculating mean and std
2023-02-28 02:17:34,469:INFO:Creating metrics dataframe
2023-02-28 02:17:34,469:INFO:Finalizing model
2023-02-28 02:17:34,653:INFO:Uploading results into container
2023-02-28 02:17:34,653:INFO:Uploading model into container now
2023-02-28 02:17:34,653:INFO:_master_model_container: 100
2023-02-28 02:17:34,653:INFO:_display_container: 43
2023-02-28 02:17:34,653:INFO:ExtraTreesRegressor(bootstrap=True, max_depth=9, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123)
2023-02-28 02:17:34,653:INFO:create_model() successfully completed......................................
2023-02-28 02:17:35,002:INFO:SubProcess create_model() end ==================================
2023-02-28 02:17:35,002:INFO:ExtraTreesRegressor(bootstrap=True, max_depth=9, min_impurity_decrease=0.1,
                    min_samples_leaf=4, min_samples_split=7, n_jobs=-1,
                    random_state=123) result for R2 is 0.8381
2023-02-28 02:17:35,002:INFO:SubProcess create_model() called ==================================
2023-02-28 02:17:35,002:INFO:Initializing create_model()
2023-02-28 02:17:35,002:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=AdaBoostRegressor(learning_rate=1e-06, n_estimators=240, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:17:35,002:INFO:Checking exceptions
2023-02-28 02:17:35,006:INFO:Importing libraries
2023-02-28 02:17:35,006:INFO:Copying training dataset
2023-02-28 02:17:35,006:INFO:Defining folds
2023-02-28 02:17:35,006:INFO:Declaring metric variables
2023-02-28 02:17:35,006:INFO:Importing untrained model
2023-02-28 02:17:35,006:INFO:Declaring custom model
2023-02-28 02:17:35,006:INFO:str Imported successfully
2023-02-28 02:17:35,006:INFO:Starting cross validation
2023-02-28 02:17:35,014:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:17:35,773:INFO:Calculating mean and std
2023-02-28 02:17:35,773:INFO:Creating metrics dataframe
2023-02-28 02:17:35,776:INFO:Finalizing model
2023-02-28 02:17:36,000:INFO:Uploading results into container
2023-02-28 02:17:36,000:INFO:Uploading model into container now
2023-02-28 02:17:36,000:INFO:_master_model_container: 101
2023-02-28 02:17:36,000:INFO:_display_container: 43
2023-02-28 02:17:36,003:INFO:AdaBoostRegressor(learning_rate=1e-06, n_estimators=240, random_state=123)
2023-02-28 02:17:36,003:INFO:create_model() successfully completed......................................
2023-02-28 02:17:36,360:INFO:SubProcess create_model() end ==================================
2023-02-28 02:17:36,360:INFO:AdaBoostRegressor(learning_rate=1e-06, n_estimators=240, random_state=123) result for R2 is 0.8335
2023-02-28 02:17:36,360:INFO:SubProcess create_model() called ==================================
2023-02-28 02:17:36,360:INFO:Initializing create_model()
2023-02-28 02:17:36,362:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=HuberRegressor(alpha=0.001, epsilon=1.4, fit_intercept=False), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:17:36,362:INFO:Checking exceptions
2023-02-28 02:17:36,362:INFO:Importing libraries
2023-02-28 02:17:36,362:INFO:Copying training dataset
2023-02-28 02:17:36,370:INFO:Defining folds
2023-02-28 02:17:36,370:INFO:Declaring metric variables
2023-02-28 02:17:36,370:INFO:Importing untrained model
2023-02-28 02:17:36,370:INFO:Declaring custom model
2023-02-28 02:17:36,370:INFO:Huber Regressor Imported successfully
2023-02-28 02:17:36,370:INFO:Starting cross validation
2023-02-28 02:17:36,370:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:17:36,629:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:36,629:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:36,692:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:36,692:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:36,692:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:36,692:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:36,770:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:36,786:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:36,802:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:17:36,865:INFO:Calculating mean and std
2023-02-28 02:17:36,865:INFO:Creating metrics dataframe
2023-02-28 02:17:36,865:INFO:Finalizing model
2023-02-28 02:17:37,022:INFO:Uploading results into container
2023-02-28 02:17:37,022:INFO:Uploading model into container now
2023-02-28 02:17:37,022:INFO:_master_model_container: 102
2023-02-28 02:17:37,022:INFO:_display_container: 43
2023-02-28 02:17:37,022:INFO:HuberRegressor(alpha=0.001, epsilon=1.4, fit_intercept=False)
2023-02-28 02:17:37,037:INFO:create_model() successfully completed......................................
2023-02-28 02:17:37,368:INFO:SubProcess create_model() end ==================================
2023-02-28 02:17:37,368:INFO:HuberRegressor(alpha=0.001, epsilon=1.4, fit_intercept=False) result for R2 is 0.6902
2023-02-28 02:17:37,368:INFO:SubProcess create_model() called ==================================
2023-02-28 02:17:37,383:INFO:Initializing create_model()
2023-02-28 02:17:37,383:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:17:37,383:INFO:Checking exceptions
2023-02-28 02:17:37,386:INFO:Importing libraries
2023-02-28 02:17:37,386:INFO:Copying training dataset
2023-02-28 02:17:37,386:INFO:Defining folds
2023-02-28 02:17:37,386:INFO:Declaring metric variables
2023-02-28 02:17:37,386:INFO:Importing untrained model
2023-02-28 02:17:37,386:INFO:Declaring custom model
2023-02-28 02:17:37,386:INFO:str Imported successfully
2023-02-28 02:17:37,386:INFO:Starting cross validation
2023-02-28 02:17:37,386:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-02-28 02:17:38,832:INFO:Calculating mean and std
2023-02-28 02:17:38,847:INFO:Creating metrics dataframe
2023-02-28 02:17:38,847:INFO:Finalizing model
2023-02-28 02:17:39,116:INFO:Uploading results into container
2023-02-28 02:17:39,132:INFO:Uploading model into container now
2023-02-28 02:17:39,132:INFO:_master_model_container: 103
2023-02-28 02:17:39,134:INFO:_display_container: 43
2023-02-28 02:17:39,134:INFO:BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                 random_state=123)
2023-02-28 02:17:39,134:INFO:create_model() successfully completed......................................
2023-02-28 02:17:39,528:INFO:SubProcess create_model() end ==================================
2023-02-28 02:17:39,528:INFO:BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                 random_state=123) result for R2 is 0.8395
2023-02-28 02:17:39,562:INFO:StackingRegressor(cv=5,
                  estimators=[('Gradient Boosting Regressor',
                               GradientBoostingRegressor(random_state=123)),
                              ('Random Forest Regressor',
                               RandomForestRegressor(max_depth=9,
                                                     min_impurity_decrease=0.1,
                                                     min_samples_leaf=4,
                                                     min_samples_split=7,
                                                     n_jobs=-1,
                                                     random_state=123)),
                              ('Light Gradient Boosting Machine',
                               LGBMRegressor(random_state=123)),
                              ('Extra Trees Regressor',...
                                                   min_samples_split=7,
                                                   n_jobs=-1,
                                                   random_state=123)),
                              ('str',
                               AdaBoostRegressor(learning_rate=1e-06,
                                                 n_estimators=240,
                                                 random_state=123)),
                              ('Huber Regressor',
                               HuberRegressor(alpha=0.001, epsilon=1.4,
                                              fit_intercept=False)),
                              ('str_1',
                               BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                                                random_state=123))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1) is best model
2023-02-28 02:17:39,562:INFO:choose_better completed
2023-02-28 02:17:39,575:INFO:_master_model_container: 103
2023-02-28 02:17:39,575:INFO:_display_container: 42
2023-02-28 02:17:39,606:INFO:StackingRegressor(cv=5,
                  estimators=[('Gradient Boosting Regressor',
                               GradientBoostingRegressor(random_state=123)),
                              ('Random Forest Regressor',
                               RandomForestRegressor(max_depth=9,
                                                     min_impurity_decrease=0.1,
                                                     min_samples_leaf=4,
                                                     min_samples_split=7,
                                                     n_jobs=-1,
                                                     random_state=123)),
                              ('Light Gradient Boosting Machine',
                               LGBMRegressor(random_state=123)),
                              ('Extra Trees Regressor',...
                                                   min_samples_split=7,
                                                   n_jobs=-1,
                                                   random_state=123)),
                              ('str',
                               AdaBoostRegressor(learning_rate=1e-06,
                                                 n_estimators=240,
                                                 random_state=123)),
                              ('Huber Regressor',
                               HuberRegressor(alpha=0.001, epsilon=1.4,
                                              fit_intercept=False)),
                              ('str_1',
                               BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                                                random_state=123))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1)
2023-02-28 02:17:39,606:INFO:stack_models() successfully completed......................................
2023-02-28 02:20:06,047:INFO:Initializing evaluate_model()
2023-02-28 02:20:06,047:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=StackingRegressor(cv=5,
                  estimators=[('Gradient Boosting Regressor',
                               GradientBoostingRegressor(random_state=123)),
                              ('Random Forest Regressor',
                               RandomForestRegressor(max_depth=9,
                                                     min_impurity_decrease=0.1,
                                                     min_samples_leaf=4,
                                                     min_samples_split=7,
                                                     n_jobs=-1,
                                                     random_state=123)),
                              ('Light Gradient Boosting Machine',
                               LGBMRegressor(random_state=123)),
                              ('Extra Trees Regressor',...
                                                   min_samples_split=7,
                                                   n_jobs=-1,
                                                   random_state=123)),
                              ('str',
                               AdaBoostRegressor(learning_rate=1e-06,
                                                 n_estimators=240,
                                                 random_state=123)),
                              ('Huber Regressor',
                               HuberRegressor(alpha=0.001, epsilon=1.4,
                                              fit_intercept=False)),
                              ('str_1',
                               BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                                                random_state=123))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-02-28 02:20:06,078:INFO:Initializing plot_model()
2023-02-28 02:20:06,078:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=StackingRegressor(cv=5,
                  estimators=[('Gradient Boosting Regressor',
                               GradientBoostingRegressor(random_state=123)),
                              ('Random Forest Regressor',
                               RandomForestRegressor(max_depth=9,
                                                     min_impurity_decrease=0.1,
                                                     min_samples_leaf=4,
                                                     min_samples_split=7,
                                                     n_jobs=-1,
                                                     random_state=123)),
                              ('Light Gradient Boosting Machine',
                               LGBMRegressor(random_state=123)),
                              ('Extra Trees Regressor',...
                                                   min_samples_split=7,
                                                   n_jobs=-1,
                                                   random_state=123)),
                              ('str',
                               AdaBoostRegressor(learning_rate=1e-06,
                                                 n_estimators=240,
                                                 random_state=123)),
                              ('Huber Regressor',
                               HuberRegressor(alpha=0.001, epsilon=1.4,
                                              fit_intercept=False)),
                              ('str_1',
                               BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                                                random_state=123))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, system=True)
2023-02-28 02:20:06,078:INFO:Checking exceptions
2023-02-28 02:20:06,083:INFO:Preloading libraries
2023-02-28 02:20:06,230:INFO:Copying training dataset
2023-02-28 02:20:06,230:INFO:Plot type: pipeline
2023-02-28 02:20:06,490:INFO:Visual Rendered Successfully
2023-02-28 02:20:06,911:INFO:plot_model() successfully completed......................................
2023-02-28 02:20:17,869:INFO:Initializing plot_model()
2023-02-28 02:20:17,876:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=StackingRegressor(cv=5,
                  estimators=[('Gradient Boosting Regressor',
                               GradientBoostingRegressor(random_state=123)),
                              ('Random Forest Regressor',
                               RandomForestRegressor(max_depth=9,
                                                     min_impurity_decrease=0.1,
                                                     min_samples_leaf=4,
                                                     min_samples_split=7,
                                                     n_jobs=-1,
                                                     random_state=123)),
                              ('Light Gradient Boosting Machine',
                               LGBMRegressor(random_state=123)),
                              ('Extra Trees Regressor',...
                                                   min_samples_split=7,
                                                   n_jobs=-1,
                                                   random_state=123)),
                              ('str',
                               AdaBoostRegressor(learning_rate=1e-06,
                                                 n_estimators=240,
                                                 random_state=123)),
                              ('Huber Regressor',
                               HuberRegressor(alpha=0.001, epsilon=1.4,
                                              fit_intercept=False)),
                              ('str_1',
                               BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                                                random_state=123))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, system=True)
2023-02-28 02:20:17,876:INFO:Checking exceptions
2023-02-28 02:20:17,876:INFO:Preloading libraries
2023-02-28 02:20:18,018:INFO:Copying training dataset
2023-02-28 02:20:18,018:INFO:Plot type: error
2023-02-28 02:20:18,178:INFO:Fitting Model
2023-02-28 02:20:18,192:INFO:Scoring test/hold-out set
2023-02-28 02:20:18,690:INFO:Visual Rendered Successfully
2023-02-28 02:20:19,401:INFO:plot_model() successfully completed......................................
2023-02-28 02:20:27,197:INFO:Initializing plot_model()
2023-02-28 02:20:27,197:INFO:plot_model(plot=learning, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=StackingRegressor(cv=5,
                  estimators=[('Gradient Boosting Regressor',
                               GradientBoostingRegressor(random_state=123)),
                              ('Random Forest Regressor',
                               RandomForestRegressor(max_depth=9,
                                                     min_impurity_decrease=0.1,
                                                     min_samples_leaf=4,
                                                     min_samples_split=7,
                                                     n_jobs=-1,
                                                     random_state=123)),
                              ('Light Gradient Boosting Machine',
                               LGBMRegressor(random_state=123)),
                              ('Extra Trees Regressor',...
                                                   min_samples_split=7,
                                                   n_jobs=-1,
                                                   random_state=123)),
                              ('str',
                               AdaBoostRegressor(learning_rate=1e-06,
                                                 n_estimators=240,
                                                 random_state=123)),
                              ('Huber Regressor',
                               HuberRegressor(alpha=0.001, epsilon=1.4,
                                              fit_intercept=False)),
                              ('str_1',
                               BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                                                random_state=123))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, system=True)
2023-02-28 02:20:27,197:INFO:Checking exceptions
2023-02-28 02:20:27,197:INFO:Preloading libraries
2023-02-28 02:20:27,331:INFO:Copying training dataset
2023-02-28 02:20:27,331:INFO:Plot type: learning
2023-02-28 02:20:27,473:INFO:Fitting Model
2023-02-28 02:20:27,710:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:27,710:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:27,772:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:27,799:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:27,804:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:27,851:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:27,804:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:27,851:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:27,868:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:27,868:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:27,893:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:27,938:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:27,969:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:28,026:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:28,042:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:28,057:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:29,717:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:29,722:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:29,811:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:29,811:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:29,819:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:29,827:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:29,852:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:29,880:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:29,909:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:29,926:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:29,934:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:29,958:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:29,975:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:29,983:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:29,999:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,015:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,079:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,079:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,087:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,103:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,111:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,124:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,159:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,159:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,177:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,208:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,239:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,248:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,248:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,254:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,270:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,278:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,286:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,302:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,302:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,333:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,366:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,382:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,421:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,421:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,421:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,421:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,421:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,446:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,454:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,481:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,481:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,527:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,535:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,584:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,584:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,602:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,649:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,657:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,658:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,755:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,796:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,802:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,804:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,837:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:30,967:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:31,182:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:31,319:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:31,619:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:31,805:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:31,855:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:31,960:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:32,055:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:32,103:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:32,373:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:33,121:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:33,320:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:33,417:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:33,556:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:33,586:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:33,728:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:33,862:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:34,183:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:34,525:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:34,976:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:41,357:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:41,499:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:41,515:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:41,628:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:41,628:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:41,863:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:42,085:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:42,216:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:42,429:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:43,095:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:43,745:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:43,794:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:43,856:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:43,919:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:44,018:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:44,018:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:44,018:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:44,046:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:44,062:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:44,158:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:44,174:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:44,188:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:44,231:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:44,255:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:44,329:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:44,332:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:44,401:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:44,421:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:44,491:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:44,663:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:44,720:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:44,838:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:45,170:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:45,229:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:45,253:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:45,300:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:45,440:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:45,440:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:45,573:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:45,680:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:45,697:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:45,818:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:45,899:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:46,020:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:46,092:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:46,160:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:46,255:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:46,304:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:46,401:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:46,409:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:46,442:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:46,536:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:46,688:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:46,836:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:46,870:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:46,870:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:46,870:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:46,992:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:47,025:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:47,039:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:47,160:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:47,301:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:47,423:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:47,471:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:47,546:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:47,560:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:47,716:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:47,899:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:48,042:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:48,179:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:48,677:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:49,108:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:49,398:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:50,010:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:50,044:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:50,553:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:50,575:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:50,952:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:50,969:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:51,420:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:51,782:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:52,031:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:52,147:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:52,518:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:52,867:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:53,711:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:54,826:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:54,907:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:55,015:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:55,112:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:55,211:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:55,962:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:56,054:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:56,148:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:56,267:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:56,365:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:56,910:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:57,038:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:57,573:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:58,182:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:58,305:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:58,467:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:58,527:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:59,344:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:59,842:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:59,963:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:20:59,995:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:00,011:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:00,109:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:00,141:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:00,246:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:00,256:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:00,262:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:00,366:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:00,388:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:00,432:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:00,496:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:00,617:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:00,617:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:00,778:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:00,786:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:00,859:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:00,887:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:00,979:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:01,020:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:01,029:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:01,129:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:01,182:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:01,272:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:01,328:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:01,457:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:01,618:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:01,671:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:01,686:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:02,272:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:02,399:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:02,560:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:02,673:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:03,025:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:03,137:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:03,714:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:03,847:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:03,935:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:03,975:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:04,084:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:04,106:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:04,229:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:04,507:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:04,537:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:04,692:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:05,157:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:05,196:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:05,320:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:05,434:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:05,595:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:05,611:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:05,851:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:05,966:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:07,049:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:07,236:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:07,446:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:07,681:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:07,837:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:08,130:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:08,270:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:08,538:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:08,773:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:08,911:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:09,057:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:10,625:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:10,790:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:10,931:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:11,101:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:11,130:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:11,271:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:12,611:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:13,431:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:13,499:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:13,586:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:13,718:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:13,845:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:14,015:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:14,097:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:14,453:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:15,056:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:15,202:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:15,337:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:15,471:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:15,609:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:16,175:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:16,470:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:16,698:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:16,892:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:16,964:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:17,206:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:17,351:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:17,495:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:17,592:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:17,855:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:17,922:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:18,101:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:18,251:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:18,396:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:18,715:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:24,217:INFO:Visual Rendered Successfully
2023-02-28 02:21:24,534:INFO:plot_model() successfully completed......................................
2023-02-28 02:21:24,638:INFO:Initializing evaluate_model()
2023-02-28 02:21:24,638:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=StackingRegressor(cv=5,
                  estimators=[('Gradient Boosting Regressor',
                               GradientBoostingRegressor(random_state=123)),
                              ('Random Forest Regressor',
                               RandomForestRegressor(max_depth=9,
                                                     min_impurity_decrease=0.1,
                                                     min_samples_leaf=4,
                                                     min_samples_split=7,
                                                     n_jobs=-1,
                                                     random_state=123)),
                              ('Light Gradient Boosting Machine',
                               LGBMRegressor(random_state=123)),
                              ('Extra Trees Regressor',...
                                                   min_samples_split=7,
                                                   n_jobs=-1,
                                                   random_state=123)),
                              ('str',
                               AdaBoostRegressor(learning_rate=1e-06,
                                                 n_estimators=240,
                                                 random_state=123)),
                              ('Huber Regressor',
                               HuberRegressor(alpha=0.001, epsilon=1.4,
                                              fit_intercept=False)),
                              ('str_1',
                               BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                                                random_state=123))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-02-28 02:21:24,655:INFO:Initializing plot_model()
2023-02-28 02:21:24,655:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=StackingRegressor(cv=5,
                  estimators=[('Gradient Boosting Regressor',
                               GradientBoostingRegressor(random_state=123)),
                              ('Random Forest Regressor',
                               RandomForestRegressor(max_depth=9,
                                                     min_impurity_decrease=0.1,
                                                     min_samples_leaf=4,
                                                     min_samples_split=7,
                                                     n_jobs=-1,
                                                     random_state=123)),
                              ('Light Gradient Boosting Machine',
                               LGBMRegressor(random_state=123)),
                              ('Extra Trees Regressor',...
                                                   min_samples_split=7,
                                                   n_jobs=-1,
                                                   random_state=123)),
                              ('str',
                               AdaBoostRegressor(learning_rate=1e-06,
                                                 n_estimators=240,
                                                 random_state=123)),
                              ('Huber Regressor',
                               HuberRegressor(alpha=0.001, epsilon=1.4,
                                              fit_intercept=False)),
                              ('str_1',
                               BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                                                random_state=123))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, system=True)
2023-02-28 02:21:24,655:INFO:Checking exceptions
2023-02-28 02:21:24,662:INFO:Preloading libraries
2023-02-28 02:21:24,815:INFO:Copying training dataset
2023-02-28 02:21:24,815:INFO:Plot type: pipeline
2023-02-28 02:21:24,969:INFO:Visual Rendered Successfully
2023-02-28 02:21:25,269:INFO:plot_model() successfully completed......................................
2023-02-28 02:21:25,302:INFO:Initializing plot_model()
2023-02-28 02:21:25,302:INFO:plot_model(plot=feature, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=StackingRegressor(cv=5,
                  estimators=[('Gradient Boosting Regressor',
                               GradientBoostingRegressor(random_state=123)),
                              ('Random Forest Regressor',
                               RandomForestRegressor(max_depth=9,
                                                     min_impurity_decrease=0.1,
                                                     min_samples_leaf=4,
                                                     min_samples_split=7,
                                                     n_jobs=-1,
                                                     random_state=123)),
                              ('Light Gradient Boosting Machine',
                               LGBMRegressor(random_state=123)),
                              ('Extra Trees Regressor',...
                                                   min_samples_split=7,
                                                   n_jobs=-1,
                                                   random_state=123)),
                              ('str',
                               AdaBoostRegressor(learning_rate=1e-06,
                                                 n_estimators=240,
                                                 random_state=123)),
                              ('Huber Regressor',
                               HuberRegressor(alpha=0.001, epsilon=1.4,
                                              fit_intercept=False)),
                              ('str_1',
                               BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                                                random_state=123))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, system=True)
2023-02-28 02:21:25,302:INFO:Checking exceptions
2023-02-28 02:21:38,034:INFO:Initializing plot_model()
2023-02-28 02:21:38,034:INFO:plot_model(plot=parameter, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=StackingRegressor(cv=5,
                  estimators=[('Gradient Boosting Regressor',
                               GradientBoostingRegressor(random_state=123)),
                              ('Random Forest Regressor',
                               RandomForestRegressor(max_depth=9,
                                                     min_impurity_decrease=0.1,
                                                     min_samples_leaf=4,
                                                     min_samples_split=7,
                                                     n_jobs=-1,
                                                     random_state=123)),
                              ('Light Gradient Boosting Machine',
                               LGBMRegressor(random_state=123)),
                              ('Extra Trees Regressor',...
                                                   min_samples_split=7,
                                                   n_jobs=-1,
                                                   random_state=123)),
                              ('str',
                               AdaBoostRegressor(learning_rate=1e-06,
                                                 n_estimators=240,
                                                 random_state=123)),
                              ('Huber Regressor',
                               HuberRegressor(alpha=0.001, epsilon=1.4,
                                              fit_intercept=False)),
                              ('str_1',
                               BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                                                random_state=123))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, system=True)
2023-02-28 02:21:38,034:INFO:Checking exceptions
2023-02-28 02:21:38,041:INFO:Preloading libraries
2023-02-28 02:21:38,169:INFO:Copying training dataset
2023-02-28 02:21:38,169:INFO:Plot type: parameter
2023-02-28 02:21:38,185:INFO:Visual Rendered Successfully
2023-02-28 02:21:38,927:INFO:plot_model() successfully completed......................................
2023-02-28 02:21:44,843:INFO:Initializing plot_model()
2023-02-28 02:21:44,843:INFO:plot_model(plot=learning, fold=KFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=StackingRegressor(cv=5,
                  estimators=[('Gradient Boosting Regressor',
                               GradientBoostingRegressor(random_state=123)),
                              ('Random Forest Regressor',
                               RandomForestRegressor(max_depth=9,
                                                     min_impurity_decrease=0.1,
                                                     min_samples_leaf=4,
                                                     min_samples_split=7,
                                                     n_jobs=-1,
                                                     random_state=123)),
                              ('Light Gradient Boosting Machine',
                               LGBMRegressor(random_state=123)),
                              ('Extra Trees Regressor',...
                                                   min_samples_split=7,
                                                   n_jobs=-1,
                                                   random_state=123)),
                              ('str',
                               AdaBoostRegressor(learning_rate=1e-06,
                                                 n_estimators=240,
                                                 random_state=123)),
                              ('Huber Regressor',
                               HuberRegressor(alpha=0.001, epsilon=1.4,
                                              fit_intercept=False)),
                              ('str_1',
                               BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                                                random_state=123))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, system=True)
2023-02-28 02:21:44,843:INFO:Checking exceptions
2023-02-28 02:21:44,847:INFO:Preloading libraries
2023-02-28 02:21:44,986:INFO:Copying training dataset
2023-02-28 02:21:44,986:INFO:Plot type: learning
2023-02-28 02:21:45,112:INFO:Fitting Model
2023-02-28 02:21:45,411:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:45,447:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:45,454:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:45,505:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:45,518:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:45,526:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:45,567:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:45,567:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:45,575:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:45,655:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:45,663:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:45,687:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:45,736:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:45,776:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:45,849:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:47,487:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:47,609:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:47,624:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:47,647:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:47,680:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:47,696:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:47,705:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:47,736:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:47,779:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:47,784:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:47,805:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:47,805:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:47,815:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:47,830:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:47,849:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:47,867:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:47,869:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:47,917:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:47,923:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:47,952:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:47,959:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:47,963:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:47,996:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:48,005:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:48,012:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:48,021:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:48,061:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:48,069:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:48,090:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:48,090:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:48,094:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:48,118:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:48,142:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:48,150:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:48,167:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:48,167:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:48,199:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:48,208:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:48,239:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:48,263:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:48,273:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:48,279:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:48,303:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:48,320:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:48,336:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:48,344:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:48,392:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:48,410:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:48,424:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:48,424:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:48,440:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:48,497:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:48,506:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:48,506:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:48,539:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:48,581:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:48,611:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:48,634:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:48,661:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:48,831:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:49,030:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:49,330:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:49,418:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:49,620:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:49,651:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:49,890:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:50,036:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:50,247:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:50,287:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:50,561:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:50,649:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:51,445:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:51,721:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:52,116:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:52,528:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:21:53,061:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:00,563:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:00,864:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:00,864:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:00,895:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:00,895:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:01,153:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:01,233:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:01,595:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:02,256:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:02,840:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:03,013:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:03,076:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:03,632:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:03,675:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:03,912:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:03,962:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:04,124:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:04,132:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:04,224:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:04,244:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:04,336:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:04,368:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:04,384:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:04,415:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:04,510:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:04,526:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:04,588:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:04,625:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:04,667:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:04,667:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:04,839:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:04,886:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:04,997:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:05,141:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:05,312:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:05,375:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:05,438:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:05,475:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:05,612:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:05,612:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:05,753:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:05,800:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:06,004:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:06,067:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:06,208:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:06,226:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:06,318:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:06,326:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:06,428:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:06,696:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:06,853:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:06,879:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:06,995:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:07,027:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:07,092:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:07,341:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:07,341:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:07,357:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:07,388:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:07,531:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:07,704:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:07,735:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:07,832:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:07,911:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:07,991:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:08,003:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:08,067:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:08,167:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:08,429:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:08,508:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:08,697:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:09,232:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:09,932:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:10,381:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:10,490:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:10,970:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:11,034:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:11,915:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:12,856:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:12,997:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:13,044:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:13,235:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:13,375:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:13,567:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:14,088:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:14,353:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:15,137:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:15,802:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:16,054:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:16,495:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:17,032:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:18,754:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:18,842:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:18,874:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:19,011:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:19,122:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:19,250:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:19,966:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:20,055:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:20,861:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:21,243:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:21,687:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:21,800:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:22,233:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:22,452:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:22,596:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:22,716:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:22,877:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:23,017:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:23,366:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:23,382:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:23,605:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:23,620:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:23,763:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:23,779:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:23,916:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:23,922:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:24,051:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:24,127:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:24,206:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:24,285:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:24,316:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:24,383:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:24,508:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:24,580:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:24,664:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:24,790:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:24,806:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:24,880:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:25,000:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:25,079:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:25,194:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:26,004:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:26,678:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:27,058:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:27,508:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:27,520:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:27,645:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:27,793:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:27,889:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:27,936:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:28,001:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:28,114:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:28,114:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:28,259:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:28,347:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:28,606:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:28,757:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:28,889:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:28,961:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:28,977:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:28,977:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:28,985:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:29,090:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:29,176:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:29,255:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:29,326:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:29,512:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:29,611:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:29,643:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:29,842:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:30,050:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:30,588:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:32,526:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:32,540:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:32,657:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:32,786:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:32,957:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:33,110:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:35,804:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:36,191:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:36,369:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:36,505:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:36,661:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:36,796:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:37,876:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:38,111:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:38,287:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:38,431:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:38,576:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:38,747:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:38,761:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:39,876:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:40,021:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:40,628:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:40,806:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:41,010:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:41,201:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:41,375:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:41,939:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:42,512:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:42,736:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:42,774:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:43,133:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:43,247:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:43,257:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:43,590:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:43,782:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:43,849:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:44,209:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:44,243:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:44,341:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:44,832:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:44,923:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:22:52,157:INFO:Visual Rendered Successfully
2023-02-28 02:22:52,542:INFO:plot_model() successfully completed......................................
2023-02-28 02:22:52,564:INFO:Initializing predict_model()
2023-02-28 02:22:52,564:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(random_state=123)),
                            ('Random Forest Regressor',
                             RandomForestRegressor(max_depth=9,
                                                   min_impurity_decrease=0.1,
                                                   min_samples_leaf=4,
                                                   min_samples_split=7,
                                                   n_jobs=-1,
                                                   random_state=123)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(random_state=123)),
                            ('Extra Trees Regressor',
                             ExtraTr...
                                                 min_impurity_decrease=0.1,
                                                 min_samples_leaf=4,
                                                 min_samples_split=7, n_jobs=-1,
                                                 random_state=123)),
                            ('str',
                             AdaBoostRegressor(learning_rate=1e-06,
                                               n_estimators=240,
                                               random_state=123)),
                            ('Huber Regressor',
                             HuberRegressor(alpha=0.001, epsilon=1.4,
                                            fit_intercept=False)),
                            ('str_1',
                             BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                                              random_state=123))],
                n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001AB078A3430>)
2023-02-28 02:22:52,564:INFO:Checking exceptions
2023-02-28 02:22:52,564:INFO:Preloading libraries
2023-02-28 02:23:08,739:INFO:Initializing predict_model()
2023-02-28 02:23:08,739:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=StackingRegressor(cv=5,
                  estimators=[('Gradient Boosting Regressor',
                               GradientBoostingRegressor(random_state=123)),
                              ('Random Forest Regressor',
                               RandomForestRegressor(max_depth=9,
                                                     min_impurity_decrease=0.1,
                                                     min_samples_leaf=4,
                                                     min_samples_split=7,
                                                     n_jobs=-1,
                                                     random_state=123)),
                              ('Light Gradient Boosting Machine',
                               LGBMRegressor(random_state=123)),
                              ('Extra Trees Regressor',...
                                                   min_samples_split=7,
                                                   n_jobs=-1,
                                                   random_state=123)),
                              ('str',
                               AdaBoostRegressor(learning_rate=1e-06,
                                                 n_estimators=240,
                                                 random_state=123)),
                              ('Huber Regressor',
                               HuberRegressor(alpha=0.001, epsilon=1.4,
                                              fit_intercept=False)),
                              ('str_1',
                               BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                                                random_state=123))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001AB089A7550>)
2023-02-28 02:23:08,739:INFO:Checking exceptions
2023-02-28 02:23:08,739:INFO:Preloading libraries
2023-02-28 02:25:21,856:INFO:Initializing predict_model()
2023-02-28 02:25:21,856:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(random_state=123)),
                            ('Random Forest Regressor',
                             RandomForestRegressor(max_depth=9,
                                                   min_impurity_decrease=0.1,
                                                   min_samples_leaf=4,
                                                   min_samples_split=7,
                                                   n_jobs=-1,
                                                   random_state=123)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(random_state=123)),
                            ('Extra Trees Regressor',
                             ExtraTr...
                                                 min_impurity_decrease=0.1,
                                                 min_samples_leaf=4,
                                                 min_samples_split=7, n_jobs=-1,
                                                 random_state=123)),
                            ('str',
                             AdaBoostRegressor(learning_rate=1e-06,
                                               n_estimators=240,
                                               random_state=123)),
                            ('Huber Regressor',
                             HuberRegressor(alpha=0.001, epsilon=1.4,
                                            fit_intercept=False)),
                            ('str_1',
                             BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                                              random_state=123))],
                n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001AB089A7790>)
2023-02-28 02:25:21,856:INFO:Checking exceptions
2023-02-28 02:25:21,856:INFO:Preloading libraries
2023-02-28 02:27:25,820:INFO:Initializing finalize_model()
2023-02-28 02:27:25,820:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(random_state=123)),
                            ('Random Forest Regressor',
                             RandomForestRegressor(max_depth=9,
                                                   min_impurity_decrease=0.1,
                                                   min_samples_leaf=4,
                                                   min_samples_split=7,
                                                   n_jobs=-1,
                                                   random_state=123)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(random_state=123)),
                            ('Extra Trees Regressor',
                             ExtraTr...
                                                 min_impurity_decrease=0.1,
                                                 min_samples_leaf=4,
                                                 min_samples_split=7, n_jobs=-1,
                                                 random_state=123)),
                            ('str',
                             AdaBoostRegressor(learning_rate=1e-06,
                                               n_estimators=240,
                                               random_state=123)),
                            ('Huber Regressor',
                             HuberRegressor(alpha=0.001, epsilon=1.4,
                                            fit_intercept=False)),
                            ('str_1',
                             BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                                              random_state=123))],
                n_jobs=-1), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-02-28 02:27:25,828:INFO:Finalizing VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(random_state=123)),
                            ('Random Forest Regressor',
                             RandomForestRegressor(max_depth=9,
                                                   min_impurity_decrease=0.1,
                                                   min_samples_leaf=4,
                                                   min_samples_split=7,
                                                   n_jobs=-1,
                                                   random_state=123)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(random_state=123)),
                            ('Extra Trees Regressor',
                             ExtraTr...
                                                 min_impurity_decrease=0.1,
                                                 min_samples_leaf=4,
                                                 min_samples_split=7, n_jobs=-1,
                                                 random_state=123)),
                            ('str',
                             AdaBoostRegressor(learning_rate=1e-06,
                                               n_estimators=240,
                                               random_state=123)),
                            ('Huber Regressor',
                             HuberRegressor(alpha=0.001, epsilon=1.4,
                                            fit_intercept=False)),
                            ('str_1',
                             BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                                              random_state=123))],
                n_jobs=-1)
2023-02-28 02:27:25,842:INFO:Initializing create_model()
2023-02-28 02:27:25,842:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(random_state=123)),
                            ('Random Forest Regressor',
                             RandomForestRegressor(max_depth=9,
                                                   min_impurity_decrease=0.1,
                                                   min_samples_leaf=4,
                                                   min_samples_split=7,
                                                   n_jobs=-1,
                                                   random_state=123)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(random_state=123)),
                            ('Extra Trees Regressor',
                             ExtraTr...
                                                 min_impurity_decrease=0.1,
                                                 min_samples_leaf=4,
                                                 min_samples_split=7, n_jobs=-1,
                                                 random_state=123)),
                            ('str',
                             AdaBoostRegressor(learning_rate=1e-06,
                                               n_estimators=240,
                                               random_state=123)),
                            ('Huber Regressor',
                             HuberRegressor(alpha=0.001, epsilon=1.4,
                                            fit_intercept=False)),
                            ('str_1',
                             BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                                              random_state=123))],
                n_jobs=-1), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-02-28 02:27:25,842:INFO:Checking exceptions
2023-02-28 02:27:25,845:INFO:Importing libraries
2023-02-28 02:27:25,845:INFO:Copying training dataset
2023-02-28 02:27:25,845:INFO:Defining folds
2023-02-28 02:27:25,845:INFO:Declaring metric variables
2023-02-28 02:27:25,845:INFO:Importing untrained model
2023-02-28 02:27:25,845:INFO:Declaring custom model
2023-02-28 02:27:25,848:INFO:Voting Regressor Imported successfully
2023-02-28 02:27:25,851:INFO:Cross validation set to False
2023-02-28 02:27:25,851:INFO:Fitting Model
2023-02-28 02:27:25,954:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:27:27,602:INFO:Pipeline(memory=FastMemory(location=C:\Users\takis\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                  min_impurity_decrease=0.1,
                                                                  min_samples_leaf=4,
                                                                  min_samples_split=7,
                                                                  n_jobs=-1,
                                                                  random_state=123)),
                                             ('str',
                                              AdaBoostRegressor(learning_rate=1e-06,
                                                                n_estimators=240,
                                                                random_state=123)),
                                             ('Huber Regressor',
                                              HuberRegressor(alpha=0.001,
                                                             epsilon=1.4,
                                                             fit_intercept=False)),
                                             ('str_1',
                                              BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                                                               random_state=123))],
                                 n_jobs=-1))])
2023-02-28 02:27:27,602:INFO:create_model() successfully completed......................................
2023-02-28 02:27:27,912:INFO:_master_model_container: 103
2023-02-28 02:27:27,912:INFO:_display_container: 45
2023-02-28 02:27:27,973:INFO:Pipeline(memory=FastMemory(location=C:\Users\takis\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                  min_impurity_decrease=0.1,
                                                                  min_samples_leaf=4,
                                                                  min_samples_split=7,
                                                                  n_jobs=-1,
                                                                  random_state=123)),
                                             ('str',
                                              AdaBoostRegressor(learning_rate=1e-06,
                                                                n_estimators=240,
                                                                random_state=123)),
                                             ('Huber Regressor',
                                              HuberRegressor(alpha=0.001,
                                                             epsilon=1.4,
                                                             fit_intercept=False)),
                                             ('str_1',
                                              BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                                                               random_state=123))],
                                 n_jobs=-1))])
2023-02-28 02:27:27,973:INFO:finalize_model() successfully completed......................................
2023-02-28 02:30:21,445:INFO:Initializing save_model()
2023-02-28 02:30:21,445:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\takis\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                  min_impurity_decrease=0.1,
                                                                  min_samples_leaf=4,
                                                                  min_samples_split=7,
                                                                  n_jobs=-1,
                                                                  random_state=123)),
                                             ('str',
                                              AdaBoostRegressor(learning_rate=1e-06,
                                                                n_estimators=240,
                                                                random_state=123)),
                                             ('Huber Regressor',
                                              HuberRegressor(alpha=0.001,
                                                             epsilon=1.4,
                                                             fit_intercept=False)),
                                             ('str_1',
                                              BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                                                               random_state=123))],
                                 n_jobs=-1))]), model_name=exp1_fm1.pkl, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\takis\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                     'smoker'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64},
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-02-28 02:30:21,445:INFO:Adding model into prep_pipe
2023-02-28 02:30:21,591:WARNING:Only Model saved as it was a pipeline.
2023-02-28 02:30:21,800:INFO:exp1_fm1.pkl.pkl saved in current working directory
2023-02-28 02:30:21,844:INFO:Pipeline(memory=FastMemory(location=C:\Users\takis\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                  min_impurity_decrease=0.1,
                                                                  min_samples_leaf=4,
                                                                  min_samples_split=7,
                                                                  n_jobs=-1,
                                                                  random_state=123)),
                                             ('str',
                                              AdaBoostRegressor(learning_rate=1e-06,
                                                                n_estimators=240,
                                                                random_state=123)),
                                             ('Huber Regressor',
                                              HuberRegressor(alpha=0.001,
                                                             epsilon=1.4,
                                                             fit_intercept=False)),
                                             ('str_1',
                                              BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                                                               random_state=123))],
                                 n_jobs=-1))])
2023-02-28 02:30:21,844:INFO:save_model() successfully completed......................................
2023-02-28 02:30:48,639:INFO:Initializing finalize_model()
2023-02-28 02:30:48,639:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=StackingRegressor(cv=5,
                  estimators=[('Gradient Boosting Regressor',
                               GradientBoostingRegressor(random_state=123)),
                              ('Random Forest Regressor',
                               RandomForestRegressor(max_depth=9,
                                                     min_impurity_decrease=0.1,
                                                     min_samples_leaf=4,
                                                     min_samples_split=7,
                                                     n_jobs=-1,
                                                     random_state=123)),
                              ('Light Gradient Boosting Machine',
                               LGBMRegressor(random_state=123)),
                              ('Extra Trees Regressor',...
                                                   min_samples_split=7,
                                                   n_jobs=-1,
                                                   random_state=123)),
                              ('str',
                               AdaBoostRegressor(learning_rate=1e-06,
                                                 n_estimators=240,
                                                 random_state=123)),
                              ('Huber Regressor',
                               HuberRegressor(alpha=0.001, epsilon=1.4,
                                              fit_intercept=False)),
                              ('str_1',
                               BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                                                random_state=123))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-02-28 02:30:48,651:INFO:Finalizing StackingRegressor(cv=5,
                  estimators=[('Gradient Boosting Regressor',
                               GradientBoostingRegressor(random_state=123)),
                              ('Random Forest Regressor',
                               RandomForestRegressor(max_depth=9,
                                                     min_impurity_decrease=0.1,
                                                     min_samples_leaf=4,
                                                     min_samples_split=7,
                                                     n_jobs=-1,
                                                     random_state=123)),
                              ('Light Gradient Boosting Machine',
                               LGBMRegressor(random_state=123)),
                              ('Extra Trees Regressor',...
                                                   min_samples_split=7,
                                                   n_jobs=-1,
                                                   random_state=123)),
                              ('str',
                               AdaBoostRegressor(learning_rate=1e-06,
                                                 n_estimators=240,
                                                 random_state=123)),
                              ('Huber Regressor',
                               HuberRegressor(alpha=0.001, epsilon=1.4,
                                              fit_intercept=False)),
                              ('str_1',
                               BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                                                random_state=123))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1)
2023-02-28 02:30:48,664:INFO:Initializing create_model()
2023-02-28 02:30:48,664:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=StackingRegressor(cv=5,
                  estimators=[('Gradient Boosting Regressor',
                               GradientBoostingRegressor(random_state=123)),
                              ('Random Forest Regressor',
                               RandomForestRegressor(max_depth=9,
                                                     min_impurity_decrease=0.1,
                                                     min_samples_leaf=4,
                                                     min_samples_split=7,
                                                     n_jobs=-1,
                                                     random_state=123)),
                              ('Light Gradient Boosting Machine',
                               LGBMRegressor(random_state=123)),
                              ('Extra Trees Regressor',...
                                                   min_samples_split=7,
                                                   n_jobs=-1,
                                                   random_state=123)),
                              ('str',
                               AdaBoostRegressor(learning_rate=1e-06,
                                                 n_estimators=240,
                                                 random_state=123)),
                              ('Huber Regressor',
                               HuberRegressor(alpha=0.001, epsilon=1.4,
                                              fit_intercept=False)),
                              ('str_1',
                               BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                                                random_state=123))],
                  final_estimator=LinearRegression(n_jobs=-1), n_jobs=-1), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-02-28 02:30:48,664:INFO:Checking exceptions
2023-02-28 02:30:48,664:INFO:Importing libraries
2023-02-28 02:30:48,664:INFO:Copying training dataset
2023-02-28 02:30:48,664:INFO:Defining folds
2023-02-28 02:30:48,664:INFO:Declaring metric variables
2023-02-28 02:30:48,664:INFO:Importing untrained model
2023-02-28 02:30:48,664:INFO:Declaring custom model
2023-02-28 02:30:48,664:INFO:Stacking Regressor Imported successfully
2023-02-28 02:30:48,672:INFO:Cross validation set to False
2023-02-28 02:30:48,672:INFO:Fitting Model
2023-02-28 02:30:48,842:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:30:50,433:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:30:50,439:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:30:50,441:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:30:50,446:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:30:50,449:WARNING:c:\Users\takis\anaconda3\envs\caretenv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-02-28 02:30:55,281:INFO:Pipeline(memory=FastMemory(location=C:\Users\takis\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                    min_samples_split=7,
                                                                    n_jobs=-1,
                                                                    random_state=123)),
                                               ('str',
                                                AdaBoostRegressor(learning_rate=1e-06,
                                                                  n_estimators=240,
                                                                  random_state=123)),
                                               ('Huber Regressor',
                                                HuberRegressor(alpha=0.001,
                                                               epsilon=1.4,
                                                               fit_intercept=False)),
                                               ('str_1',
                                                BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                                                                 random_state=123))],
                                   final_estimator=LinearRegression(n_jobs=-1),
                                   n_jobs=-1))])
2023-02-28 02:30:55,281:INFO:create_model() successfully completed......................................
2023-02-28 02:30:55,631:INFO:_master_model_container: 103
2023-02-28 02:30:55,631:INFO:_display_container: 45
2023-02-28 02:30:55,695:INFO:Pipeline(memory=FastMemory(location=C:\Users\takis\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                    min_samples_split=7,
                                                                    n_jobs=-1,
                                                                    random_state=123)),
                                               ('str',
                                                AdaBoostRegressor(learning_rate=1e-06,
                                                                  n_estimators=240,
                                                                  random_state=123)),
                                               ('Huber Regressor',
                                                HuberRegressor(alpha=0.001,
                                                               epsilon=1.4,
                                                               fit_intercept=False)),
                                               ('str_1',
                                                BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                                                                 random_state=123))],
                                   final_estimator=LinearRegression(n_jobs=-1),
                                   n_jobs=-1))])
2023-02-28 02:30:55,695:INFO:finalize_model() successfully completed......................................
2023-02-28 02:31:00,742:INFO:Initializing save_model()
2023-02-28 02:31:00,742:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\takis\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                    min_samples_split=7,
                                                                    n_jobs=-1,
                                                                    random_state=123)),
                                               ('str',
                                                AdaBoostRegressor(learning_rate=1e-06,
                                                                  n_estimators=240,
                                                                  random_state=123)),
                                               ('Huber Regressor',
                                                HuberRegressor(alpha=0.001,
                                                               epsilon=1.4,
                                                               fit_intercept=False)),
                                               ('str_1',
                                                BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                                                                 random_state=123))],
                                   final_estimator=LinearRegression(n_jobs=-1),
                                   n_jobs=-1))]), model_name=exp1_fm2.pkl, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\takis\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                     'smoker'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64},
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-02-28 02:31:00,742:INFO:Adding model into prep_pipe
2023-02-28 02:31:00,879:WARNING:Only Model saved as it was a pipeline.
2023-02-28 02:31:01,105:INFO:exp1_fm2.pkl.pkl saved in current working directory
2023-02-28 02:31:01,154:INFO:Pipeline(memory=FastMemory(location=C:\Users\takis\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                    min_samples_split=7,
                                                                    n_jobs=-1,
                                                                    random_state=123)),
                                               ('str',
                                                AdaBoostRegressor(learning_rate=1e-06,
                                                                  n_estimators=240,
                                                                  random_state=123)),
                                               ('Huber Regressor',
                                                HuberRegressor(alpha=0.001,
                                                               epsilon=1.4,
                                                               fit_intercept=False)),
                                               ('str_1',
                                                BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                                                                 random_state=123))],
                                   final_estimator=LinearRegression(n_jobs=-1),
                                   n_jobs=-1))])
2023-02-28 02:31:01,154:INFO:save_model() successfully completed......................................
2023-02-28 02:33:12,117:INFO:Initializing automl()
2023-02-28 02:33:12,117:INFO:automl(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, optimize=MAE, use_holdout=False, turbo=True, return_train_score=False)
2023-02-28 02:33:12,117:INFO:Model Selection Basis : CV Results on Training set
2023-02-28 02:33:12,117:INFO:Checking model 0
2023-02-28 02:33:12,125:INFO:Checking model 1
2023-02-28 02:33:12,125:INFO:Checking model 2
2023-02-28 02:33:12,125:INFO:Checking model 3
2023-02-28 02:33:12,125:INFO:Checking model 4
2023-02-28 02:33:12,125:INFO:Checking model 5
2023-02-28 02:33:12,125:INFO:Checking model 6
2023-02-28 02:33:12,125:INFO:Checking model 7
2023-02-28 02:33:12,125:INFO:Checking model 8
2023-02-28 02:33:12,125:INFO:Checking model 9
2023-02-28 02:33:12,125:INFO:Checking model 10
2023-02-28 02:33:12,125:INFO:Checking model 11
2023-02-28 02:33:12,125:INFO:Checking model 12
2023-02-28 02:33:12,125:INFO:Checking model 13
2023-02-28 02:33:12,125:INFO:Checking model 14
2023-02-28 02:33:12,125:INFO:Checking model 15
2023-02-28 02:33:12,125:INFO:Checking model 16
2023-02-28 02:33:12,125:INFO:Checking model 17
2023-02-28 02:33:12,125:INFO:Checking model 18
2023-02-28 02:33:12,125:INFO:Checking model 19
2023-02-28 02:33:12,125:INFO:Checking model 20
2023-02-28 02:33:12,125:INFO:Checking model 21
2023-02-28 02:33:12,129:INFO:Checking model 22
2023-02-28 02:33:12,129:INFO:Checking model 23
2023-02-28 02:33:12,129:INFO:Checking model 24
2023-02-28 02:33:12,129:INFO:Checking model 25
2023-02-28 02:33:12,129:INFO:Checking model 26
2023-02-28 02:33:12,129:INFO:Checking model 27
2023-02-28 02:33:12,130:INFO:Checking model 28
2023-02-28 02:33:12,130:INFO:Checking model 29
2023-02-28 02:33:12,130:INFO:Checking model 30
2023-02-28 02:33:12,130:INFO:Checking model 31
2023-02-28 02:33:12,130:INFO:Checking model 32
2023-02-28 02:33:12,130:INFO:Checking model 33
2023-02-28 02:33:12,130:INFO:Checking model 34
2023-02-28 02:33:12,130:INFO:Checking model 35
2023-02-28 02:33:12,131:INFO:Checking model 36
2023-02-28 02:33:12,131:INFO:Checking model 37
2023-02-28 02:33:12,131:INFO:Checking model 38
2023-02-28 02:33:12,131:INFO:Checking model 39
2023-02-28 02:33:12,131:INFO:Checking model 40
2023-02-28 02:33:12,131:INFO:Checking model 41
2023-02-28 02:33:12,131:INFO:Checking model 42
2023-02-28 02:33:12,131:INFO:Checking model 43
2023-02-28 02:33:12,132:INFO:Checking model 44
2023-02-28 02:33:12,132:INFO:Checking model 45
2023-02-28 02:33:12,132:INFO:Checking model 46
2023-02-28 02:33:12,132:INFO:Checking model 47
2023-02-28 02:33:12,133:INFO:Checking model 48
2023-02-28 02:33:12,133:INFO:Checking model 49
2023-02-28 02:33:12,133:INFO:Checking model 50
2023-02-28 02:33:12,133:INFO:Checking model 51
2023-02-28 02:33:12,133:INFO:Checking model 52
2023-02-28 02:33:12,133:INFO:Checking model 53
2023-02-28 02:33:12,133:INFO:Checking model 54
2023-02-28 02:33:12,133:INFO:Checking model 55
2023-02-28 02:33:12,134:INFO:Checking model 56
2023-02-28 02:33:12,134:INFO:Checking model 57
2023-02-28 02:33:12,134:INFO:Checking model 58
2023-02-28 02:33:12,134:INFO:Checking model 59
2023-02-28 02:33:12,134:INFO:Checking model 60
2023-02-28 02:33:12,134:INFO:Checking model 61
2023-02-28 02:33:12,134:INFO:Checking model 62
2023-02-28 02:33:12,134:INFO:Checking model 63
2023-02-28 02:33:12,135:INFO:Checking model 64
2023-02-28 02:33:12,135:INFO:Checking model 65
2023-02-28 02:33:12,135:INFO:Checking model 66
2023-02-28 02:33:12,135:INFO:Checking model 67
2023-02-28 02:33:12,135:INFO:Checking model 68
2023-02-28 02:33:12,135:INFO:Checking model 69
2023-02-28 02:33:12,135:INFO:Checking model 70
2023-02-28 02:33:12,135:INFO:Checking model 71
2023-02-28 02:33:12,137:INFO:Checking model 72
2023-02-28 02:33:12,137:INFO:Checking model 73
2023-02-28 02:33:12,137:INFO:Checking model 74
2023-02-28 02:33:12,137:INFO:Checking model 75
2023-02-28 02:33:12,137:INFO:Checking model 76
2023-02-28 02:33:12,137:INFO:Checking model 77
2023-02-28 02:33:12,137:INFO:Checking model 78
2023-02-28 02:33:12,137:INFO:Checking model 79
2023-02-28 02:33:12,137:INFO:Checking model 80
2023-02-28 02:33:12,137:INFO:Checking model 81
2023-02-28 02:33:12,137:INFO:Checking model 82
2023-02-28 02:33:12,137:INFO:Checking model 83
2023-02-28 02:33:12,137:INFO:Checking model 84
2023-02-28 02:33:12,137:INFO:Checking model 85
2023-02-28 02:33:12,137:INFO:Checking model 86
2023-02-28 02:33:12,137:INFO:Checking model 87
2023-02-28 02:33:12,137:INFO:Checking model 88
2023-02-28 02:33:12,137:INFO:Checking model 89
2023-02-28 02:33:12,137:INFO:Checking model 90
2023-02-28 02:33:12,137:INFO:Checking model 91
2023-02-28 02:33:12,137:INFO:Checking model 92
2023-02-28 02:33:12,137:INFO:Checking model 93
2023-02-28 02:33:12,137:INFO:Checking model 94
2023-02-28 02:33:12,137:INFO:Checking model 95
2023-02-28 02:33:12,141:INFO:Checking model 96
2023-02-28 02:33:12,141:INFO:Checking model 97
2023-02-28 02:33:12,141:INFO:Checking model 98
2023-02-28 02:33:12,141:INFO:Checking model 99
2023-02-28 02:33:12,141:INFO:Checking model 100
2023-02-28 02:33:12,141:INFO:Checking model 101
2023-02-28 02:33:12,141:INFO:Checking model 102
2023-02-28 02:33:12,149:INFO:Initializing create_model()
2023-02-28 02:33:12,149:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001AB066B8580>, estimator=VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(random_state=123)),
                            ('Random Forest Regressor',
                             RandomForestRegressor(max_depth=9,
                                                   min_impurity_decrease=0.1,
                                                   min_samples_leaf=4,
                                                   min_samples_split=7,
                                                   n_jobs=-1,
                                                   random_state=123)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(random_state=123)),
                            ('Extra Trees Regressor',
                             ExtraTr...
                                                 min_impurity_decrease=0.1,
                                                 min_samples_leaf=4,
                                                 min_samples_split=7, n_jobs=-1,
                                                 random_state=123)),
                            ('str',
                             AdaBoostRegressor(learning_rate=1e-06,
                                               n_estimators=240,
                                               random_state=123)),
                            ('Huber Regressor',
                             HuberRegressor(alpha=0.001, epsilon=1.4,
                                            fit_intercept=False)),
                            ('str_1',
                             BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                                              random_state=123))],
                n_jobs=-1), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-02-28 02:33:12,149:INFO:Checking exceptions
2023-02-28 02:33:12,149:INFO:Importing libraries
2023-02-28 02:33:12,149:INFO:Copying training dataset
2023-02-28 02:33:12,157:INFO:Defining folds
2023-02-28 02:33:12,157:INFO:Declaring metric variables
2023-02-28 02:33:12,157:INFO:Importing untrained model
2023-02-28 02:33:12,157:INFO:Declaring custom model
2023-02-28 02:33:12,157:INFO:Voting Regressor Imported successfully
2023-02-28 02:33:12,157:INFO:Cross validation set to False
2023-02-28 02:33:12,157:INFO:Fitting Model
2023-02-28 02:33:12,419:INFO:VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(random_state=123)),
                            ('Random Forest Regressor',
                             RandomForestRegressor(max_depth=9,
                                                   min_impurity_decrease=0.1,
                                                   min_samples_leaf=4,
                                                   min_samples_split=7,
                                                   n_jobs=-1,
                                                   random_state=123)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(random_state=123)),
                            ('Extra Trees Regressor',
                             ExtraTr...
                                                 min_impurity_decrease=0.1,
                                                 min_samples_leaf=4,
                                                 min_samples_split=7, n_jobs=-1,
                                                 random_state=123)),
                            ('str',
                             AdaBoostRegressor(learning_rate=1e-06,
                                               n_estimators=240,
                                               random_state=123)),
                            ('Huber Regressor',
                             HuberRegressor(alpha=0.001, epsilon=1.4,
                                            fit_intercept=False)),
                            ('str_1',
                             BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                                              random_state=123))],
                n_jobs=-1)
2023-02-28 02:33:12,419:INFO:create_model() successfully completed......................................
2023-02-28 02:33:13,883:INFO:VotingRegressor(estimators=[('Gradient Boosting Regressor',
                             GradientBoostingRegressor(random_state=123)),
                            ('Random Forest Regressor',
                             RandomForestRegressor(max_depth=9,
                                                   min_impurity_decrease=0.1,
                                                   min_samples_leaf=4,
                                                   min_samples_split=7,
                                                   n_jobs=-1,
                                                   random_state=123)),
                            ('Light Gradient Boosting Machine',
                             LGBMRegressor(random_state=123)),
                            ('Extra Trees Regressor',
                             ExtraTr...
                                                 min_impurity_decrease=0.1,
                                                 min_samples_leaf=4,
                                                 min_samples_split=7, n_jobs=-1,
                                                 random_state=123)),
                            ('str',
                             AdaBoostRegressor(learning_rate=1e-06,
                                               n_estimators=240,
                                               random_state=123)),
                            ('Huber Regressor',
                             HuberRegressor(alpha=0.001, epsilon=1.4,
                                            fit_intercept=False)),
                            ('str_1',
                             BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                                              random_state=123))],
                n_jobs=-1)
2023-02-28 02:33:13,883:INFO:automl() successfully completed......................................
2023-02-28 02:35:16,693:INFO:Soft dependency imported: fastapi: 0.92.0
2023-02-28 02:35:16,693:INFO:Soft dependency imported: uvicorn: 0.20.0
2023-02-28 02:35:16,693:INFO:Soft dependency imported: pydantic: 1.10.5
2023-02-28 02:35:16,783:INFO:Initializing save_model()
2023-02-28 02:35:16,783:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\takis\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                  min_impurity_decrease=0.1,
                                                                  min_samples_leaf=4,
                                                                  min_samples_split=7,
                                                                  n_jobs=-1,
                                                                  random_state=123)),
                                             ('str',
                                              AdaBoostRegressor(learning_rate=1e-06,
                                                                n_estimators=240,
                                                                random_state=123)),
                                             ('Huber Regressor',
                                              HuberRegressor(alpha=0.001,
                                                             epsilon=1.4,
                                                             fit_intercept=False)),
                                             ('str_1',
                                              BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                                                               random_state=123))],
                                 n_jobs=-1))]), model_name=fm1_api, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\takis\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                     'smoker'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64},
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))]), verbose=False, use_case=MLUsecase.REGRESSION, kwargs={})
2023-02-28 02:35:16,783:INFO:Adding model into prep_pipe
2023-02-28 02:35:16,940:WARNING:Only Model saved as it was a pipeline.
2023-02-28 02:35:17,163:INFO:fm1_api.pkl saved in current working directory
2023-02-28 02:35:17,214:INFO:Pipeline(memory=FastMemory(location=C:\Users\takis\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                  min_impurity_decrease=0.1,
                                                                  min_samples_leaf=4,
                                                                  min_samples_split=7,
                                                                  n_jobs=-1,
                                                                  random_state=123)),
                                             ('str',
                                              AdaBoostRegressor(learning_rate=1e-06,
                                                                n_estimators=240,
                                                                random_state=123)),
                                             ('Huber Regressor',
                                              HuberRegressor(alpha=0.001,
                                                             epsilon=1.4,
                                                             fit_intercept=False)),
                                             ('str_1',
                                              BaggingRegressor(estimator=GradientBoostingRegressor(random_state=123),
                                                               random_state=123))],
                                 n_jobs=-1))])
2023-02-28 02:35:17,214:INFO:save_model() successfully completed......................................
2023-02-28 02:37:13,462:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-28 02:37:13,462:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-28 02:37:13,462:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-28 02:37:13,462:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-28 02:37:14,121:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-28 02:37:14,716:INFO:Initializing load_model()
2023-02-28 02:37:14,716:INFO:load_model(model_name=fm1_api, platform=None, authentication=None, verbose=True)
2023-02-28 02:37:52,841:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-28 02:37:52,841:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-28 02:37:52,841:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-28 02:37:52,841:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-02-28 02:37:53,322:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-02-28 02:37:53,822:INFO:Initializing load_model()
2023-02-28 02:37:53,822:INFO:load_model(model_name=fm1_api, platform=None, authentication=None, verbose=True)
